{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FW9Wm7zenz0u"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "from matplotlib import pyplot\n",
        "from keras.datasets import cifar10, mnist, fashion_mnist\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Flatten\n",
        "from keras.optimizers import SGD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y-oxre0GmjMa"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import random\n",
        "random.seed(1485)\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eo9ezoLuql8C"
      },
      "outputs": [],
      "source": [
        "def load_dataset(name):\n",
        "  if name == \"mnist\":\n",
        "    (trainX, trainY), (testX, testY) = mnist.load_data() #cifar10.load_data()\n",
        "    trainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\n",
        "    testX = testX.reshape((testX.shape[0], 28, 28, 1))\n",
        "    trainY = to_categorical(trainY)\n",
        "    testY = to_categorical(testY)\n",
        "  elif name == \"cifar\":\n",
        "    (trainX, trainY), (testX, testY) = cifar10.load_data()\n",
        "    trainY = to_categorical(trainY)\n",
        "    testY = to_categorical(testY)\n",
        "  elif name == \"fashion\":\n",
        "    (trainX, trainY), (testX, testY) = fashion_mnist.load_data()\n",
        "    trainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\n",
        "    testX = testX.reshape((testX.shape[0], 28, 28, 1))\n",
        "    trainY = to_categorical(trainY)\n",
        "    testY = to_categorical(testY)\n",
        "  return trainX, trainY, testX, testY\n",
        "\n",
        "def prep_pixels(train, test):\n",
        "  train_norm = train.astype('float32')\n",
        "  test_norm = test.astype('float32')\n",
        "  train_norm = train_norm / 255.0\n",
        "  test_norm = test_norm / 255.0\n",
        "  return train_norm, test_norm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vrtk-hRlqhAO"
      },
      "outputs": [],
      "source": [
        "# CIFAR\n",
        "def vgg_custom_model(lr, mom):\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
        "  model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "  model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "  opt = SGD(lr=lr, momentum=mom)\n",
        "  model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vaNEpbL7MaZ5"
      },
      "outputs": [],
      "source": [
        "# MNIST (28,28,1)\n",
        "def vgg_custom_model(lr, mom):\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(28, 28, 1)))\n",
        "  model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  # model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  # model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  # model.add(MaxPooling2D((2, 2)))\n",
        "  # model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  # model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  # model.add(MaxPooling2D((2, 2)))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "  model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "  opt = SGD(lr=lr, momentum=mom)\n",
        "  model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lb4Tch8tskr0",
        "outputId": "27b14b9b-7348-4ea1-8f62-d2956161e83b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "trainX, trainY, testX, testY = load_dataset(\"mnist\")\n",
        "trainX, testX = prep_pixels(trainX, testX)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQuU5PkmrWaa",
        "outputId": "89e84124-c3ad-4620-9f52-5ceacdc3e6a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "938/938 [==============================] - 119s 126ms/step - loss: 0.1539 - accuracy: 0.9531 - val_loss: 0.0558 - val_accuracy: 0.9815\n"
          ]
        }
      ],
      "source": [
        "model = vgg_custom_model(lr=0.0001, mom=0.9)\n",
        "history = model.fit(trainX, trainY, epochs=1, batch_size=64, validation_data=(testX, testY), verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eitJAkTrsU6f",
        "outputId": "4c45afe7-f757-4cfd-f958-18770a675cec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 10s 31ms/step - loss: 0.0558 - accuracy: 0.9815\n",
            "0.9815000295639038\n"
          ]
        }
      ],
      "source": [
        "loss, acc = model.evaluate(testX, testY, verbose=1)\n",
        "print(acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDwCaBByBLFV"
      },
      "source": [
        "## Pre processed input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "fQIqAYi-pwsj",
        "outputId": "53c06cc0-12ca-4f9e-eedc-443686bdea8e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x786777d24820>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "pyplot.imshow(trainX[1], cmap='gray')\n",
        "# trainX[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xgs7KaOHBAfm"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "greyscale_threshold = 0.2  # white is 1 ; 0.2 for mnist, 0.5 for cifar\n",
        "\n",
        "def get_flip_contrast(converted_img):\n",
        "    # guesstimate if image has dark or light background\n",
        "    grey_qty = 0\n",
        "    for i in converted_img:\n",
        "        grey_qty += ((i > greyscale_threshold).sum()/len(i))\n",
        "    grey_qty_normalized = grey_qty/converted_img.shape[0]\n",
        "#     print(grey_qty_normalized)\n",
        "    if grey_qty_normalized >= 0.5:\n",
        "        # image is light on dark background => do not flip contrast\n",
        "        return 0\n",
        "    else:\n",
        "        # image is dark on light background => flip contrast\n",
        "        return 1\n",
        "\n",
        "def binarize_image(converted_img):\n",
        "    # we want to avoid background but this should be reversed for dark image on light background\n",
        "    flip_contrast = get_flip_contrast(converted_img)\n",
        "    binarized = []\n",
        "    for i in converted_img:\n",
        "        # if flip_contrast:\n",
        "        #     binarized_row = np.ones(len(i))\n",
        "        #     for j_ind, j in enumerate(i):\n",
        "        #         if j>=greyscale_threshold:\n",
        "        #             binarized_row[j_ind] = 0\n",
        "        # else:\n",
        "        binarized_row = np.zeros(len(i))\n",
        "        for j_ind, j in enumerate(i):\n",
        "            if j>=greyscale_threshold:\n",
        "                binarized_row[j_ind] = 1\n",
        "        binarized.append(binarized_row)\n",
        "\n",
        "    binarized = np.array(binarized)\n",
        "    return binarized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "ps7mmohvGXx7",
        "outputId": "07926505-b158-4f80-eabe-d563d3a7f0e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28, 1)\n",
            "(28, 28, 1)\n",
            "1\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "{{function_node __wrapped__MatMul_device_/job:localhost/replica:0/task:0/device:CPU:0}} Matrix size-incompatible: In[0]: [784,1], In[1]: [3,1] [Op:MatMul] name: ",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-9eac3fa4bfe3>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# print(c.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mim\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrgb_to_grayscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbinarize_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# c = np.reshape(b, (-1, 4))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   5881\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mNoReturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5882\u001b[0m   \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5883\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5884\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5885\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__MatMul_device_/job:localhost/replica:0/task:0/device:CPU:0}} Matrix size-incompatible: In[0]: [784,1], In[1]: [3,1] [Op:MatMul] name: "
          ]
        }
      ],
      "source": [
        "im=0\n",
        "print(trainX.shape)\n",
        "print(trainX[im].shape)\n",
        "print(get_flip_contrast(trainX[im]))\n",
        "# b = binarize_image(trainX[im])\n",
        "# c = np.reshape(b, (-1, 4))\n",
        "# print(c.shape)\n",
        "for im in range(5):\n",
        "    b = tf.image.rgb_to_grayscale(trainX[im])\n",
        "    b = binarize_image(b.numpy())\n",
        "    # c = np.reshape(b, (-1, 4))\n",
        "    c = np.expand_dims(b, axis=2)\n",
        "    print(c.shape)\n",
        "pyplot.imshow(c, cmap='gray')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VylYNoILV4AK",
        "outputId": "c4163391-d7fd-43f6-c27e-8d40bbc254c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(10000, 32, 32, 1)\n"
          ]
        }
      ],
      "source": [
        "pY= np.asarray(processed_testX)\n",
        "print(pY.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EzYxn095BFsL",
        "outputId": "00c5ca61-a1ca-47df-fb03-5c25f5a52113"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 60000/60000 [01:37<00:00, 614.80it/s]\n"
          ]
        }
      ],
      "source": [
        "#all together NOT reqd\n",
        "processed_trainX=[]\n",
        "for im in tqdm(range(len(trainX))):\n",
        "    # b = tf.image.rgb_to_grayscale(trainX[im])\n",
        "    # b = binarize_image(b.numpy())\n",
        "    b = trainX[im]\n",
        "    b = binarize_image(b)\n",
        "    c = np.reshape(b, (-1, 4))\n",
        "    # c = np.expand_dims(b, axis=2)\n",
        "    processed_trainX.append(c)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUOQzC3zCFaB",
        "outputId": "a7dc2f2a-2be6-4b81-9872-c61efe098411"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10000/10000 [00:14<00:00, 686.83it/s]\n"
          ]
        }
      ],
      "source": [
        "#all together NOT reqd\n",
        "processed_testX=[]\n",
        "for im in tqdm(range(len(testX))):\n",
        "    # b = tf.image.rgb_to_grayscale(testX[im])\n",
        "    # b = binarize_image(b.numpy())\n",
        "    b = testX[im]\n",
        "    b = binarize_image(b)\n",
        "    c = np.reshape(b, (-1, 4))\n",
        "    # c = np.expand_dims(b, axis=2)\n",
        "    processed_testX.append(c)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### N-bit reservoir data"
      ],
      "metadata": {
        "id": "_7yHSoXzR5cw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip nbit_analysis_for_reservoir.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZoIalWQR-o4",
        "outputId": "e2778f45-2305-4076-f08b-38310a4ea458"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  nbit_analysis_for_reservoir.zip\n",
            " extracting: Extracted/4-bit.xlsx    \n",
            " extracting: Extracted/4-bit_entropy.xlsx  \n",
            " extracting: Extracted/5-bit.xlsx    \n",
            " extracting: Extracted/5-bit_entropy.xlsx  \n",
            " extracting: Extracted/6-bit.xlsx    \n",
            " extracting: Extracted/6-bit_entropy.xlsx  \n",
            " extracting: Extracted/7-bit.xlsx    \n",
            " extracting: Extracted/7-bit_entropy.xlsx  \n",
            " extracting: Extracted/8-bit.xlsx    \n",
            " extracting: Extracted/8-bit_entropy.xlsx  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "readout_mapping = pd.read_excel('Extracted/4-bit.xlsx')\n",
        "readout_mapping.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "cjJr02c_SFIB",
        "outputId": "cf94c331-3e7b-4266-c2ee-3935d078f29c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0     0.3     0.4      0.5      0.6      0.7\n",
              "0           1  20.385  43.923   61.779   77.105   90.162\n",
              "1           2  18.694  35.285   49.405   61.161   71.154\n",
              "2           3  52.554  82.902  105.034  120.577  130.879\n",
              "3           4  16.016  29.244   40.702   50.776   58.739\n",
              "4           5  41.516  71.200   94.731  112.138  125.132"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0495b6d3-2c61-4d2a-9881-ca40e772dc25\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>0.3</th>\n",
              "      <th>0.4</th>\n",
              "      <th>0.5</th>\n",
              "      <th>0.6</th>\n",
              "      <th>0.7</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>20.385</td>\n",
              "      <td>43.923</td>\n",
              "      <td>61.779</td>\n",
              "      <td>77.105</td>\n",
              "      <td>90.162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>18.694</td>\n",
              "      <td>35.285</td>\n",
              "      <td>49.405</td>\n",
              "      <td>61.161</td>\n",
              "      <td>71.154</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>52.554</td>\n",
              "      <td>82.902</td>\n",
              "      <td>105.034</td>\n",
              "      <td>120.577</td>\n",
              "      <td>130.879</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>16.016</td>\n",
              "      <td>29.244</td>\n",
              "      <td>40.702</td>\n",
              "      <td>50.776</td>\n",
              "      <td>58.739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>41.516</td>\n",
              "      <td>71.200</td>\n",
              "      <td>94.731</td>\n",
              "      <td>112.138</td>\n",
              "      <td>125.132</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0495b6d3-2c61-4d2a-9881-ca40e772dc25')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0495b6d3-2c61-4d2a-9881-ca40e772dc25 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0495b6d3-2c61-4d2a-9881-ca40e772dc25');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-fb7839bf-c3b9-4764-8fe8-4fb2d9eaa01f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fb7839bf-c3b9-4764-8fe8-4fb2d9eaa01f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-fb7839bf-c3b9-4764-8fe8-4fb2d9eaa01f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "readout_mapping",
              "summary": "{\n  \"name\": \"readout_mapping\",\n  \"rows\": 15,\n  \"fields\": [\n    {\n      \"column\": \"Unnamed: 0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4,\n        \"min\": 1,\n        \"max\": 15,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          10,\n          12,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 0.3,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 22.174018662990854,\n        \"min\": 13.67,\n        \"max\": 87.563,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          34.485,\n          35.852000000000004,\n          20.385\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 0.4,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 28.884245510229935,\n        \"min\": 24.908,\n        \"max\": 120.542,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          58.504,\n          55.891000000000005,\n          43.922999999999995\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 0.5,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 32.06651385078923,\n        \"min\": 34.81,\n        \"max\": 139.001,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          77.376,\n          70.54,\n          61.779\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 0.6,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 33.2053936829259,\n        \"min\": 43.178000000000004,\n        \"max\": 149.923,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          91.482,\n          81.172,\n          77.105\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 0.7,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 33.32142633901896,\n        \"min\": 50.34,\n        \"max\": 156.584,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          102.0,\n          88.446,\n          90.162\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "readout_mapping[0.3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bAhzdD3kTELD",
        "outputId": "c3826f25-c64c-4ae7-dbc1-fef1221453ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     20.385\n",
              "1     18.694\n",
              "2     52.554\n",
              "3     16.016\n",
              "4     41.516\n",
              "5     42.890\n",
              "6     73.044\n",
              "7     13.670\n",
              "8     39.264\n",
              "9     34.485\n",
              "10    65.988\n",
              "11    35.852\n",
              "12    59.483\n",
              "13    60.071\n",
              "14    87.563\n",
              "Name: 0.3, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config = \"4bit40p\"\n",
        "vout = list(readout_mapping[0.4])\n",
        "vout_mapping = {}\n",
        "vout_mapping['{0:04b}'.format(0)] = 0.000\n",
        "for v_ind, v in enumerate(vout, 1):\n",
        "    vout_mapping['{0:04b}'.format(v_ind)] = v\n",
        "print(vout_mapping)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FV9JmLtJSe3e",
        "outputId": "825b606d-01e8-4c84-fc79-df75592a4dee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'0000': 0.0, '0001': 43.922999999999995, '0010': 35.285, '0011': 82.902, '0100': 29.244, '0101': 71.2, '0110': 66.667, '0111': 105.765, '1000': 24.908, '1001': 68.086, '1010': 58.504, '1011': 100.45400000000001, '1100': 55.891000000000005, '1101': 93.439, '1110': 86.708, '1111': 120.542}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8L5_XrHID7Z"
      },
      "source": [
        "### Reservoir Vouts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "A_ea4cfGRXo6",
        "outputId": "83411b4a-3765-4eab-82b5-7b73c4006fc5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   0        1        2        3        4        5        6         7   \\\n",
              "0   0  60.8684  41.5629  86.3955  34.2662  83.8812  64.1904   99.4241   \n",
              "1   0  61.1562  41.7318  85.0438  34.2150  82.4636  62.8211   98.8232   \n",
              "2   0  60.4900  41.8793  85.8486  33.9915  82.3169  62.9551   99.1851   \n",
              "3   0  60.8307  41.7019  84.6410  34.0208  82.8960  62.7907   98.6990   \n",
              "4   0  60.7626  42.0426  84.5182  34.2287  82.9573  62.9176  100.2519   \n",
              "\n",
              "        8        9        10       11       12       13       14       15  \n",
              "0  29.4246  79.9931  61.3460  98.9802  53.3931  97.0847  78.0642  111.704  \n",
              "1  29.6049  79.2128  61.3729  98.1410  53.5749  96.0234  77.4053  110.492  \n",
              "2  29.7845  81.0870  61.7485  97.1178  53.2268  95.5435  76.3657  109.809  \n",
              "3  29.5571  80.3683  61.1568  98.1737  53.6685  96.0785  76.7872  109.196  \n",
              "4  29.2494  79.0557  61.0597  97.4431  53.4340  96.3310  77.5604  111.181  "
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-2a06f4af-0d18-4797-b6db-9b2df34b3055\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>60.8684</td>\n",
              "      <td>41.5629</td>\n",
              "      <td>86.3955</td>\n",
              "      <td>34.2662</td>\n",
              "      <td>83.8812</td>\n",
              "      <td>64.1904</td>\n",
              "      <td>99.4241</td>\n",
              "      <td>29.4246</td>\n",
              "      <td>79.9931</td>\n",
              "      <td>61.3460</td>\n",
              "      <td>98.9802</td>\n",
              "      <td>53.3931</td>\n",
              "      <td>97.0847</td>\n",
              "      <td>78.0642</td>\n",
              "      <td>111.704</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>61.1562</td>\n",
              "      <td>41.7318</td>\n",
              "      <td>85.0438</td>\n",
              "      <td>34.2150</td>\n",
              "      <td>82.4636</td>\n",
              "      <td>62.8211</td>\n",
              "      <td>98.8232</td>\n",
              "      <td>29.6049</td>\n",
              "      <td>79.2128</td>\n",
              "      <td>61.3729</td>\n",
              "      <td>98.1410</td>\n",
              "      <td>53.5749</td>\n",
              "      <td>96.0234</td>\n",
              "      <td>77.4053</td>\n",
              "      <td>110.492</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>60.4900</td>\n",
              "      <td>41.8793</td>\n",
              "      <td>85.8486</td>\n",
              "      <td>33.9915</td>\n",
              "      <td>82.3169</td>\n",
              "      <td>62.9551</td>\n",
              "      <td>99.1851</td>\n",
              "      <td>29.7845</td>\n",
              "      <td>81.0870</td>\n",
              "      <td>61.7485</td>\n",
              "      <td>97.1178</td>\n",
              "      <td>53.2268</td>\n",
              "      <td>95.5435</td>\n",
              "      <td>76.3657</td>\n",
              "      <td>109.809</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>60.8307</td>\n",
              "      <td>41.7019</td>\n",
              "      <td>84.6410</td>\n",
              "      <td>34.0208</td>\n",
              "      <td>82.8960</td>\n",
              "      <td>62.7907</td>\n",
              "      <td>98.6990</td>\n",
              "      <td>29.5571</td>\n",
              "      <td>80.3683</td>\n",
              "      <td>61.1568</td>\n",
              "      <td>98.1737</td>\n",
              "      <td>53.6685</td>\n",
              "      <td>96.0785</td>\n",
              "      <td>76.7872</td>\n",
              "      <td>109.196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>60.7626</td>\n",
              "      <td>42.0426</td>\n",
              "      <td>84.5182</td>\n",
              "      <td>34.2287</td>\n",
              "      <td>82.9573</td>\n",
              "      <td>62.9176</td>\n",
              "      <td>100.2519</td>\n",
              "      <td>29.2494</td>\n",
              "      <td>79.0557</td>\n",
              "      <td>61.0597</td>\n",
              "      <td>97.4431</td>\n",
              "      <td>53.4340</td>\n",
              "      <td>96.3310</td>\n",
              "      <td>77.5604</td>\n",
              "      <td>111.181</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2a06f4af-0d18-4797-b6db-9b2df34b3055')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-20f33e24-bedb-4600-803a-6c338b2d606d\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-20f33e24-bedb-4600-803a-6c338b2d606d')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-20f33e24-bedb-4600-803a-6c338b2d606d button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2a06f4af-0d18-4797-b6db-9b2df34b3055 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2a06f4af-0d18-4797-b6db-9b2df34b3055');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import pandas as pd\n",
        "readout_mapping = pd.read_excel('Vout.xlsx')\n",
        "readout_mapping.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IkGZVHXzhRV-",
        "outputId": "442c17eb-4be8-4a1f-ce27-cccf29d67efa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'0000': 0.0, '0001': 60.946725, '0010': 41.91007499999999, '0011': 84.99817999999999, '0100': 34.22956, '0101': 81.90558, '0110': 62.871390000000005, '0111': 99.07972, '1000': 29.628125000000004, '1001': 80.17856500000002, '1010': 61.29259, '1011': 98.35782999999999, '1100': 53.645735, '1101': 95.66469499999998, '1110': 77.352185, '1111': 110.78180000000002}\n"
          ]
        }
      ],
      "source": [
        "vout = list(readout_mapping.mean(axis=0))\n",
        "vout_mapping = {}\n",
        "for v_ind, v in enumerate(vout):\n",
        "    vout_mapping['{0:04b}'.format(v_ind)] = v\n",
        "print(vout_mapping)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using Vout mapping"
      ],
      "metadata": {
        "id": "-atf-YTzSRI3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2QkkvaxNg5Et",
        "outputId": "73fe1d95-22ab-40f7-a5a9-deb2e061f388"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 60000/60000 [02:33<00:00, 390.82it/s]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "processed_trainX=[]\n",
        "for im in tqdm(range(len(trainX))):\n",
        "    # b = tf.image.rgb_to_grayscale(trainX[im])\n",
        "    # b = binarize_image(b.numpy())\n",
        "    b = trainX[im]\n",
        "    b = binarize_image(b)\n",
        "    c = np.reshape(b, (-1, 4))\n",
        "    im_res_inp = []\n",
        "    for i in c:\n",
        "        bit_pattern = ''.join([str(int(i[j])) for j in range(4)])\n",
        "        im_res_inp.append(vout_mapping[bit_pattern])\n",
        "    # processed_trainX.append(im_res_inp)\n",
        "    d=np.reshape(im_res_inp, (-1, 14))\n",
        "    processed_trainX.append(d)\n",
        "pX= np.asarray(processed_trainX)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dN3NNTd5h58A",
        "outputId": "cf6ec50c-3e49-4336-c42a-a58187f78072"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10000/10000 [00:28<00:00, 350.71it/s]\n"
          ]
        }
      ],
      "source": [
        "processed_testX=[]\n",
        "for im in tqdm(range(len(testX))):\n",
        "    # b = tf.image.rgb_to_grayscale(testX[im])\n",
        "    # b = binarize_image(b.numpy())\n",
        "    b = testX[im]\n",
        "    b = binarize_image(b)\n",
        "    c = np.reshape(b, (-1, 4))\n",
        "    im_res_inp = []\n",
        "    for i in c:\n",
        "        bit_pattern = ''.join([str(int(i[j])) for j in range(4)])\n",
        "        im_res_inp.append(vout_mapping[bit_pattern])\n",
        "    # processed_trainX.append(im_res_inp)\n",
        "    d=np.reshape(im_res_inp, (-1, 14))\n",
        "    processed_testX.append(d)\n",
        "pY= np.asarray(processed_testX)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ex95T229BJpr"
      },
      "outputs": [],
      "source": [
        "def vgg_custom_model(lr, mom):\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(14, 14, 1)))\n",
        "  model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  # model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  # model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  # model.add(MaxPooling2D((2, 2)))\n",
        "  # model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  # model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  # model.add(MaxPooling2D((2, 2)))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "  model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "  opt = SGD(lr=lr, momentum=mom)\n",
        "  model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "  return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDvxW2RwESsA",
        "outputId": "ce828174-9849-4f22-9030-1ccbc330d5ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1875/1875 [==============================] - 41s 22ms/step - loss: 5701558884892672.0000 - accuracy: 0.1105 - val_loss: 2.3013 - val_accuracy: 0.1135\n",
            "Epoch 2/20\n",
            "1875/1875 [==============================] - 38s 20ms/step - loss: 2.3018 - accuracy: 0.1120 - val_loss: 2.3020 - val_accuracy: 0.1028\n",
            "Epoch 3/20\n",
            "1875/1875 [==============================] - 38s 20ms/step - loss: 2.3018 - accuracy: 0.1123 - val_loss: 2.3023 - val_accuracy: 0.1028\n",
            "Epoch 4/20\n",
            "1875/1875 [==============================] - 40s 21ms/step - loss: 2.3019 - accuracy: 0.1107 - val_loss: 2.3013 - val_accuracy: 0.1135\n",
            "Epoch 5/20\n",
            "1875/1875 [==============================] - 40s 21ms/step - loss: 2.3019 - accuracy: 0.1114 - val_loss: 2.3019 - val_accuracy: 0.1135\n",
            "Epoch 6/20\n",
            "1875/1875 [==============================] - 38s 20ms/step - loss: 2.3019 - accuracy: 0.1111 - val_loss: 2.3015 - val_accuracy: 0.1135\n",
            "Epoch 7/20\n",
            "1875/1875 [==============================] - 40s 21ms/step - loss: 2.3018 - accuracy: 0.1116 - val_loss: 2.3019 - val_accuracy: 0.1135\n",
            "Epoch 8/20\n",
            "1875/1875 [==============================] - 39s 21ms/step - loss: 2.3019 - accuracy: 0.1110 - val_loss: 2.3023 - val_accuracy: 0.1135\n",
            "Epoch 9/20\n",
            "1875/1875 [==============================] - 38s 20ms/step - loss: 2.3020 - accuracy: 0.1105 - val_loss: 2.3016 - val_accuracy: 0.1135\n",
            "Epoch 10/20\n",
            "1875/1875 [==============================] - 38s 20ms/step - loss: 2.3020 - accuracy: 0.1113 - val_loss: 2.3014 - val_accuracy: 0.1135\n",
            "Epoch 11/20\n",
            "1875/1875 [==============================] - 38s 20ms/step - loss: 2.3019 - accuracy: 0.1113 - val_loss: 2.3016 - val_accuracy: 0.1135\n",
            "Epoch 12/20\n",
            "1875/1875 [==============================] - 38s 21ms/step - loss: 2.3019 - accuracy: 0.1117 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
            "Epoch 13/20\n",
            "1875/1875 [==============================] - 37s 20ms/step - loss: 2.3019 - accuracy: 0.1110 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
            "Epoch 14/20\n",
            "1875/1875 [==============================] - 39s 21ms/step - loss: 2.3019 - accuracy: 0.1108 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
            "Epoch 15/20\n",
            "1875/1875 [==============================] - 38s 20ms/step - loss: 2.3020 - accuracy: 0.1108 - val_loss: 2.3024 - val_accuracy: 0.1135\n",
            "Epoch 16/20\n",
            "1875/1875 [==============================] - 38s 20ms/step - loss: 2.3020 - accuracy: 0.1107 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
            "Epoch 17/20\n",
            "1875/1875 [==============================] - 38s 20ms/step - loss: 2.3019 - accuracy: 0.1117 - val_loss: 2.3014 - val_accuracy: 0.1135\n",
            "Epoch 18/20\n",
            "1875/1875 [==============================] - 37s 20ms/step - loss: 2.3019 - accuracy: 0.1111 - val_loss: 2.3012 - val_accuracy: 0.1135\n",
            "Epoch 19/20\n",
            "1875/1875 [==============================] - 37s 20ms/step - loss: 2.3018 - accuracy: 0.1098 - val_loss: 2.3023 - val_accuracy: 0.0980\n",
            "Epoch 20/20\n",
            "1875/1875 [==============================] - 38s 21ms/step - loss: 2.3019 - accuracy: 0.1101 - val_loss: 2.3020 - val_accuracy: 0.1135\n"
          ]
        }
      ],
      "source": [
        "model = vgg_custom_model(0.001,0.9)\n",
        "history = model.fit(pX, trainY, epochs=20, batch_size=32, validation_data=(pY, testY), verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hI4_4y_PtR08"
      },
      "source": [
        "## Set up W&B"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcc4n2yHtQ8l",
        "outputId": "2125d7e6-e4e5-4bde-eb25-e6bb393f575a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "!pip install wandb -qU\n",
        "import wandb\n",
        "from wandb.keras import WandbCallback\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 716,
          "referenced_widgets": [
            "4490d439b342455bb334041c10b41ae7",
            "ae2c1f6ad6ff47a889ccc550f36230a5",
            "9de148b9ed774c6db8e60f3314c63be5",
            "1da91789a55243a49349b420bc758852",
            "98a03a4ba6354bd3be0e9c3639b6f929",
            "a96000645a9d4dcba56aa9b4605a04d2",
            "0d5205160bc14986afe86a1f10f0bfa6",
            "92fc58f5cddf435e99532d4155fd5715"
          ]
        },
        "id": "C2nQ4Q6Ptzpa",
        "outputId": "e532a870-0222-4359-cdf6-0b6ccc17f597"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Finishing last run (ID:hdw3mu28) before initializing another..."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4490d439b342455bb334041c10b41ae7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">experiment_0</strong> at: <a href='https://wandb.ai/alkaluqman/reservoir-nn/runs/hdw3mu28' target=\"_blank\">https://wandb.ai/alkaluqman/reservoir-nn/runs/hdw3mu28</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20230322_021116-hdw3mu28/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Successfully finished last run (ID:hdw3mu28). Initializing new run:<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.14.0"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230322_021127-rz2kz74r</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/alkaluqman/reservoir-nn/runs/rz2kz74r' target=\"_blank\">experiment_0</a></strong> to <a href='https://wandb.ai/alkaluqman/reservoir-nn' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/alkaluqman/reservoir-nn' target=\"_blank\">https://wandb.ai/alkaluqman/reservoir-nn</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/alkaluqman/reservoir-nn/runs/rz2kz74r' target=\"_blank\">https://wandb.ai/alkaluqman/reservoir-nn/runs/rz2kz74r</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "782/782 [==============================] - ETA: 0s - loss: 1.6766 - accuracy: 0.3953"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 6). These functions will not be directly callable after loading.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20230322_021127-rz2kz74r/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "782/782 [==============================] - 415s 530ms/step - loss: 1.6766 - accuracy: 0.3953 - val_loss: 1.4960 - val_accuracy: 0.4555\n",
            "313/313 [==============================] - 20s 64ms/step\n",
            "313/313 [==============================] - 20s 63ms/step - loss: 1.4960 - accuracy: 0.4555\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>▁</td></tr><tr><td>accuracy</td><td>▁</td></tr><tr><td>epoch</td><td>▁</td></tr><tr><td>loss</td><td>█▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>0.4555</td></tr><tr><td>accuracy</td><td>0.39532</td></tr><tr><td>best_epoch</td><td>0</td></tr><tr><td>best_val_loss</td><td>1.49602</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>loss</td><td>1.49602</td></tr><tr><td>val_accuracy</td><td>0.4555</td></tr><tr><td>val_loss</td><td>1.49602</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">experiment_0</strong> at: <a href='https://wandb.ai/alkaluqman/reservoir-nn/runs/rz2kz74r' target=\"_blank\">https://wandb.ai/alkaluqman/reservoir-nn/runs/rz2kz74r</a><br/>Synced 5 W&B file(s), 2 media file(s), 6 artifact file(s) and 1 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20230322_021127-rz2kz74r/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "total_runs = 1\n",
        "epochs = 1\n",
        "for run in range(total_runs):\n",
        "  wandb.init(\n",
        "      project=\"reservoir-nn\",\n",
        "      name=f\"experiment_{run}\",\n",
        "      # Track hyperparameters and run metadata\n",
        "      config={\n",
        "      \"learning_rate\": 0.001,\n",
        "      \"architecture\": \"VGG custom 3\",\n",
        "      \"dataset\": \"CIFAR-10\",\n",
        "      \"epochs\": epochs,\n",
        "      \"optimizer\": \"SGD\"\n",
        "      })\n",
        "  wandb_callback = WandbCallback(monitor='val_loss', log_weights=False, log_evaluation=True, validation_steps=1)\n",
        "  callbacks = [wandb_callback]\n",
        "\n",
        "  model.fit(trainX, trainY, epochs=epochs, batch_size=64, callbacks=callbacks, validation_data=(testX, testY), verbose=1)\n",
        "  loss, acc = model.evaluate(testX, testY, verbose=1)\n",
        "  wandb.log({\"acc\": acc, \"loss\": loss})\n",
        "  wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kK_PCHbI3Mb"
      },
      "source": [
        "## Experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "40upuxDZI6C2",
        "outputId": "d053d410-8d53-44d0-9eb9-d34cc1fa766a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "27bb36fb888d43f4b09975ae5bce89ac",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016668876783334476, max=1.0…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem at: <ipython-input-28-8c65b052b37b> 10 <cell line: 8>\n"
          ]
        },
        {
          "ename": "CommError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCommError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-8c65b052b37b>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrun\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_runs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   wandb.init(\n\u001b[0m\u001b[1;32m     11\u001b[0m       \u001b[0mproject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"reservoir-nn\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"experiment_readout_{run}\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\u001b[0m\n\u001b[1;32m   1162\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlogger\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1164\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1165\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1166\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\u001b[0m\n\u001b[1;32m   1143\u001b[0m         \u001b[0mexcept_exit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_except_exit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1145\u001b[0;31m             \u001b[0mrun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1146\u001b[0m             \u001b[0mexcept_exit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_except_exit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    762\u001b[0m                     \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mteardown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mrun_result\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# for mypy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mCommError\u001b[0m: Run initialization has timed out after 60.0 sec. \nPlease refer to the documentation for additional information: https://docs.wandb.ai/guides/track/tracking-faq#initstarterror-error-communicating-with-wandb-process-"
          ]
        }
      ],
      "source": [
        "epochs = 20\n",
        "# learning_rates = [0.001, 0.001, 0.005, 0.01]\n",
        "# momentums = [0.9, 0.5, 0.9, 0.9]\n",
        "learning_rates = [0.001, 0.0001]\n",
        "momentums = [0.9, 0.9]\n",
        "total_runs = len(learning_rates)\n",
        "params = list(zip(learning_rates, momentums))\n",
        "for run in range(total_runs):\n",
        "  lr, mom = params[run]\n",
        "  wandb.init(\n",
        "      project=\"reservoir-nn\",\n",
        "      name=f\"experiment_readout_{run}\",\n",
        "      # Track hyperparameters and run metadata\n",
        "      config={\n",
        "      \"architecture\": \"VGG custom 1\",\n",
        "      \"dataset\": \"MNIST binarized 14x14\",\n",
        "      \"epochs\": epochs,\n",
        "      \"optimizer\": \"SGD\",\n",
        "      \"learning_rate\": lr,\n",
        "      \"momentum\": mom\n",
        "      })\n",
        "  wandb_callback = WandbCallback(monitor='val_loss', log_weights=False, log_evaluation=True, validation_steps=1)\n",
        "  callbacks = [wandb_callback]\n",
        "\n",
        "  model = vgg_custom_model(lr, mom)\n",
        "  model.fit(pX, trainY, epochs=epochs, batch_size=64, callbacks=callbacks, validation_data=(pY, testY), verbose=1)\n",
        "  loss, acc = model.evaluate(pY, testY, verbose=1)\n",
        "  wandb.log({\"acc\": acc, \"loss\": loss})\n",
        "  wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFhD4pOWvGFq"
      },
      "source": [
        "MNIST numbrs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMmrzbFMKNEK",
        "outputId": "4c1f4537-0a76-4281-e084-1571d713820f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 2.7249 - accuracy: 0.1773 - val_loss: 2.1234 - val_accuracy: 0.1834\n",
            "Epoch 2/20\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 2.1169 - accuracy: 0.1825 - val_loss: 2.1210 - val_accuracy: 0.1796\n",
            "Epoch 3/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 2.1151 - accuracy: 0.1827 - val_loss: 2.1179 - val_accuracy: 0.1833\n",
            "Epoch 4/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 2.1138 - accuracy: 0.1831 - val_loss: 2.1183 - val_accuracy: 0.1831\n",
            "Epoch 5/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 1.7796 - accuracy: 0.3287 - val_loss: 0.5374 - val_accuracy: 0.8313\n",
            "Epoch 6/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2848 - accuracy: 0.9114 - val_loss: 0.1905 - val_accuracy: 0.9367\n",
            "Epoch 7/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1817 - accuracy: 0.9429 - val_loss: 0.1440 - val_accuracy: 0.9514\n",
            "Epoch 8/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1530 - accuracy: 0.9524 - val_loss: 0.1353 - val_accuracy: 0.9581\n",
            "Epoch 9/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1354 - accuracy: 0.9567 - val_loss: 0.1232 - val_accuracy: 0.9605\n",
            "Epoch 10/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1262 - accuracy: 0.9600 - val_loss: 0.1098 - val_accuracy: 0.9649\n",
            "Epoch 11/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1167 - accuracy: 0.9624 - val_loss: 0.1321 - val_accuracy: 0.9608\n",
            "Epoch 12/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1086 - accuracy: 0.9646 - val_loss: 0.1301 - val_accuracy: 0.9609\n",
            "Epoch 13/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1021 - accuracy: 0.9677 - val_loss: 0.1122 - val_accuracy: 0.9665\n",
            "Epoch 14/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0989 - accuracy: 0.9678 - val_loss: 0.1292 - val_accuracy: 0.9601\n",
            "Epoch 15/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0942 - accuracy: 0.9694 - val_loss: 0.1084 - val_accuracy: 0.9682\n",
            "Epoch 16/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0909 - accuracy: 0.9702 - val_loss: 0.1045 - val_accuracy: 0.9670\n",
            "Epoch 17/20\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0871 - accuracy: 0.9719 - val_loss: 0.0966 - val_accuracy: 0.9712\n",
            "Epoch 18/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0846 - accuracy: 0.9722 - val_loss: 0.1158 - val_accuracy: 0.9644\n",
            "Epoch 19/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0823 - accuracy: 0.9730 - val_loss: 0.1044 - val_accuracy: 0.9685\n",
            "Epoch 20/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0792 - accuracy: 0.9746 - val_loss: 0.1059 - val_accuracy: 0.9695\n"
          ]
        }
      ],
      "source": [
        "model = vgg_custom_model(0.001,0.9)\n",
        "history = model.fit(pX, trainY, epochs=20, batch_size=32, validation_data=(pY, testY), verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UIvT2G3zvMHR",
        "outputId": "489fc210-837c-45da-bacc-1585bf7abaaf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.9349 - accuracy: 0.8867 - val_loss: 0.2022 - val_accuracy: 0.9369\n",
            "Epoch 2/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1764 - accuracy: 0.9456 - val_loss: 0.1719 - val_accuracy: 0.9453\n",
            "Epoch 3/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1387 - accuracy: 0.9579 - val_loss: 0.1333 - val_accuracy: 0.9583\n",
            "Epoch 4/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1181 - accuracy: 0.9636 - val_loss: 0.1217 - val_accuracy: 0.9625\n",
            "Epoch 5/20\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.1045 - accuracy: 0.9670 - val_loss: 0.1101 - val_accuracy: 0.9656\n",
            "Epoch 6/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0946 - accuracy: 0.9704 - val_loss: 0.1066 - val_accuracy: 0.9678\n",
            "Epoch 7/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0844 - accuracy: 0.9731 - val_loss: 0.1029 - val_accuracy: 0.9674\n",
            "Epoch 8/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0785 - accuracy: 0.9753 - val_loss: 0.1012 - val_accuracy: 0.9700\n",
            "Epoch 9/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0729 - accuracy: 0.9769 - val_loss: 0.0939 - val_accuracy: 0.9705\n",
            "Epoch 10/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0678 - accuracy: 0.9782 - val_loss: 0.0967 - val_accuracy: 0.9701\n",
            "Epoch 11/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0640 - accuracy: 0.9797 - val_loss: 0.0989 - val_accuracy: 0.9697\n",
            "Epoch 12/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0596 - accuracy: 0.9808 - val_loss: 0.0847 - val_accuracy: 0.9738\n",
            "Epoch 13/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0563 - accuracy: 0.9817 - val_loss: 0.0904 - val_accuracy: 0.9710\n",
            "Epoch 14/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0530 - accuracy: 0.9829 - val_loss: 0.0833 - val_accuracy: 0.9741\n",
            "Epoch 15/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0503 - accuracy: 0.9839 - val_loss: 0.0867 - val_accuracy: 0.9740\n",
            "Epoch 16/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0481 - accuracy: 0.9841 - val_loss: 0.0848 - val_accuracy: 0.9739\n",
            "Epoch 17/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0452 - accuracy: 0.9854 - val_loss: 0.0822 - val_accuracy: 0.9758\n",
            "Epoch 18/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0436 - accuracy: 0.9856 - val_loss: 0.0864 - val_accuracy: 0.9740\n",
            "Epoch 19/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0410 - accuracy: 0.9866 - val_loss: 0.0817 - val_accuracy: 0.9763\n",
            "Epoch 20/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0388 - accuracy: 0.9875 - val_loss: 0.0814 - val_accuracy: 0.9755\n"
          ]
        }
      ],
      "source": [
        "model = vgg_custom_model(0.0001,0.9)\n",
        "history = model.fit(pX, trainY, epochs=20, batch_size=32, validation_data=(pY, testY), verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1R4SSxQ8Wr1"
      },
      "source": [
        "Fashion MNIST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jahlXpar8Y8j",
        "outputId": "6020d44f-865f-4c81-8ddd-a24d571bb201"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/optimizers/legacy/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 3.9301 - accuracy: 0.0993 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 2/20\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 2.3027 - accuracy: 0.0977 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 3/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3027 - accuracy: 0.0969 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 4/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 2.3027 - accuracy: 0.0982 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 5/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3027 - accuracy: 0.0976 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 6/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3027 - accuracy: 0.0978 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 7/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3027 - accuracy: 0.0998 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 8/20\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 2.3027 - accuracy: 0.0982 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 9/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3027 - accuracy: 0.0958 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 10/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 2.3027 - accuracy: 0.0991 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 11/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3027 - accuracy: 0.0977 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 12/20\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 2.3027 - accuracy: 0.0999 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 13/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3027 - accuracy: 0.0989 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 14/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 2.3027 - accuracy: 0.0974 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 15/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3027 - accuracy: 0.0981 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 16/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3027 - accuracy: 0.0988 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 17/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3027 - accuracy: 0.0973 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 18/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 2.3027 - accuracy: 0.0996 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 19/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3027 - accuracy: 0.0982 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
            "Epoch 20/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3027 - accuracy: 0.0984 - val_loss: 2.3026 - val_accuracy: 0.1000\n"
          ]
        }
      ],
      "source": [
        "model = vgg_custom_model(0.001,0.9)\n",
        "history = model.fit(pX, trainY, epochs=20, batch_size=32, validation_data=(pY, testY), verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jt4xPNGf8aCQ",
        "outputId": "e6bf6c2f-0a13-4678-ee2e-e18b415e57f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 1.2087 - accuracy: 0.7731 - val_loss: 0.5397 - val_accuracy: 0.8090\n",
            "Epoch 2/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4767 - accuracy: 0.8266 - val_loss: 0.4876 - val_accuracy: 0.8267\n",
            "Epoch 3/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4328 - accuracy: 0.8396 - val_loss: 0.4731 - val_accuracy: 0.8260\n",
            "Epoch 4/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4073 - accuracy: 0.8481 - val_loss: 0.4633 - val_accuracy: 0.8286\n",
            "Epoch 5/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3884 - accuracy: 0.8535 - val_loss: 0.4430 - val_accuracy: 0.8385\n",
            "Epoch 6/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3733 - accuracy: 0.8609 - val_loss: 0.4340 - val_accuracy: 0.8422\n",
            "Epoch 7/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3610 - accuracy: 0.8645 - val_loss: 0.4295 - val_accuracy: 0.8420\n",
            "Epoch 8/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3511 - accuracy: 0.8688 - val_loss: 0.4232 - val_accuracy: 0.8465\n",
            "Epoch 9/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3432 - accuracy: 0.8705 - val_loss: 0.4264 - val_accuracy: 0.8455\n",
            "Epoch 10/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3356 - accuracy: 0.8734 - val_loss: 0.4253 - val_accuracy: 0.8427\n",
            "Epoch 11/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3281 - accuracy: 0.8767 - val_loss: 0.4143 - val_accuracy: 0.8482\n",
            "Epoch 12/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3219 - accuracy: 0.8789 - val_loss: 0.4175 - val_accuracy: 0.8496\n",
            "Epoch 13/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3162 - accuracy: 0.8808 - val_loss: 0.4138 - val_accuracy: 0.8489\n",
            "Epoch 14/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3107 - accuracy: 0.8819 - val_loss: 0.4144 - val_accuracy: 0.8508\n",
            "Epoch 15/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3048 - accuracy: 0.8843 - val_loss: 0.4171 - val_accuracy: 0.8485\n",
            "Epoch 16/20\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.3001 - accuracy: 0.8870 - val_loss: 0.4235 - val_accuracy: 0.8469\n",
            "Epoch 17/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2949 - accuracy: 0.8887 - val_loss: 0.4137 - val_accuracy: 0.8522\n",
            "Epoch 18/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2914 - accuracy: 0.8903 - val_loss: 0.4168 - val_accuracy: 0.8495\n",
            "Epoch 19/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2880 - accuracy: 0.8913 - val_loss: 0.4089 - val_accuracy: 0.8514\n",
            "Epoch 20/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2839 - accuracy: 0.8927 - val_loss: 0.4143 - val_accuracy: 0.8528\n"
          ]
        }
      ],
      "source": [
        "model = vgg_custom_model(0.0001,0.9)\n",
        "history = model.fit(pX, trainY, epochs=20, batch_size=32, validation_data=(pY, testY), verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zJ3-ObmJ1Zg"
      },
      "source": [
        "## Study : Number of channels in data vs Accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-cxSUpnKERZ"
      },
      "source": [
        "CIFAR greyscale 2^n states"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2V3Gh7jKFQV",
        "outputId": "45d1f4e2-c742-44a8-aa49-7acc3fcb6d16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 13s 0us/step\n"
          ]
        }
      ],
      "source": [
        "trainX, trainY, testX, testY = load_dataset(\"cifar\")\n",
        "trainX, testX = prep_pixels(trainX, testX)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rL8iX68LWOoe",
        "outputId": "ced1a81c-e0c8-479a-a1cd-43c80b231413"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.25, 0.5, 0.75, 1.0]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "nstate = 4\n",
        "one_range = 1/nstate\n",
        "curr_range = one_range\n",
        "greyscale_threshold = []\n",
        "for i in range(nstate):\n",
        "  greyscale_threshold.append(curr_range)\n",
        "  curr_range += one_range\n",
        "print(greyscale_threshold)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RBalvrD9O2hS"
      },
      "outputs": [],
      "source": [
        "def soft_binarize_image(converted_img):\n",
        "    binarized = []\n",
        "    for i in converted_img:\n",
        "        binarized_row = np.zeros(len(i))\n",
        "        for j_ind, j in enumerate(i):\n",
        "          for state, state_val in enumerate(greyscale_threshold):\n",
        "            if j<=state_val:\n",
        "                binarized_row[j_ind] = state\n",
        "                break\n",
        "        binarized.append(binarized_row)\n",
        "\n",
        "    binarized = np.array(binarized)\n",
        "    return binarized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3oxgU4DVO-xZ",
        "outputId": "389552e6-4740-4d5e-91cb-347c839472fa"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 50000/50000 [05:07<00:00, 162.78it/s]\n",
            "100%|██████████| 10000/10000 [01:01<00:00, 161.33it/s]\n"
          ]
        }
      ],
      "source": [
        "processed_trainX=[]\n",
        "for im in tqdm(range(len(trainX))):\n",
        "    b = tf.image.rgb_to_grayscale(trainX[im])\n",
        "    b = soft_binarize_image(b.numpy())\n",
        "    processed_trainX.append(b)\n",
        "pX= np.asarray(processed_trainX)\n",
        "\n",
        "processed_testX=[]\n",
        "for im in tqdm(range(len(testX))):\n",
        "    b = tf.image.rgb_to_grayscale(testX[im])\n",
        "    b = soft_binarize_image(b.numpy())\n",
        "    processed_testX.append(b)\n",
        "pY= np.asarray(processed_testX)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "24d13uGyKbQX"
      },
      "outputs": [],
      "source": [
        "from keras.optimizers import RMSprop\n",
        "\n",
        "def vgg_custom_model():\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 1)))\n",
        "  model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "  model.add(MaxPooling2D((2, 2)))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "  model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "  #opt = SGD(lr=0.0001, momentum=0.9)\n",
        "  # opt = Adagrad(learning_rate=0.0001, initial_accumulator_value=0.1, epsilon=1e-03)\n",
        "  opt = RMSprop(learning_rate=0.0001, rho=0.9, momentum=0.1, epsilon=1e-03, centered=False)\n",
        "  model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "cmJ6kDIwKprt",
        "outputId": "959c55cd-595f-4336-d5c8-082a167d61fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "782/782 [==============================] - 7s 9ms/step - loss: 1.9160 - accuracy: 0.3124 - val_loss: 1.9141 - val_accuracy: 0.3019\n",
            "Epoch 2/40\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.6538 - accuracy: 0.4114 - val_loss: 1.6604 - val_accuracy: 0.4000\n",
            "Epoch 3/40\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.5340 - accuracy: 0.4571 - val_loss: 1.5520 - val_accuracy: 0.4527\n",
            "Epoch 4/40\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.4518 - accuracy: 0.4881 - val_loss: 1.4755 - val_accuracy: 0.4825\n",
            "Epoch 5/40\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.3819 - accuracy: 0.5156 - val_loss: 1.4825 - val_accuracy: 0.4850\n",
            "Epoch 6/40\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.3225 - accuracy: 0.5375 - val_loss: 1.6596 - val_accuracy: 0.4352\n",
            "Epoch 7/40\n",
            "782/782 [==============================] - 7s 8ms/step - loss: 1.2727 - accuracy: 0.5546 - val_loss: 1.3762 - val_accuracy: 0.5180\n",
            "Epoch 8/40\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.2235 - accuracy: 0.5729 - val_loss: 1.3078 - val_accuracy: 0.5362\n",
            "Epoch 9/40\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.1788 - accuracy: 0.5914 - val_loss: 1.3257 - val_accuracy: 0.5330\n",
            "Epoch 10/40\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 1.1381 - accuracy: 0.6063 - val_loss: 1.6016 - val_accuracy: 0.4689\n",
            "Epoch 11/40\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.1012 - accuracy: 0.6165 - val_loss: 1.3433 - val_accuracy: 0.5389\n",
            "Epoch 12/40\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.0643 - accuracy: 0.6308 - val_loss: 1.2970 - val_accuracy: 0.5585\n",
            "Epoch 13/40\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 1.0297 - accuracy: 0.6452 - val_loss: 1.3621 - val_accuracy: 0.5342\n",
            "Epoch 14/40\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.9946 - accuracy: 0.6582 - val_loss: 1.4468 - val_accuracy: 0.5200\n",
            "Epoch 15/40\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.9630 - accuracy: 0.6666 - val_loss: 1.3659 - val_accuracy: 0.5444\n",
            "Epoch 16/40\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.9292 - accuracy: 0.6804 - val_loss: 1.4887 - val_accuracy: 0.5340\n",
            "Epoch 17/40\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.8968 - accuracy: 0.6916 - val_loss: 1.3036 - val_accuracy: 0.5643\n",
            "Epoch 18/40\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.8636 - accuracy: 0.7019 - val_loss: 1.4014 - val_accuracy: 0.5406\n",
            "Epoch 19/40\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.8350 - accuracy: 0.7147 - val_loss: 1.4206 - val_accuracy: 0.5472\n",
            "Epoch 20/40\n",
            "575/782 [=====================>........] - ETA: 1s - loss: 0.8026 - accuracy: 0.7243"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-41dd4006496d>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvgg_custom_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1683\u001b[0m                         ):\n\u001b[1;32m   1684\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1685\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1686\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    924\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m       (concrete_function,\n\u001b[1;32m    142\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    144\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1755\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1756\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1757\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1758\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1759\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    382\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "model = vgg_custom_model()\n",
        "history = model.fit(pX, trainY, epochs=40, batch_size=64, validation_data=(pY, testY), verbose=1)\n",
        "loss, acc = model.evaluate(pY, testY, verbose=1)\n",
        "print(acc, loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "DBuhSC9bU2sv",
        "outputId": "5ba6d820-77b4-405d-83ca-01245fa35913"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fc87fb1a490>"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "pyplot.imshow(pX[4], cmap='gray')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "EPDq--gDVhjE",
        "outputId": "cdd24418-6bcc-428f-deb1-7e3dd98df201"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fc87f986100>"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "pyplot.imshow(pX[7], cmap='gray')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_m3wIcdZBKls"
      },
      "source": [
        "## Feed forward NN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SmNl7JPFQlmu",
        "outputId": "fcb9b5e4-09be-4709-c5d5-e0d236058492"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(32, 32)),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(10)\n",
        "])\n",
        "model.compile(optimizer=SGD(lr=0.001, momentum=0.9),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "# history = model.fit(pX, trainY, epochs=1, batch_size=32, validation_data=(pY, testY), verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5k1NCGdIM0G"
      },
      "source": [
        "### MNIST pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "znqjrMsWOvrw"
      },
      "outputs": [],
      "source": [
        "def load_dataset(name):\n",
        "  if name == \"mnist\":\n",
        "    (trainX, trainY), (testX, testY) = mnist.load_data()\n",
        "    trainX = trainX.reshape((trainX.shape[0], 28 * 28 * 1))\n",
        "    testX = testX.reshape((testX.shape[0], 28 * 28 * 1))\n",
        "    trainY = to_categorical(trainY)\n",
        "    testY = to_categorical(testY)\n",
        "  return trainX, trainY, testX, testY\n",
        "\n",
        "def prep_pixels(train, test):\n",
        "  train_norm = train.astype('float32')\n",
        "  test_norm = test.astype('float32')\n",
        "  train_norm = train_norm / 255.0\n",
        "  test_norm = test_norm / 255.0\n",
        "  return train_norm, test_norm\n",
        "\n",
        "trainX, trainY, testX, testY = load_dataset(\"mnist\")\n",
        "trainX, testX = prep_pixels(trainX, testX)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nEq1AS0aIiX8",
        "outputId": "fc0f522c-f4ee-4983-9792-d45c2bee0f0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 60000/60000 [03:04<00:00, 325.74it/s]\n",
            "100%|██████████| 10000/10000 [00:32<00:00, 310.35it/s]\n"
          ]
        }
      ],
      "source": [
        "greyscale_threshold = 0.2  # white is 1 ; 0.2 for mnist, 0.5 for cifar\n",
        "\n",
        "def binarize_image(converted_img):\n",
        "    binarized_row = np.zeros(len(converted_img))\n",
        "    for j_ind, j in enumerate(converted_img):\n",
        "        if j>=greyscale_threshold:\n",
        "            binarized_row[j_ind] = 1\n",
        "    binarized = np.array(binarized_row)\n",
        "    return binarized\n",
        "\n",
        "processed_trainX=[]\n",
        "for im in tqdm(range(len(trainX))):\n",
        "    b = trainX[im]\n",
        "    b = binarize_image(b)\n",
        "    c = np.reshape(b, (-1, 4))\n",
        "    im_res_inp = []\n",
        "    for i in c:\n",
        "        bit_pattern = ''.join([str(int(i[j])) for j in range(4)])\n",
        "        im_res_inp.append(vout_mapping[bit_pattern])\n",
        "    processed_trainX.append(im_res_inp)\n",
        "pX= np.asarray(processed_trainX)\n",
        "\n",
        "processed_testX=[]\n",
        "for im in tqdm(range(len(testX))):\n",
        "    b = testX[im]\n",
        "    b = binarize_image(b)\n",
        "    c = np.reshape(b, (-1, 4))\n",
        "    im_res_inp = []\n",
        "    for i in c:\n",
        "        bit_pattern = ''.join([str(int(i[j])) for j in range(4)])\n",
        "        im_res_inp.append(vout_mapping[bit_pattern])\n",
        "    processed_testX.append(im_res_inp)\n",
        "pY= np.asarray(processed_testX)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFl6GgojLXde",
        "outputId": "77f42d2e-0b6d-4fcb-a630-a1a34311793b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 784)\n",
            "(60000, 196)\n",
            "(10000, 196)\n"
          ]
        }
      ],
      "source": [
        "# trainX[1]\n",
        "print(trainX.shape)\n",
        "\n",
        "# pX[1]\n",
        "print(pX.shape)\n",
        "print(pY.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Mx0Y0PoKgT6"
      },
      "source": [
        "1 layer FFN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "izVxJ9_jV2JH"
      },
      "outputs": [],
      "source": [
        "from keras.optimizers import Adam\n",
        "\n",
        "# Check input shape when changing dataset\n",
        "def ann_custom_model_1(lr, mom):\n",
        "  model = Sequential()\n",
        "  model.add(Dense(98, input_shape=(196,), activation=\"relu\", kernel_initializer='he_normal'))\n",
        "  model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "  # opt = SGD(lr=lr, momentum=mom)\n",
        "  opt = Adam(lr=lr)\n",
        "  model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzRm-MS9BQFT",
        "outputId": "cc98d9f5-ec08-4d01-bee2-c5c1d411fc50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 2.1147 - accuracy: 0.8608 - val_loss: 0.6323 - val_accuracy: 0.9041\n",
            "Epoch 2/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.4321 - accuracy: 0.9217 - val_loss: 0.3286 - val_accuracy: 0.9292\n",
            "Epoch 3/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2440 - accuracy: 0.9379 - val_loss: 0.2472 - val_accuracy: 0.9373\n",
            "Epoch 4/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1886 - accuracy: 0.9467 - val_loss: 0.2505 - val_accuracy: 0.9329\n",
            "Epoch 5/50\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1684 - accuracy: 0.9516 - val_loss: 0.1942 - val_accuracy: 0.9464\n",
            "Epoch 6/50\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1560 - accuracy: 0.9555 - val_loss: 0.2031 - val_accuracy: 0.9476\n",
            "Epoch 7/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1396 - accuracy: 0.9593 - val_loss: 0.2042 - val_accuracy: 0.9457\n",
            "Epoch 8/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1353 - accuracy: 0.9606 - val_loss: 0.1861 - val_accuracy: 0.9572\n",
            "Epoch 9/50\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1280 - accuracy: 0.9628 - val_loss: 0.1957 - val_accuracy: 0.9548\n",
            "Epoch 10/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1232 - accuracy: 0.9641 - val_loss: 0.1710 - val_accuracy: 0.9584\n",
            "Epoch 11/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1159 - accuracy: 0.9660 - val_loss: 0.1803 - val_accuracy: 0.9580\n",
            "Epoch 12/50\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1194 - accuracy: 0.9652 - val_loss: 0.1861 - val_accuracy: 0.9592\n",
            "Epoch 13/50\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1101 - accuracy: 0.9681 - val_loss: 0.1805 - val_accuracy: 0.9601\n",
            "Epoch 14/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1096 - accuracy: 0.9684 - val_loss: 0.1880 - val_accuracy: 0.9596\n",
            "Epoch 15/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1085 - accuracy: 0.9684 - val_loss: 0.1772 - val_accuracy: 0.9594\n",
            "Epoch 16/50\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1038 - accuracy: 0.9704 - val_loss: 0.2014 - val_accuracy: 0.9525\n",
            "Epoch 17/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1017 - accuracy: 0.9712 - val_loss: 0.1857 - val_accuracy: 0.9621\n",
            "Epoch 18/50\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1021 - accuracy: 0.9711 - val_loss: 0.2048 - val_accuracy: 0.9559\n",
            "Epoch 19/50\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.1008 - accuracy: 0.9717 - val_loss: 0.1978 - val_accuracy: 0.9589\n",
            "Epoch 20/50\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0981 - accuracy: 0.9722 - val_loss: 0.2249 - val_accuracy: 0.9570\n",
            "Epoch 21/50\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0940 - accuracy: 0.9738 - val_loss: 0.2211 - val_accuracy: 0.9580\n",
            "Epoch 22/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0947 - accuracy: 0.9730 - val_loss: 0.2037 - val_accuracy: 0.9606\n",
            "Epoch 23/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0940 - accuracy: 0.9730 - val_loss: 0.2270 - val_accuracy: 0.9574\n",
            "Epoch 24/50\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0914 - accuracy: 0.9745 - val_loss: 0.2271 - val_accuracy: 0.9598\n",
            "Epoch 25/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0921 - accuracy: 0.9747 - val_loss: 0.2260 - val_accuracy: 0.9611\n",
            "Epoch 26/50\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0882 - accuracy: 0.9750 - val_loss: 0.2361 - val_accuracy: 0.9586\n",
            "Epoch 27/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0915 - accuracy: 0.9747 - val_loss: 0.2356 - val_accuracy: 0.9607\n",
            "Epoch 28/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0863 - accuracy: 0.9756 - val_loss: 0.2449 - val_accuracy: 0.9595\n",
            "Epoch 29/50\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0854 - accuracy: 0.9765 - val_loss: 0.2550 - val_accuracy: 0.9578\n",
            "Epoch 30/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0843 - accuracy: 0.9762 - val_loss: 0.2371 - val_accuracy: 0.9592\n",
            "Epoch 31/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0881 - accuracy: 0.9760 - val_loss: 0.2682 - val_accuracy: 0.9587\n",
            "Epoch 32/50\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0838 - accuracy: 0.9768 - val_loss: 0.2508 - val_accuracy: 0.9599\n",
            "Epoch 33/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0813 - accuracy: 0.9768 - val_loss: 0.2519 - val_accuracy: 0.9628\n",
            "Epoch 34/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0878 - accuracy: 0.9763 - val_loss: 0.3055 - val_accuracy: 0.9542\n",
            "Epoch 35/50\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0798 - accuracy: 0.9778 - val_loss: 0.3419 - val_accuracy: 0.9561\n",
            "Epoch 36/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0834 - accuracy: 0.9786 - val_loss: 0.3160 - val_accuracy: 0.9593\n",
            "Epoch 37/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0790 - accuracy: 0.9786 - val_loss: 0.2766 - val_accuracy: 0.9613\n",
            "Epoch 38/50\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0793 - accuracy: 0.9789 - val_loss: 0.2658 - val_accuracy: 0.9601\n",
            "Epoch 39/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0798 - accuracy: 0.9786 - val_loss: 0.2741 - val_accuracy: 0.9598\n",
            "Epoch 40/50\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0800 - accuracy: 0.9785 - val_loss: 0.2912 - val_accuracy: 0.9609\n",
            "Epoch 41/50\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0769 - accuracy: 0.9797 - val_loss: 0.2763 - val_accuracy: 0.9630\n",
            "Epoch 42/50\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0797 - accuracy: 0.9793 - val_loss: 0.3084 - val_accuracy: 0.9603\n",
            "Epoch 43/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0776 - accuracy: 0.9786 - val_loss: 0.2766 - val_accuracy: 0.9635\n",
            "Epoch 44/50\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0755 - accuracy: 0.9799 - val_loss: 0.3222 - val_accuracy: 0.9572\n",
            "Epoch 45/50\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0763 - accuracy: 0.9794 - val_loss: 0.3032 - val_accuracy: 0.9596\n",
            "Epoch 46/50\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0757 - accuracy: 0.9807 - val_loss: 0.3123 - val_accuracy: 0.9620\n",
            "Epoch 47/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0754 - accuracy: 0.9804 - val_loss: 0.3156 - val_accuracy: 0.9607\n",
            "Epoch 48/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0730 - accuracy: 0.9814 - val_loss: 0.3401 - val_accuracy: 0.9595\n",
            "Epoch 49/50\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0737 - accuracy: 0.9806 - val_loss: 0.3684 - val_accuracy: 0.9612\n",
            "Epoch 50/50\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0746 - accuracy: 0.9804 - val_loss: 0.3435 - val_accuracy: 0.9586\n"
          ]
        }
      ],
      "source": [
        "model1 = ann_custom_model_1(0.001,0.9)\n",
        "# history = model1.fit(trainX, trainY, epochs=20, batch_size=32, validation_data=(testX, testY), verbose=1)\n",
        "history = model1.fit(pX, trainY, epochs=50, batch_size=32, validation_data=(pY, testY), verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "UFyQOC4PQ6dZ"
      },
      "outputs": [],
      "source": [
        "def baseline_dense(lr, mom):\n",
        "  model = Sequential()\n",
        "  model.add(Dense(128, input_shape=(784,), activation=\"relu\", kernel_initializer='he_uniform'))\n",
        "  # model.add(Dense(10, input_shape=(196,), activation=\"softmax\", kernel_initializer='he_uniform'))\n",
        "  model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "  opt = SGD(lr=lr, momentum=mom)\n",
        "  model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QbAkBkVMw3Po"
      },
      "outputs": [],
      "source": [
        "model1 = baseline_dense(0.1,0.9)\n",
        "history = model1.fit(trainX, trainY, epochs=20, batch_size=32, validation_data=(testX, testY), verbose=1)\n",
        "# history = model1.fit(pX, trainY, epochs=20, batch_size=32, validation_data=(pY, testY), verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYKNjqTBKl43"
      },
      "source": [
        "2 layer FFN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-momoc0gKnEQ"
      },
      "outputs": [],
      "source": [
        "# Check input shape when changing dataset\n",
        "def ann_custom_model_2(lr, mom):\n",
        "  model = Sequential()\n",
        "  model.add(Dense(98, input_shape=(196,), activation=\"sigmoid\", kernel_initializer='he_uniform'))\n",
        "  # model.add(Dropout(0.5))\n",
        "  model.add(Dense(24, activation=\"sigmoid\", kernel_initializer='he_uniform'))\n",
        "  model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "  opt = SGD(lr=lr, momentum=mom)\n",
        "  model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6llMwoiKqBP",
        "outputId": "7ca47b5b-dd64-4cd8-c697-a3374f2475ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 1.7340 - accuracy: 0.6044 - val_loss: 1.2178 - val_accuracy: 0.7770\n",
            "Epoch 2/20\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.9383 - accuracy: 0.8163 - val_loss: 0.7175 - val_accuracy: 0.8548\n",
            "Epoch 3/20\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.6183 - accuracy: 0.8651 - val_loss: 0.5245 - val_accuracy: 0.8779\n",
            "Epoch 4/20\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.4834 - accuracy: 0.8841 - val_loss: 0.4344 - val_accuracy: 0.8921\n",
            "Epoch 5/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4125 - accuracy: 0.8940 - val_loss: 0.3856 - val_accuracy: 0.8979\n",
            "Epoch 6/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3709 - accuracy: 0.9028 - val_loss: 0.3468 - val_accuracy: 0.9094\n",
            "Epoch 7/20\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3404 - accuracy: 0.9077 - val_loss: 0.3215 - val_accuracy: 0.9122\n",
            "Epoch 8/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3165 - accuracy: 0.9123 - val_loss: 0.3125 - val_accuracy: 0.9139\n",
            "Epoch 9/20\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2994 - accuracy: 0.9163 - val_loss: 0.2938 - val_accuracy: 0.9177\n",
            "Epoch 10/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2828 - accuracy: 0.9214 - val_loss: 0.2734 - val_accuracy: 0.9227\n",
            "Epoch 11/20\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2686 - accuracy: 0.9253 - val_loss: 0.2712 - val_accuracy: 0.9236\n",
            "Epoch 12/20\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2604 - accuracy: 0.9273 - val_loss: 0.2627 - val_accuracy: 0.9228\n",
            "Epoch 13/20\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2483 - accuracy: 0.9292 - val_loss: 0.2497 - val_accuracy: 0.9303\n",
            "Epoch 14/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2394 - accuracy: 0.9321 - val_loss: 0.2413 - val_accuracy: 0.9305\n",
            "Epoch 15/20\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2322 - accuracy: 0.9338 - val_loss: 0.2427 - val_accuracy: 0.9295\n",
            "Epoch 16/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2245 - accuracy: 0.9351 - val_loss: 0.2362 - val_accuracy: 0.9294\n",
            "Epoch 17/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2188 - accuracy: 0.9377 - val_loss: 0.2328 - val_accuracy: 0.9312\n",
            "Epoch 18/20\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2130 - accuracy: 0.9384 - val_loss: 0.2154 - val_accuracy: 0.9369\n",
            "Epoch 19/20\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2093 - accuracy: 0.9398 - val_loss: 0.2159 - val_accuracy: 0.9371\n",
            "Epoch 20/20\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2031 - accuracy: 0.9417 - val_loss: 0.2164 - val_accuracy: 0.9355\n"
          ]
        }
      ],
      "source": [
        "model2 = ann_custom_model_2(0.001,0.9)\n",
        "# history = model2.fit(trainX, trainY, epochs=20, batch_size=32, validation_data=(testX, testY), verbose=1)\n",
        "history = model2.fit(pX, trainY, epochs=20, batch_size=32, validation_data=(pY, testY), verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qdsPNsGrMhJN",
        "outputId": "1b50970e-dc46-4799-a4ba-e5bbb1d816a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_14 (Dense)            (None, 14, 28)            420       \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 14, 10)            290       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 710\n",
            "Trainable params: 710\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Combine N-bit analysis for MNIST"
      ],
      "metadata": {
        "id": "YrwgbTC-d13h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "analysis_df = pd.DataFrame(columns = ['config', 'val_accuracy', 'val_loss', 'history_val_acc', 'history_val_loss', 'history_train_acc', 'history_train_loss'])\n",
        "\n",
        "nbits = [4,5,6,7,8]\n",
        "for nb in nbits:\n",
        "  readout_mapping = pd.read_excel('Extracted/'+str(nb)+'-bit.xlsx')\n",
        "  for p in readout_mapping.columns[1:]:\n",
        "    config = str(nb)+\"bit\"+str(int(p*100))+\"p\"\n",
        "    print(\"Processing \"+str(config))\n",
        "    vout = list(readout_mapping[p])\n",
        "    vout_mapping = {}\n",
        "    vout_mapping['{0:04b}'.format(0)] = 0.000\n",
        "    for v_ind, v in enumerate(vout, 1):\n",
        "        vout_mapping['{0:04b}'.format(v_ind)] = v\n",
        "    print(vout_mapping)\n",
        "\n",
        "    # transform input\n",
        "    processed_trainX=[]\n",
        "    for im in tqdm(range(len(trainX))):\n",
        "        b = trainX[im]\n",
        "        b = binarize_image(b)\n",
        "        c = np.reshape(b, (-1, 4))\n",
        "        im_res_inp = []\n",
        "        for i in c:\n",
        "            bit_pattern = ''.join([str(int(i[j])) for j in range(4)])\n",
        "            im_res_inp.append(vout_mapping[bit_pattern])\n",
        "        processed_trainX.append(im_res_inp)\n",
        "    pX= np.asarray(processed_trainX)\n",
        "\n",
        "    processed_testX=[]\n",
        "    for im in tqdm(range(len(testX))):\n",
        "        b = testX[im]\n",
        "        b = binarize_image(b)\n",
        "        c = np.reshape(b, (-1, 4))\n",
        "        im_res_inp = []\n",
        "        for i in c:\n",
        "            bit_pattern = ''.join([str(int(i[j])) for j in range(4)])\n",
        "            im_res_inp.append(vout_mapping[bit_pattern])\n",
        "        processed_testX.append(im_res_inp)\n",
        "    pY= np.asarray(processed_testX)\n",
        "\n",
        "    # train model\n",
        "    model1 = ann_custom_model_1(0.001,0.9)\n",
        "    history = model1.fit(pX, trainY, epochs=30, batch_size=32, validation_data=(pY, testY), verbose=0)\n",
        "    analysis_df = analysis_df.append({\n",
        "                  \"config\": config,\n",
        "                  \"val_accuracy\": max(history.history['val_accuracy']),\n",
        "                  \"val_loss\":  min(history.history['val_loss']),\n",
        "                  \"history_val_acc\": history.history['val_accuracy'],\n",
        "                  \"history_val_loss\": history.history['val_loss'],\n",
        "                  \"history_train_acc\": history.history['accuracy'],\n",
        "                  \"history_train_loss\": history.history['loss']\n",
        "              }, ignore_index=True)\n",
        "\n",
        "    print(analysis_df.head())\n",
        "analysis_df.to_csv('nbit_analysis.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5D2VyBnlbte",
        "outputId": "be7fd799-3f91-460d-fefa-34cbf8c01c19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing 4bit30p\n",
            "{'0000': 0.0, '0001': 20.385, '0010': 18.694, '0011': 52.553999999999995, '0100': 16.016, '0101': 41.516, '0110': 42.89, '0111': 73.044, '1000': 13.67, '1001': 39.264, '1010': 34.485, '1011': 65.988, '1100': 35.852000000000004, '1101': 59.483000000000004, '1110': 60.071, '1111': 87.563}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 60000/60000 [02:11<00:00, 455.65it/s]\n",
            "100%|██████████| 10000/10000 [00:21<00:00, 455.08it/s]\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "<ipython-input-76-dc9983b947f2>:44: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  analysis_df = analysis_df.append({\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    config  val_accuracy  val_loss  \\\n",
            "0  4bit30p        0.9659  0.171998   \n",
            "\n",
            "                                     history_val_acc  \\\n",
            "0  [0.9089999794960022, 0.9362000226974487, 0.937...   \n",
            "\n",
            "                                    history_val_loss  \\\n",
            "0  [0.5961990356445312, 0.2810992896556854, 0.243...   \n",
            "\n",
            "                                   history_train_acc  \\\n",
            "0  [0.8606666922569275, 0.9236666560173035, 0.940...   \n",
            "\n",
            "                                  history_train_loss  \n",
            "0  [1.7612853050231934, 0.3980737030506134, 0.232...  \n",
            "Processing 4bit40p\n",
            "{'0000': 0.0, '0001': 43.922999999999995, '0010': 35.285, '0011': 82.902, '0100': 29.244, '0101': 71.2, '0110': 66.667, '0111': 105.765, '1000': 24.908, '1001': 68.086, '1010': 58.504, '1011': 100.45400000000001, '1100': 55.891000000000005, '1101': 93.439, '1110': 86.708, '1111': 120.542}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 60000/60000 [02:08<00:00, 465.39it/s]\n",
            "100%|██████████| 10000/10000 [00:21<00:00, 458.48it/s]\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "<ipython-input-76-dc9983b947f2>:44: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  analysis_df = analysis_df.append({\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    config  val_accuracy  val_loss  \\\n",
            "0  4bit30p        0.9659  0.171998   \n",
            "1  4bit40p        0.9629  0.169417   \n",
            "\n",
            "                                     history_val_acc  \\\n",
            "0  [0.9089999794960022, 0.9362000226974487, 0.937...   \n",
            "1  [0.9169999957084656, 0.9271000027656555, 0.942...   \n",
            "\n",
            "                                    history_val_loss  \\\n",
            "0  [0.5961990356445312, 0.2810992896556854, 0.243...   \n",
            "1  [0.7165398597717285, 0.40322554111480713, 0.24...   \n",
            "\n",
            "                                   history_train_acc  \\\n",
            "0  [0.8606666922569275, 0.9236666560173035, 0.940...   \n",
            "1  [0.8648666739463806, 0.9231166839599609, 0.935...   \n",
            "\n",
            "                                  history_train_loss  \n",
            "0  [1.7612853050231934, 0.3980737030506134, 0.232...  \n",
            "1  [2.221606969833374, 0.5513030886650085, 0.2889...  \n",
            "Processing 4bit50p\n",
            "{'0000': 0.0, '0001': 61.779, '0010': 49.404999999999994, '0011': 105.034, '0100': 40.702000000000005, '0101': 94.731, '0110': 84.259, '0111': 126.531, '1000': 34.81, '1001': 91.08099999999999, '1010': 77.376, '1011': 123.47800000000001, '1100': 70.54, '1101': 116.193, '1110': 103.379, '1111': 139.001}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 60000/60000 [02:08<00:00, 466.54it/s]\n",
            "100%|██████████| 10000/10000 [00:21<00:00, 466.04it/s]\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "<ipython-input-76-dc9983b947f2>:44: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  analysis_df = analysis_df.append({\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    config  val_accuracy  val_loss  \\\n",
            "0  4bit30p        0.9659  0.171998   \n",
            "1  4bit40p        0.9629  0.169417   \n",
            "2  4bit50p        0.9618  0.180078   \n",
            "\n",
            "                                     history_val_acc  \\\n",
            "0  [0.9089999794960022, 0.9362000226974487, 0.937...   \n",
            "1  [0.9169999957084656, 0.9271000027656555, 0.942...   \n",
            "2  [0.9168999791145325, 0.9251000285148621, 0.927...   \n",
            "\n",
            "                                    history_val_loss  \\\n",
            "0  [0.5961990356445312, 0.2810992896556854, 0.243...   \n",
            "1  [0.7165398597717285, 0.40322554111480713, 0.24...   \n",
            "2  [1.0729739665985107, 0.5806041359901428, 0.340...   \n",
            "\n",
            "                                   history_train_acc  \\\n",
            "0  [0.8606666922569275, 0.9236666560173035, 0.940...   \n",
            "1  [0.8648666739463806, 0.9231166839599609, 0.935...   \n",
            "2  [0.8630499839782715, 0.9223499894142151, 0.934...   \n",
            "\n",
            "                                  history_train_loss  \n",
            "0  [1.7612853050231934, 0.3980737030506134, 0.232...  \n",
            "1  [2.221606969833374, 0.5513030886650085, 0.2889...  \n",
            "2  [3.1047916412353516, 0.7570062279701233, 0.389...  \n",
            "Processing 4bit60p\n",
            "{'0000': 0.0, '0001': 77.105, '0010': 61.161, '0011': 120.577, '0100': 50.776, '0101': 112.138, '0110': 96.652, '0111': 139.125, '1000': 43.178000000000004, '1001': 108.88000000000001, '1010': 91.482, '1011': 138.127, '1100': 81.172, '1101': 131.747, '1110': 114.026, '1111': 149.923}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 60000/60000 [02:10<00:00, 461.49it/s]\n",
            "100%|██████████| 10000/10000 [00:20<00:00, 485.83it/s]\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "<ipython-input-76-dc9983b947f2>:44: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  analysis_df = analysis_df.append({\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    config  val_accuracy  val_loss  \\\n",
            "0  4bit30p        0.9659  0.171998   \n",
            "1  4bit40p        0.9629  0.169417   \n",
            "2  4bit50p        0.9618  0.180078   \n",
            "3  4bit60p        0.9604  0.207152   \n",
            "\n",
            "                                     history_val_acc  \\\n",
            "0  [0.9089999794960022, 0.9362000226974487, 0.937...   \n",
            "1  [0.9169999957084656, 0.9271000027656555, 0.942...   \n",
            "2  [0.9168999791145325, 0.9251000285148621, 0.927...   \n",
            "3  [0.9065999984741211, 0.9140999913215637, 0.925...   \n",
            "\n",
            "                                    history_val_loss  \\\n",
            "0  [0.5961990356445312, 0.2810992896556854, 0.243...   \n",
            "1  [0.7165398597717285, 0.40322554111480713, 0.24...   \n",
            "2  [1.0729739665985107, 0.5806041359901428, 0.340...   \n",
            "3  [0.7896328568458557, 0.39091727137565613, 0.29...   \n",
            "\n",
            "                                   history_train_acc  \\\n",
            "0  [0.8606666922569275, 0.9236666560173035, 0.940...   \n",
            "1  [0.8648666739463806, 0.9231166839599609, 0.935...   \n",
            "2  [0.8630499839782715, 0.9223499894142151, 0.934...   \n",
            "3  [0.861466646194458, 0.9171666502952576, 0.9309...   \n",
            "\n",
            "                                  history_train_loss  \n",
            "0  [1.7612853050231934, 0.3980737030506134, 0.232...  \n",
            "1  [2.221606969833374, 0.5513030886650085, 0.2889...  \n",
            "2  [3.1047916412353516, 0.7570062279701233, 0.389...  \n",
            "3  [2.903733968734741, 0.5294719934463501, 0.2888...  \n",
            "Processing 4bit70p\n",
            "{'0000': 0.0, '0001': 90.162, '0010': 71.154, '0011': 130.879, '0100': 58.739, '0101': 125.13199999999999, '0110': 105.343, '0111': 147.112, '1000': 50.34, '1001': 122.134, '1010': 102.0, '1011': 147.491, '1100': 88.446, '1101': 142.05300000000003, '1110': 120.80799999999999, '1111': 156.584}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 60000/60000 [02:09<00:00, 464.28it/s]\n",
            "100%|██████████| 10000/10000 [00:21<00:00, 461.77it/s]\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "<ipython-input-76-dc9983b947f2>:44: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  analysis_df = analysis_df.append({\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    config  val_accuracy  val_loss  \\\n",
            "0  4bit30p        0.9659  0.171998   \n",
            "1  4bit40p        0.9629  0.169417   \n",
            "2  4bit50p        0.9618  0.180078   \n",
            "3  4bit60p        0.9604  0.207152   \n",
            "4  4bit70p        0.9573  0.214989   \n",
            "\n",
            "                                     history_val_acc  \\\n",
            "0  [0.9089999794960022, 0.9362000226974487, 0.937...   \n",
            "1  [0.9169999957084656, 0.9271000027656555, 0.942...   \n",
            "2  [0.9168999791145325, 0.9251000285148621, 0.927...   \n",
            "3  [0.9065999984741211, 0.9140999913215637, 0.925...   \n",
            "4  [0.9067000150680542, 0.9178000092506409, 0.923...   \n",
            "\n",
            "                                    history_val_loss  \\\n",
            "0  [0.5961990356445312, 0.2810992896556854, 0.243...   \n",
            "1  [0.7165398597717285, 0.40322554111480713, 0.24...   \n",
            "2  [1.0729739665985107, 0.5806041359901428, 0.340...   \n",
            "3  [0.7896328568458557, 0.39091727137565613, 0.29...   \n",
            "4  [0.8529000282287598, 0.3971153795719147, 0.286...   \n",
            "\n",
            "                                   history_train_acc  \\\n",
            "0  [0.8606666922569275, 0.9236666560173035, 0.940...   \n",
            "1  [0.8648666739463806, 0.9231166839599609, 0.935...   \n",
            "2  [0.8630499839782715, 0.9223499894142151, 0.934...   \n",
            "3  [0.861466646194458, 0.9171666502952576, 0.9309...   \n",
            "4  [0.8608499765396118, 0.9120166897773743, 0.928...   \n",
            "\n",
            "                                  history_train_loss  \n",
            "0  [1.7612853050231934, 0.3980737030506134, 0.232...  \n",
            "1  [2.221606969833374, 0.5513030886650085, 0.2889...  \n",
            "2  [3.1047916412353516, 0.7570062279701233, 0.389...  \n",
            "3  [2.903733968734741, 0.5294719934463501, 0.2888...  \n",
            "4  [3.1085143089294434, 0.5468863248825073, 0.286...  \n",
            "Processing 5bit30p\n",
            "{'0000': 0.0, '0001': 23.317, '0010': 19.406, '0011': 53.212, '0100': 16.02, '0101': 41.596000000000004, '0110': 43.28, '0111': 73.77300000000001, '1000': 13.854, '1001': 39.607000000000006, '1010': 34.793, '1011': 66.60199999999999, '1100': 36.183, '1101': 60.239000000000004, '1110': 60.367, '1111': 88.12, '10000': 12.125, '10001': 37.979, '10010': 33.010999999999996, '10011': 65.379, '10100': 29.387, '10101': 54.171, '10110': 54.947, '10111': 83.596, '11000': 31.298, '11001': 55.684999999999995, '11010': 50.66, '11011': 80.66, '11100': 50.916000000000004, '11101': 73.866, '11110': 73.272, '11111': 99.26}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 60000/60000 [02:09<00:00, 464.17it/s]\n",
            "100%|██████████| 10000/10000 [00:21<00:00, 454.88it/s]\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "<ipython-input-76-dc9983b947f2>:44: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  analysis_df = analysis_df.append({\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    config  val_accuracy  val_loss  \\\n",
            "0  4bit30p        0.9659  0.171998   \n",
            "1  4bit40p        0.9629  0.169417   \n",
            "2  4bit50p        0.9618  0.180078   \n",
            "3  4bit60p        0.9604  0.207152   \n",
            "4  4bit70p        0.9573  0.214989   \n",
            "\n",
            "                                     history_val_acc  \\\n",
            "0  [0.9089999794960022, 0.9362000226974487, 0.937...   \n",
            "1  [0.9169999957084656, 0.9271000027656555, 0.942...   \n",
            "2  [0.9168999791145325, 0.9251000285148621, 0.927...   \n",
            "3  [0.9065999984741211, 0.9140999913215637, 0.925...   \n",
            "4  [0.9067000150680542, 0.9178000092506409, 0.923...   \n",
            "\n",
            "                                    history_val_loss  \\\n",
            "0  [0.5961990356445312, 0.2810992896556854, 0.243...   \n",
            "1  [0.7165398597717285, 0.40322554111480713, 0.24...   \n",
            "2  [1.0729739665985107, 0.5806041359901428, 0.340...   \n",
            "3  [0.7896328568458557, 0.39091727137565613, 0.29...   \n",
            "4  [0.8529000282287598, 0.3971153795719147, 0.286...   \n",
            "\n",
            "                                   history_train_acc  \\\n",
            "0  [0.8606666922569275, 0.9236666560173035, 0.940...   \n",
            "1  [0.8648666739463806, 0.9231166839599609, 0.935...   \n",
            "2  [0.8630499839782715, 0.9223499894142151, 0.934...   \n",
            "3  [0.861466646194458, 0.9171666502952576, 0.9309...   \n",
            "4  [0.8608499765396118, 0.9120166897773743, 0.928...   \n",
            "\n",
            "                                  history_train_loss  \n",
            "0  [1.7612853050231934, 0.3980737030506134, 0.232...  \n",
            "1  [2.221606969833374, 0.5513030886650085, 0.2889...  \n",
            "2  [3.1047916412353516, 0.7570062279701233, 0.389...  \n",
            "3  [2.903733968734741, 0.5294719934463501, 0.2888...  \n",
            "4  [3.1085143089294434, 0.5468863248825073, 0.286...  \n",
            "Processing 5bit40p\n",
            "{'0000': 0.0, '0001': 44.436, '0010': 35.693000000000005, '0011': 83.83699999999999, '0100': 29.544999999999998, '0101': 72.24600000000001, '0110': 67.58, '0111': 107.003, '1000': 25.187, '1001': 68.709, '1010': 59.21, '1011': 101.639, '1100': 56.402, '1101': 94.327, '1110': 87.20700000000001, '1111': 121.296, '10000': 22.203, '10001': 66.395, '10010': 56.789, '10011': 100.17099999999999, '10100': 50.019, '10101': 89.17899999999999, '10110': 83.15599999999999, '10111': 118.697, '11000': 48.730999999999995, '11001': 88.67999999999999, '11010': 78.545, '11011': 116.373, '11100': 73.64800000000001, '11101': 107.979, '11110': 100.038, '11111': 131.189}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 60000/60000 [02:09<00:00, 461.99it/s]\n",
            "100%|██████████| 10000/10000 [00:21<00:00, 457.48it/s]\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "<ipython-input-76-dc9983b947f2>:44: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  analysis_df = analysis_df.append({\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    config  val_accuracy  val_loss  \\\n",
            "0  4bit30p        0.9659  0.171998   \n",
            "1  4bit40p        0.9629  0.169417   \n",
            "2  4bit50p        0.9618  0.180078   \n",
            "3  4bit60p        0.9604  0.207152   \n",
            "4  4bit70p        0.9573  0.214989   \n",
            "\n",
            "                                     history_val_acc  \\\n",
            "0  [0.9089999794960022, 0.9362000226974487, 0.937...   \n",
            "1  [0.9169999957084656, 0.9271000027656555, 0.942...   \n",
            "2  [0.9168999791145325, 0.9251000285148621, 0.927...   \n",
            "3  [0.9065999984741211, 0.9140999913215637, 0.925...   \n",
            "4  [0.9067000150680542, 0.9178000092506409, 0.923...   \n",
            "\n",
            "                                    history_val_loss  \\\n",
            "0  [0.5961990356445312, 0.2810992896556854, 0.243...   \n",
            "1  [0.7165398597717285, 0.40322554111480713, 0.24...   \n",
            "2  [1.0729739665985107, 0.5806041359901428, 0.340...   \n",
            "3  [0.7896328568458557, 0.39091727137565613, 0.29...   \n",
            "4  [0.8529000282287598, 0.3971153795719147, 0.286...   \n",
            "\n",
            "                                   history_train_acc  \\\n",
            "0  [0.8606666922569275, 0.9236666560173035, 0.940...   \n",
            "1  [0.8648666739463806, 0.9231166839599609, 0.935...   \n",
            "2  [0.8630499839782715, 0.9223499894142151, 0.934...   \n",
            "3  [0.861466646194458, 0.9171666502952576, 0.9309...   \n",
            "4  [0.8608499765396118, 0.9120166897773743, 0.928...   \n",
            "\n",
            "                                  history_train_loss  \n",
            "0  [1.7612853050231934, 0.3980737030506134, 0.232...  \n",
            "1  [2.221606969833374, 0.5513030886650085, 0.2889...  \n",
            "2  [3.1047916412353516, 0.7570062279701233, 0.389...  \n",
            "3  [2.903733968734741, 0.5294719934463501, 0.2888...  \n",
            "4  [3.1085143089294434, 0.5468863248825073, 0.286...  \n",
            "Processing 5bit50p\n",
            "{'0000': 0.0, '0001': 62.486, '0010': 49.844, '0011': 105.99799999999999, '0100': 41.172, '0101': 95.624, '0110': 84.987, '0111': 127.496, '1000': 35.312000000000005, '1001': 91.949, '1010': 78.091, '1011': 124.409, '1100': 71.15599999999999, '1101': 116.866, '1110': 103.852, '1111': 139.61399999999998, '10000': 30.926, '10001': 89.28800000000001, '10010': 75.556, '10011': 123.186, '10100': 65.833, '10101': 113.682, '10110': 101.84400000000001, '10111': 138.934, '11000': 61.233000000000004, '11001': 111.241, '11010': 96.474, '11011': 136.73, '11100': 87.624, '11101': 128.674, '11110': 115.18, '11111': 147.631}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 60000/60000 [02:08<00:00, 468.67it/s]\n",
            "100%|██████████| 10000/10000 [00:21<00:00, 456.17it/s]\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "<ipython-input-76-dc9983b947f2>:44: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  analysis_df = analysis_df.append({\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    config  val_accuracy  val_loss  \\\n",
            "0  4bit30p        0.9659  0.171998   \n",
            "1  4bit40p        0.9629  0.169417   \n",
            "2  4bit50p        0.9618  0.180078   \n",
            "3  4bit60p        0.9604  0.207152   \n",
            "4  4bit70p        0.9573  0.214989   \n",
            "\n",
            "                                     history_val_acc  \\\n",
            "0  [0.9089999794960022, 0.9362000226974487, 0.937...   \n",
            "1  [0.9169999957084656, 0.9271000027656555, 0.942...   \n",
            "2  [0.9168999791145325, 0.9251000285148621, 0.927...   \n",
            "3  [0.9065999984741211, 0.9140999913215637, 0.925...   \n",
            "4  [0.9067000150680542, 0.9178000092506409, 0.923...   \n",
            "\n",
            "                                    history_val_loss  \\\n",
            "0  [0.5961990356445312, 0.2810992896556854, 0.243...   \n",
            "1  [0.7165398597717285, 0.40322554111480713, 0.24...   \n",
            "2  [1.0729739665985107, 0.5806041359901428, 0.340...   \n",
            "3  [0.7896328568458557, 0.39091727137565613, 0.29...   \n",
            "4  [0.8529000282287598, 0.3971153795719147, 0.286...   \n",
            "\n",
            "                                   history_train_acc  \\\n",
            "0  [0.8606666922569275, 0.9236666560173035, 0.940...   \n",
            "1  [0.8648666739463806, 0.9231166839599609, 0.935...   \n",
            "2  [0.8630499839782715, 0.9223499894142151, 0.934...   \n",
            "3  [0.861466646194458, 0.9171666502952576, 0.9309...   \n",
            "4  [0.8608499765396118, 0.9120166897773743, 0.928...   \n",
            "\n",
            "                                  history_train_loss  \n",
            "0  [1.7612853050231934, 0.3980737030506134, 0.232...  \n",
            "1  [2.221606969833374, 0.5513030886650085, 0.2889...  \n",
            "2  [3.1047916412353516, 0.7570062279701233, 0.389...  \n",
            "3  [2.903733968734741, 0.5294719934463501, 0.2888...  \n",
            "4  [3.1085143089294434, 0.5468863248825073, 0.286...  \n",
            "Processing 5bit60p\n",
            "{'0000': 0.0, '0001': 77.429, '0010': 61.333, '0011': 120.615, '0100': 50.691, '0101': 112.426, '0110': 96.712, '0111': 138.965, '1000': 43.086, '1001': 108.63000000000001, '1010': 91.25999999999999, '1011': 137.806, '1100': 80.91900000000001, '1101': 131.363, '1110': 113.786, '1111': 149.93200000000002, '10000': 37.943999999999996, '10001': 106.113, '10010': 88.973, '10011': 137.72, '10100': 77.371, '10101': 130.297, '10110': 113.467, '10111': 150.788, '11000': 70.61399999999999, '11001': 127.34200000000001, '11010': 109.559, '11011': 150.023, '11100': 97.29899999999999, '11101': 142.868, '11110': 125.024, '11111': 158.118}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 60000/60000 [02:09<00:00, 464.14it/s]\n",
            "100%|██████████| 10000/10000 [00:21<00:00, 457.12it/s]\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "<ipython-input-76-dc9983b947f2>:44: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  analysis_df = analysis_df.append({\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    config  val_accuracy  val_loss  \\\n",
            "0  4bit30p        0.9659  0.171998   \n",
            "1  4bit40p        0.9629  0.169417   \n",
            "2  4bit50p        0.9618  0.180078   \n",
            "3  4bit60p        0.9604  0.207152   \n",
            "4  4bit70p        0.9573  0.214989   \n",
            "\n",
            "                                     history_val_acc  \\\n",
            "0  [0.9089999794960022, 0.9362000226974487, 0.937...   \n",
            "1  [0.9169999957084656, 0.9271000027656555, 0.942...   \n",
            "2  [0.9168999791145325, 0.9251000285148621, 0.927...   \n",
            "3  [0.9065999984741211, 0.9140999913215637, 0.925...   \n",
            "4  [0.9067000150680542, 0.9178000092506409, 0.923...   \n",
            "\n",
            "                                    history_val_loss  \\\n",
            "0  [0.5961990356445312, 0.2810992896556854, 0.243...   \n",
            "1  [0.7165398597717285, 0.40322554111480713, 0.24...   \n",
            "2  [1.0729739665985107, 0.5806041359901428, 0.340...   \n",
            "3  [0.7896328568458557, 0.39091727137565613, 0.29...   \n",
            "4  [0.8529000282287598, 0.3971153795719147, 0.286...   \n",
            "\n",
            "                                   history_train_acc  \\\n",
            "0  [0.8606666922569275, 0.9236666560173035, 0.940...   \n",
            "1  [0.8648666739463806, 0.9231166839599609, 0.935...   \n",
            "2  [0.8630499839782715, 0.9223499894142151, 0.934...   \n",
            "3  [0.861466646194458, 0.9171666502952576, 0.9309...   \n",
            "4  [0.8608499765396118, 0.9120166897773743, 0.928...   \n",
            "\n",
            "                                  history_train_loss  \n",
            "0  [1.7612853050231934, 0.3980737030506134, 0.232...  \n",
            "1  [2.221606969833374, 0.5513030886650085, 0.2889...  \n",
            "2  [3.1047916412353516, 0.7570062279701233, 0.389...  \n",
            "3  [2.903733968734741, 0.5294719934463501, 0.2888...  \n",
            "4  [3.1085143089294434, 0.5468863248825073, 0.286...  \n",
            "Processing 5bit70p\n",
            "{'0000': 0.0, '0001': 90.318, '0010': 71.56, '0011': 131.34, '0100': 58.801, '0101': 125.42, '0110': 105.423, '0111': 147.33499999999998, '1000': 50.371, '1001': 122.294, '1010': 102.146, '1011': 147.864, '1100': 88.642, '1101': 142.406, '1110': 120.673, '1111': 156.861, '10000': 44.236, '10001': 120.087, '10010': 100.157, '10011': 148.096, '10100': 86.76599999999999, '10101': 142.37900000000002, '10110': 121.935, '10111': 158.33700000000002, '11000': 76.847, '11001': 138.553, '11010': 118.29299999999999, '11011': 158.055, '11100': 103.38799999999999, '11101': 151.792, '11110': 130.998, '11111': 164.327}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 60000/60000 [02:08<00:00, 466.95it/s]\n",
            "100%|██████████| 10000/10000 [00:21<00:00, 455.74it/s]\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "<ipython-input-76-dc9983b947f2>:44: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  analysis_df = analysis_df.append({\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    config  val_accuracy  val_loss  \\\n",
            "0  4bit30p        0.9659  0.171998   \n",
            "1  4bit40p        0.9629  0.169417   \n",
            "2  4bit50p        0.9618  0.180078   \n",
            "3  4bit60p        0.9604  0.207152   \n",
            "4  4bit70p        0.9573  0.214989   \n",
            "\n",
            "                                     history_val_acc  \\\n",
            "0  [0.9089999794960022, 0.9362000226974487, 0.937...   \n",
            "1  [0.9169999957084656, 0.9271000027656555, 0.942...   \n",
            "2  [0.9168999791145325, 0.9251000285148621, 0.927...   \n",
            "3  [0.9065999984741211, 0.9140999913215637, 0.925...   \n",
            "4  [0.9067000150680542, 0.9178000092506409, 0.923...   \n",
            "\n",
            "                                    history_val_loss  \\\n",
            "0  [0.5961990356445312, 0.2810992896556854, 0.243...   \n",
            "1  [0.7165398597717285, 0.40322554111480713, 0.24...   \n",
            "2  [1.0729739665985107, 0.5806041359901428, 0.340...   \n",
            "3  [0.7896328568458557, 0.39091727137565613, 0.29...   \n",
            "4  [0.8529000282287598, 0.3971153795719147, 0.286...   \n",
            "\n",
            "                                   history_train_acc  \\\n",
            "0  [0.8606666922569275, 0.9236666560173035, 0.940...   \n",
            "1  [0.8648666739463806, 0.9231166839599609, 0.935...   \n",
            "2  [0.8630499839782715, 0.9223499894142151, 0.934...   \n",
            "3  [0.861466646194458, 0.9171666502952576, 0.9309...   \n",
            "4  [0.8608499765396118, 0.9120166897773743, 0.928...   \n",
            "\n",
            "                                  history_train_loss  \n",
            "0  [1.7612853050231934, 0.3980737030506134, 0.232...  \n",
            "1  [2.221606969833374, 0.5513030886650085, 0.2889...  \n",
            "2  [3.1047916412353516, 0.7570062279701233, 0.389...  \n",
            "3  [2.903733968734741, 0.5294719934463501, 0.2888...  \n",
            "4  [3.1085143089294434, 0.5468863248825073, 0.286...  \n",
            "Processing 6bit30p\n",
            "{'0000': 0.0, '0001': 23.807, '0010': 19.685000000000002, '0011': 53.488, '0100': 16.271, '0101': 42.065, '0110': 43.439, '0111': 73.548, '1000': 13.835999999999999, '1001': 39.419000000000004, '1010': 34.586, '1011': 66.137, '1100': 35.946, '1101': 59.678000000000004, '1110': 60.055, '1111': 87.45400000000001, '10000': 12.062, '10001': 37.855, '10010': 33.146, '10011': 65.13199999999999, '10100': 29.346, '10101': 53.882, '10110': 54.877, '10111': 83.193, '11000': 30.967000000000002, '11001': 55.481, '11010': 50.592, '11011': 80.15899999999999, '11100': 50.812999999999995, '11101': 73.431, '11110': 72.91300000000001, '11111': 98.538, '100000': 10.831, '100001': 36.632999999999996, '100010': 32.056000000000004, '100011': 64.494, '100100': 28.282999999999998, '100101': 52.869, '100110': 53.943999999999996, '100111': 82.884, '101000': 25.536, '101001': 50.495, '101010': 45.601, '101011': 76.16199999999999, '101100': 46.488, '101101': 69.827, '101110': 69.20800000000001, '101111': 95.61699999999999, '110000': 27.490000000000002, '110001': 52.823, '110010': 47.705999999999996, '110011': 78.15700000000001, '110100': 43.476, '110101': 66.991, '110110': 67.11399999999999, '110111': 94.25699999999999, '111000': 44.339000000000006, '111001': 67.725, '111010': 62.714000000000006, '111011': 90.854, '111100': 62.089999999999996, '111101': 83.913, '111110': 82.825, '111111': 107.288}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 60000/60000 [02:09<00:00, 464.44it/s]\n",
            "100%|██████████| 10000/10000 [00:22<00:00, 444.97it/s]\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "<ipython-input-76-dc9983b947f2>:44: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  analysis_df = analysis_df.append({\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    config  val_accuracy  val_loss  \\\n",
            "0  4bit30p        0.9659  0.171998   \n",
            "1  4bit40p        0.9629  0.169417   \n",
            "2  4bit50p        0.9618  0.180078   \n",
            "3  4bit60p        0.9604  0.207152   \n",
            "4  4bit70p        0.9573  0.214989   \n",
            "\n",
            "                                     history_val_acc  \\\n",
            "0  [0.9089999794960022, 0.9362000226974487, 0.937...   \n",
            "1  [0.9169999957084656, 0.9271000027656555, 0.942...   \n",
            "2  [0.9168999791145325, 0.9251000285148621, 0.927...   \n",
            "3  [0.9065999984741211, 0.9140999913215637, 0.925...   \n",
            "4  [0.9067000150680542, 0.9178000092506409, 0.923...   \n",
            "\n",
            "                                    history_val_loss  \\\n",
            "0  [0.5961990356445312, 0.2810992896556854, 0.243...   \n",
            "1  [0.7165398597717285, 0.40322554111480713, 0.24...   \n",
            "2  [1.0729739665985107, 0.5806041359901428, 0.340...   \n",
            "3  [0.7896328568458557, 0.39091727137565613, 0.29...   \n",
            "4  [0.8529000282287598, 0.3971153795719147, 0.286...   \n",
            "\n",
            "                                   history_train_acc  \\\n",
            "0  [0.8606666922569275, 0.9236666560173035, 0.940...   \n",
            "1  [0.8648666739463806, 0.9231166839599609, 0.935...   \n",
            "2  [0.8630499839782715, 0.9223499894142151, 0.934...   \n",
            "3  [0.861466646194458, 0.9171666502952576, 0.9309...   \n",
            "4  [0.8608499765396118, 0.9120166897773743, 0.928...   \n",
            "\n",
            "                                  history_train_loss  \n",
            "0  [1.7612853050231934, 0.3980737030506134, 0.232...  \n",
            "1  [2.221606969833374, 0.5513030886650085, 0.2889...  \n",
            "2  [3.1047916412353516, 0.7570062279701233, 0.389...  \n",
            "3  [2.903733968734741, 0.5294719934463501, 0.2888...  \n",
            "4  [3.1085143089294434, 0.5468863248825073, 0.286...  \n",
            "Processing 6bit40p\n",
            "{'0000': 0.0, '0001': 44.229, '0010': 35.692, '0011': 83.69600000000001, '0100': 29.448999999999998, '0101': 71.784, '0110': 67.439, '0111': 106.80099999999999, '1000': 25.22, '1001': 68.736, '1010': 58.974, '1011': 101.18599999999999, '1100': 56.277, '1101': 93.904, '1110': 86.791, '1111': 120.659, '10000': 21.812, '10001': 66.291, '10010': 56.703, '10011': 99.768, '10100': 49.831, '10101': 89.09599999999999, '10110': 82.975, '10111': 118.645, '11000': 48.605000000000004, '11001': 88.337, '11010': 78.042, '11011': 116.09800000000001, '11100': 73.463, '11101': 107.996, '11110': 100.187, '11111': 131.23299999999998, '100000': 19.739, '100001': 64.501, '100010': 54.861, '100011': 98.807, '100100': 48.065, '100101': 87.45899999999999, '100110': 81.395, '100111': 117.63, '101000': 42.972, '101001': 84.343, '101010': 74.612, '101011': 113.85199999999999, '101100': 70.453, '101101': 105.79299999999999, '101110': 98.44200000000001, '101111': 130.315, '110000': 42.98, '110001': 84.728, '110010': 74.62100000000001, '110011': 114.261, '110100': 67.393, '110101': 103.298, '110110': 96.85000000000001, '110111': 129.554, '111000': 64.268, '111001': 102.04199999999999, '111010': 91.204, '111011': 126.83500000000001, '111100': 85.76599999999999, '111101': 118.007, '111110': 92.83, '111111': 117.75099999999999}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 60000/60000 [02:08<00:00, 466.44it/s]\n",
            "100%|██████████| 10000/10000 [00:22<00:00, 451.90it/s]\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "<ipython-input-76-dc9983b947f2>:44: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  analysis_df = analysis_df.append({\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    config  val_accuracy  val_loss  \\\n",
            "0  4bit30p        0.9659  0.171998   \n",
            "1  4bit40p        0.9629  0.169417   \n",
            "2  4bit50p        0.9618  0.180078   \n",
            "3  4bit60p        0.9604  0.207152   \n",
            "4  4bit70p        0.9573  0.214989   \n",
            "\n",
            "                                     history_val_acc  \\\n",
            "0  [0.9089999794960022, 0.9362000226974487, 0.937...   \n",
            "1  [0.9169999957084656, 0.9271000027656555, 0.942...   \n",
            "2  [0.9168999791145325, 0.9251000285148621, 0.927...   \n",
            "3  [0.9065999984741211, 0.9140999913215637, 0.925...   \n",
            "4  [0.9067000150680542, 0.9178000092506409, 0.923...   \n",
            "\n",
            "                                    history_val_loss  \\\n",
            "0  [0.5961990356445312, 0.2810992896556854, 0.243...   \n",
            "1  [0.7165398597717285, 0.40322554111480713, 0.24...   \n",
            "2  [1.0729739665985107, 0.5806041359901428, 0.340...   \n",
            "3  [0.7896328568458557, 0.39091727137565613, 0.29...   \n",
            "4  [0.8529000282287598, 0.3971153795719147, 0.286...   \n",
            "\n",
            "                                   history_train_acc  \\\n",
            "0  [0.8606666922569275, 0.9236666560173035, 0.940...   \n",
            "1  [0.8648666739463806, 0.9231166839599609, 0.935...   \n",
            "2  [0.8630499839782715, 0.9223499894142151, 0.934...   \n",
            "3  [0.861466646194458, 0.9171666502952576, 0.9309...   \n",
            "4  [0.8608499765396118, 0.9120166897773743, 0.928...   \n",
            "\n",
            "                                  history_train_loss  \n",
            "0  [1.7612853050231934, 0.3980737030506134, 0.232...  \n",
            "1  [2.221606969833374, 0.5513030886650085, 0.2889...  \n",
            "2  [3.1047916412353516, 0.7570062279701233, 0.389...  \n",
            "3  [2.903733968734741, 0.5294719934463501, 0.2888...  \n",
            "4  [3.1085143089294434, 0.5468863248825073, 0.286...  \n",
            "Processing 6bit50p\n",
            "{'0000': 0.0, '0001': 46.580000000000005, '0010': 37.318, '0011': 83.748, '0100': 30.793999999999997, '0101': 73.724, '0110': 67.058, '0111': 104.575, '1000': 25.961000000000002, '1001': 69.30699999999999, '1010': 60.08, '1011': 100.804, '1100': 56.028, '1101': 93.929, '1110': 86.036, '1111': 119.198, '10000': 23.069, '10001': 67.596, '10010': 58.244, '10011': 100.005, '10100': 51.032000000000004, '10101': 90.67699999999999, '10110': 83.36399999999999, '10111': 117.794, '11000': 48.836, '11001': 88.907, '11010': 78.417, '11011': 115.278, '11100': 73.287, '11101': 108.173, '11110': 99.407, '11111': 129.342, '100000': 20.712999999999997, '100001': 66.027, '100010': 56.338, '100011': 98.599, '100100': 49.709, '100101': 89.784, '100110': 81.54899999999999, '100111': 118.157, '101000': 44.995, '101001': 87.081, '101010': 76.106, '101011': 114.89399999999999, '101100': 72.218, '101101': 105.891, '101110': 97.057, '101111': 129.941, '110000': 43.317, '110001': 85.839, '110010': 75.49300000000001, '110011': 114.10199999999999, '110100': 68.62, '110101': 103.02799999999999, '110110': 95.929, '110111': 129.31300000000002, '111000': 65.125, '111001': 102.961, '111010': 91.614, '111011': 125.047, '111100': 85.403, '111101': 116.723, '111110': 109.13000000000001, '111111': 137.629}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 60000/60000 [02:08<00:00, 466.95it/s]\n",
            "100%|██████████| 10000/10000 [00:21<00:00, 470.93it/s]\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "<ipython-input-76-dc9983b947f2>:44: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  analysis_df = analysis_df.append({\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    config  val_accuracy  val_loss  \\\n",
            "0  4bit30p        0.9659  0.171998   \n",
            "1  4bit40p        0.9629  0.169417   \n",
            "2  4bit50p        0.9618  0.180078   \n",
            "3  4bit60p        0.9604  0.207152   \n",
            "4  4bit70p        0.9573  0.214989   \n",
            "\n",
            "                                     history_val_acc  \\\n",
            "0  [0.9089999794960022, 0.9362000226974487, 0.937...   \n",
            "1  [0.9169999957084656, 0.9271000027656555, 0.942...   \n",
            "2  [0.9168999791145325, 0.9251000285148621, 0.927...   \n",
            "3  [0.9065999984741211, 0.9140999913215637, 0.925...   \n",
            "4  [0.9067000150680542, 0.9178000092506409, 0.923...   \n",
            "\n",
            "                                    history_val_loss  \\\n",
            "0  [0.5961990356445312, 0.2810992896556854, 0.243...   \n",
            "1  [0.7165398597717285, 0.40322554111480713, 0.24...   \n",
            "2  [1.0729739665985107, 0.5806041359901428, 0.340...   \n",
            "3  [0.7896328568458557, 0.39091727137565613, 0.29...   \n",
            "4  [0.8529000282287598, 0.3971153795719147, 0.286...   \n",
            "\n",
            "                                   history_train_acc  \\\n",
            "0  [0.8606666922569275, 0.9236666560173035, 0.940...   \n",
            "1  [0.8648666739463806, 0.9231166839599609, 0.935...   \n",
            "2  [0.8630499839782715, 0.9223499894142151, 0.934...   \n",
            "3  [0.861466646194458, 0.9171666502952576, 0.9309...   \n",
            "4  [0.8608499765396118, 0.9120166897773743, 0.928...   \n",
            "\n",
            "                                  history_train_loss  \n",
            "0  [1.7612853050231934, 0.3980737030506134, 0.232...  \n",
            "1  [2.221606969833374, 0.5513030886650085, 0.2889...  \n",
            "2  [3.1047916412353516, 0.7570062279701233, 0.389...  \n",
            "3  [2.903733968734741, 0.5294719934463501, 0.2888...  \n",
            "4  [3.1085143089294434, 0.5468863248825073, 0.286...  \n",
            "Processing 6bit60p\n",
            "{'0000': 0.0, '0001': 59.426, '0010': 47.278, '0011': 100.006, '0100': 39.521, '0101': 91.49, '0110': 80.97500000000001, '0111': 121.735, '1000': 33.769, '1001': 88.37, '1010': 74.04299999999999, '1011': 116.092, '1100': 67.861, '1101': 112.322, '1110': 99.00399999999999, '1111': 133.387, '10000': 29.351, '10001': 83.61, '10010': 71.81700000000001, '10011': 117.31700000000001, '10100': 63.445, '10101': 110.03699999999999, '10110': 98.53099999999999, '10111': 149.634, '11000': 70.712, '11001': 128.282, '11010': 110.389, '11011': 151.15200000000002, '11100': 97.884, '11101': 143.63899999999998, '11110': 125.673, '11111': 159.091, '100000': 34.342, '100001': 105.577, '100010': 88.366, '100011': 138.932, '100100': 76.401, '100101': 131.398, '100110': 114.578, '100111': 152.366, '101000': 68.132, '101001': 126.68299999999999, '101010': 109.56200000000001, '101011': 151.388, '101100': 97.949, '101101': 144.383, '101110': 126.64900000000002, '101111': 160.094, '110000': 62.769000000000005, '110001': 124.913, '110010': 107.48299999999999, '110011': 150.254, '110100': 94.686, '110101': 143.322, '110110': 126.23, '110111': 160.45000000000002, '111000': 85.68599999999999, '111001': 138.739, '111010': 121.014, '111011': 158.79299999999998, '111100': 108.324, '111101': 151.68200000000002, '111110': 133.80800000000002, '111111': 165.47400000000002}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 60000/60000 [02:09<00:00, 462.66it/s]\n",
            "100%|██████████| 10000/10000 [00:21<00:00, 458.91it/s]\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "<ipython-input-76-dc9983b947f2>:44: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  analysis_df = analysis_df.append({\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    config  val_accuracy  val_loss  \\\n",
            "0  4bit30p        0.9659  0.171998   \n",
            "1  4bit40p        0.9629  0.169417   \n",
            "2  4bit50p        0.9618  0.180078   \n",
            "3  4bit60p        0.9604  0.207152   \n",
            "4  4bit70p        0.9573  0.214989   \n",
            "\n",
            "                                     history_val_acc  \\\n",
            "0  [0.9089999794960022, 0.9362000226974487, 0.937...   \n",
            "1  [0.9169999957084656, 0.9271000027656555, 0.942...   \n",
            "2  [0.9168999791145325, 0.9251000285148621, 0.927...   \n",
            "3  [0.9065999984741211, 0.9140999913215637, 0.925...   \n",
            "4  [0.9067000150680542, 0.9178000092506409, 0.923...   \n",
            "\n",
            "                                    history_val_loss  \\\n",
            "0  [0.5961990356445312, 0.2810992896556854, 0.243...   \n",
            "1  [0.7165398597717285, 0.40322554111480713, 0.24...   \n",
            "2  [1.0729739665985107, 0.5806041359901428, 0.340...   \n",
            "3  [0.7896328568458557, 0.39091727137565613, 0.29...   \n",
            "4  [0.8529000282287598, 0.3971153795719147, 0.286...   \n",
            "\n",
            "                                   history_train_acc  \\\n",
            "0  [0.8606666922569275, 0.9236666560173035, 0.940...   \n",
            "1  [0.8648666739463806, 0.9231166839599609, 0.935...   \n",
            "2  [0.8630499839782715, 0.9223499894142151, 0.934...   \n",
            "3  [0.861466646194458, 0.9171666502952576, 0.9309...   \n",
            "4  [0.8608499765396118, 0.9120166897773743, 0.928...   \n",
            "\n",
            "                                  history_train_loss  \n",
            "0  [1.7612853050231934, 0.3980737030506134, 0.232...  \n",
            "1  [2.221606969833374, 0.5513030886650085, 0.2889...  \n",
            "2  [3.1047916412353516, 0.7570062279701233, 0.389...  \n",
            "3  [2.903733968734741, 0.5294719934463501, 0.2888...  \n",
            "4  [3.1085143089294434, 0.5468863248825073, 0.286...  \n",
            "Processing 6bit70p\n",
            "{'0000': 0.0, '0001': 90.911, '0010': 71.732, '0011': 132.154, '0100': 59.14, '0101': 126.12400000000001, '0110': 106.182, '0111': 148.191, '1000': 50.789, '1001': 123.42699999999999, '1010': 103.17800000000001, '1011': 148.684, '1100': 89.147, '1101': 143.261, '1110': 121.854, '1111': 157.78, '10000': 44.521, '10001': 121.098, '10010': 101.076, '10011': 149.07500000000002, '10100': 87.35, '10101': 143.255, '10110': 122.764, '10111': 159.601, '11000': 77.423, '11001': 139.62099999999998, '11010': 119.12100000000001, '11011': 158.952, '11100': 103.97099999999999, '11101': 152.983, '11110': 131.757, '11111': 165.22400000000002, '100000': 39.937, '100001': 119.249, '100010': 99.533, '100011': 149.15800000000002, '100100': 86.12400000000001, '100101': 143.573, '100110': 122.913, '100111': 160.273, '101000': 75.969, '101001': 139.712, '101010': 119.488, '101011': 160.05700000000002, '101100': 105.095, '101101': 154.115, '101110': 133.343, '101111': 166.802, '110000': 68.626, '110001': 136.23, '110010': 116.721, '110011': 159.444, '110100': 102.56899999999999, '110101': 153.832, '110110': 133.383, '110111': 167.53799999999998, '111000': 91.242, '111001': 148.985, '111010': 128.865, '111011': 166.244, '111100': 113.824, '111101': 160.229, '111110': 139.452, '111111': 171.44899999999998}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 60000/60000 [02:08<00:00, 465.86it/s]\n",
            "100%|██████████| 10000/10000 [00:21<00:00, 471.47it/s]\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "<ipython-input-76-dc9983b947f2>:44: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  analysis_df = analysis_df.append({\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    config  val_accuracy  val_loss  \\\n",
            "0  4bit30p        0.9659  0.171998   \n",
            "1  4bit40p        0.9629  0.169417   \n",
            "2  4bit50p        0.9618  0.180078   \n",
            "3  4bit60p        0.9604  0.207152   \n",
            "4  4bit70p        0.9573  0.214989   \n",
            "\n",
            "                                     history_val_acc  \\\n",
            "0  [0.9089999794960022, 0.9362000226974487, 0.937...   \n",
            "1  [0.9169999957084656, 0.9271000027656555, 0.942...   \n",
            "2  [0.9168999791145325, 0.9251000285148621, 0.927...   \n",
            "3  [0.9065999984741211, 0.9140999913215637, 0.925...   \n",
            "4  [0.9067000150680542, 0.9178000092506409, 0.923...   \n",
            "\n",
            "                                    history_val_loss  \\\n",
            "0  [0.5961990356445312, 0.2810992896556854, 0.243...   \n",
            "1  [0.7165398597717285, 0.40322554111480713, 0.24...   \n",
            "2  [1.0729739665985107, 0.5806041359901428, 0.340...   \n",
            "3  [0.7896328568458557, 0.39091727137565613, 0.29...   \n",
            "4  [0.8529000282287598, 0.3971153795719147, 0.286...   \n",
            "\n",
            "                                   history_train_acc  \\\n",
            "0  [0.8606666922569275, 0.9236666560173035, 0.940...   \n",
            "1  [0.8648666739463806, 0.9231166839599609, 0.935...   \n",
            "2  [0.8630499839782715, 0.9223499894142151, 0.934...   \n",
            "3  [0.861466646194458, 0.9171666502952576, 0.9309...   \n",
            "4  [0.8608499765396118, 0.9120166897773743, 0.928...   \n",
            "\n",
            "                                  history_train_loss  \n",
            "0  [1.7612853050231934, 0.3980737030506134, 0.232...  \n",
            "1  [2.221606969833374, 0.5513030886650085, 0.2889...  \n",
            "2  [3.1047916412353516, 0.7570062279701233, 0.389...  \n",
            "3  [2.903733968734741, 0.5294719934463501, 0.2888...  \n",
            "4  [3.1085143089294434, 0.5468863248825073, 0.286...  \n",
            "Processing 7bit30p\n",
            "{'0000': 0.0, '0001': 23.509, '0010': 19.611, '0011': 53.721, '0100': 16.262, '0101': 42.169, '0110': 43.788000000000004, '0111': 74.232, '1000': 13.895, '1001': 40.089, '1010': 35.1, '1011': 67.465, '1100': 36.632, '1101': 60.935, '1110': 61.214, '1111': 89.16, '10000': 12.257, '10001': 38.616, '10010': 33.612, '10011': 66.182, '10100': 29.801000000000002, '10101': 54.853, '10110': 55.711999999999996, '10111': 84.91, '11000': 31.666, '11001': 56.721000000000004, '11010': 51.535, '11011': 81.88199999999999, '11100': 51.68, '11101': 74.92999999999999, '11110': 74.062, '11111': 100.358, '100000': 11.023, '100001': 37.564, '100010': 32.568, '100011': 65.473, '100100': 28.563000000000002, '100101': 53.931, '100110': 54.783, '100111': 84.121, '101000': 26.013, '101001': 51.629, '101010': 46.547, '101011': 77.55499999999999, '101100': 47.216, '101101': 70.713, '101110': 70.509, '101111': 97.574, '110000': 27.942999999999998, '110001': 53.543, '110010': 48.281, '110011': 79.42200000000001, '110100': 44.276999999999994, '110101': 68.40899999999999, '110110': 68.5, '110111': 95.71300000000001, '111000': 44.984, '111001': 69.051, '111010': 63.71, '111011': 92.609, '111100': 63.404, '111101': 85.702, '111110': 84.289, '111111': 109.304, '1000000': 9.997, '1000001': 36.521, '1000010': 31.6, '1000011': 64.786, '1000100': 27.711, '1000101': 52.998999999999995, '1000110': 54.082, '1000111': 83.713, '1001000': 24.934, '1001001': 50.622, '1001010': 45.687, '1001011': 76.73, '1001100': 46.434999999999995, '1001101': 70.201, '1001110': 70.159, '1001111': 96.92, '1010000': 23.099999999999998, '1010001': 49.038, '1010010': 43.812999999999995, '1010011': 75.422, '1010100': 39.857, '1010101': 64.24000000000001, '1010110': 64.53, '1010111': 92.62299999999999, '1011000': 40.961999999999996, '1011001': 65.626, '1011010': 60.276, '1011011': 89.259, '1011100': 60.117, '1011101': 82.741, '1011110': 81.763, '1011111': 107.283, '1100000': 25.134, '1100001': 51.244, '1100010': 45.835, '1100011': 77.634, '1100100': 41.891999999999996, '1100101': 66.418, '1100110': 66.649, '1100111': 94.732, '1101000': 39.204, '1101001': 63.837, '1101010': 58.715999999999994, '1101011': 88.436, '1101100': 58.81, '1101101': 81.446, '1101110': 80.624, '1101111': 106.45599999999999, '1110000': 40.175000000000004, '1110001': 64.974, '1110010': 59.685, '1110011': 89.598, '1110100': 55.491, '1110101': 78.792, '1110110': 78.619, '1110111': 105.146, '1111000': 56.288, '1111001': 79.067, '1111010': 73.72, '1111011': 101.24600000000001, '1111100': 72.754, '1111101': 94.134, '1111110': 92.408, '1111111': 116.255}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 60000/60000 [02:09<00:00, 463.67it/s]\n",
            "100%|██████████| 10000/10000 [00:22<00:00, 452.94it/s]\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "<ipython-input-76-dc9983b947f2>:44: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  analysis_df = analysis_df.append({\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    config  val_accuracy  val_loss  \\\n",
            "0  4bit30p        0.9659  0.171998   \n",
            "1  4bit40p        0.9629  0.169417   \n",
            "2  4bit50p        0.9618  0.180078   \n",
            "3  4bit60p        0.9604  0.207152   \n",
            "4  4bit70p        0.9573  0.214989   \n",
            "\n",
            "                                     history_val_acc  \\\n",
            "0  [0.9089999794960022, 0.9362000226974487, 0.937...   \n",
            "1  [0.9169999957084656, 0.9271000027656555, 0.942...   \n",
            "2  [0.9168999791145325, 0.9251000285148621, 0.927...   \n",
            "3  [0.9065999984741211, 0.9140999913215637, 0.925...   \n",
            "4  [0.9067000150680542, 0.9178000092506409, 0.923...   \n",
            "\n",
            "                                    history_val_loss  \\\n",
            "0  [0.5961990356445312, 0.2810992896556854, 0.243...   \n",
            "1  [0.7165398597717285, 0.40322554111480713, 0.24...   \n",
            "2  [1.0729739665985107, 0.5806041359901428, 0.340...   \n",
            "3  [0.7896328568458557, 0.39091727137565613, 0.29...   \n",
            "4  [0.8529000282287598, 0.3971153795719147, 0.286...   \n",
            "\n",
            "                                   history_train_acc  \\\n",
            "0  [0.8606666922569275, 0.9236666560173035, 0.940...   \n",
            "1  [0.8648666739463806, 0.9231166839599609, 0.935...   \n",
            "2  [0.8630499839782715, 0.9223499894142151, 0.934...   \n",
            "3  [0.861466646194458, 0.9171666502952576, 0.9309...   \n",
            "4  [0.8608499765396118, 0.9120166897773743, 0.928...   \n",
            "\n",
            "                                  history_train_loss  \n",
            "0  [1.7612853050231934, 0.3980737030506134, 0.232...  \n",
            "1  [2.221606969833374, 0.5513030886650085, 0.2889...  \n",
            "2  [3.1047916412353516, 0.7570062279701233, 0.389...  \n",
            "3  [2.903733968734741, 0.5294719934463501, 0.2888...  \n",
            "4  [3.1085143089294434, 0.5468863248825073, 0.286...  \n",
            "Processing 7bit40p\n",
            "{'0000': 0.0, '0001': 45.199000000000005, '0010': 36.257, '0011': 85.20899999999999, '0100': 30.008, '0101': 73.172, '0110': 68.41, '0111': 108.234, '1000': 25.6, '1001': 69.602, '1010': 59.808, '1011': 102.831, '1100': 57.04, '1101': 95.305, '1110': 88.02799999999999, '1111': 122.73, '10000': 22.44, '10001': 67.326, '10010': 57.459999999999994, '10011': 101.44300000000001, '10100': 50.575, '10101': 90.544, '10110': 84.324, '10111': 120.541, '11000': 49.276, '11001': 90.045, '11010': 79.50500000000001, '11011': 117.941, '11100': 74.723, '11101': 109.928, '11110': 101.652, '11111': 132.981, '100000': 20.074, '100001': 65.565, '100010': 55.873, '100011': 100.471, '100100': 48.858, '100101': 89.12100000000001, '100110': 83.178, '100111': 119.851, '101000': 44.041, '101001': 85.691, '101010': 75.556, '101011': 115.273, '101100': 71.601, '101101': 107.59299999999999, '101110': 99.622, '101111': 131.926, '110000': 43.632999999999996, '110001': 85.927, '110010': 75.72, '110011': 115.877, '110100': 68.165, '110101': 105.11099999999999, '110110': 97.928, '110111': 131.048, '111000': 65.136, '111001': 103.17099999999999, '111010': 92.605, '111011': 128.326, '111100': 87.176, '111101': 120.286, '111110': 111.415, '111111': 140.896, '1000000': 18.235, '1000001': 64.197, '1000010': 54.288000000000004, '1000011': 99.7, '1000100': 47.665, '1000101': 88.506, '1000110': 82.626, '1000111': 119.463, '1001000': 42.733, '1001001': 84.787, '1001010': 74.70599999999999, '1001011': 114.732, '1001100': 70.774, '1001101': 107.044, '1001110': 99.24, '1001111': 131.78599999999997, '1010000': 39.293, '1010001': 82.41999999999999, '1010010': 72.19399999999999, '1010011': 113.35199999999999, '1010100': 64.82300000000001, '1010101': 102.687, '1010110': 95.785, '1010111': 129.679, '1011000': 62.528, '1011001': 101.372, '1011010': 90.829, '1011011': 127.063, '1011100': 85.32, '1011101': 118.982, '1011110': 110.227, '1011111': 140.348, '1100000': 39.309, '1100001': 82.801, '1100010': 72.757, '1100011': 114.188, '1100100': 65.319, '1100101': 103.15100000000001, '1100110': 96.703, '1100111': 130.778, '1101000': 60.053000000000004, '1101001': 99.621, '1101010': 89.214, '1101011': 126.31800000000001, '1101100': 84.625, '1101101': 118.613, '1101110': 110.048, '1101111': 140.398, '1110000': 58.099, '1110001': 98.58500000000001, '1110010': 88.32, '1110011': 126.0, '1110100': 80.529, '1110101': 115.744, '1110110': 108.183, '1110111': 139.75099999999998, '1111000': 76.762, '1111001': 113.401, '1111010': 102.446, '1111011': 136.30999999999997, '1111100': 96.439, '1111101': 128.182, '1111110': 119.12100000000001, '1111111': 147.461}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 60000/60000 [02:09<00:00, 464.85it/s]\n",
            "100%|██████████| 10000/10000 [00:22<00:00, 453.85it/s]\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "<ipython-input-76-dc9983b947f2>:44: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  analysis_df = analysis_df.append({\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    config  val_accuracy  val_loss  \\\n",
            "0  4bit30p        0.9659  0.171998   \n",
            "1  4bit40p        0.9629  0.169417   \n",
            "2  4bit50p        0.9618  0.180078   \n",
            "3  4bit60p        0.9604  0.207152   \n",
            "4  4bit70p        0.9573  0.214989   \n",
            "\n",
            "                                     history_val_acc  \\\n",
            "0  [0.9089999794960022, 0.9362000226974487, 0.937...   \n",
            "1  [0.9169999957084656, 0.9271000027656555, 0.942...   \n",
            "2  [0.9168999791145325, 0.9251000285148621, 0.927...   \n",
            "3  [0.9065999984741211, 0.9140999913215637, 0.925...   \n",
            "4  [0.9067000150680542, 0.9178000092506409, 0.923...   \n",
            "\n",
            "                                    history_val_loss  \\\n",
            "0  [0.5961990356445312, 0.2810992896556854, 0.243...   \n",
            "1  [0.7165398597717285, 0.40322554111480713, 0.24...   \n",
            "2  [1.0729739665985107, 0.5806041359901428, 0.340...   \n",
            "3  [0.7896328568458557, 0.39091727137565613, 0.29...   \n",
            "4  [0.8529000282287598, 0.3971153795719147, 0.286...   \n",
            "\n",
            "                                   history_train_acc  \\\n",
            "0  [0.8606666922569275, 0.9236666560173035, 0.940...   \n",
            "1  [0.8648666739463806, 0.9231166839599609, 0.935...   \n",
            "2  [0.8630499839782715, 0.9223499894142151, 0.934...   \n",
            "3  [0.861466646194458, 0.9171666502952576, 0.9309...   \n",
            "4  [0.8608499765396118, 0.9120166897773743, 0.928...   \n",
            "\n",
            "                                  history_train_loss  \n",
            "0  [1.7612853050231934, 0.3980737030506134, 0.232...  \n",
            "1  [2.221606969833374, 0.5513030886650085, 0.2889...  \n",
            "2  [3.1047916412353516, 0.7570062279701233, 0.389...  \n",
            "3  [2.903733968734741, 0.5294719934463501, 0.2888...  \n",
            "4  [3.1085143089294434, 0.5468863248825073, 0.286...  \n",
            "Processing 7bit50p\n",
            "{'0000': 0.0, '0001': 63.72899999999999, '0010': 50.649, '0011': 107.66499999999999, '0100': 41.711, '0101': 97.32300000000001, '0110': 86.07900000000001, '0111': 128.945, '1000': 35.5, '1001': 93.472, '1010': 78.999, '1011': 126.06, '1100': 71.742, '1101': 118.601, '1110': 105.037, '1111': 141.192, '10000': 31.212, '10001': 90.502, '10010': 76.421, '10011': 125.07799999999999, '10100': 66.652, '10101': 115.392, '10110': 102.992, '10111': 140.52700000000002, '11000': 61.964999999999996, '11001': 113.155, '11010': 98.486, '11011': 139.06, '11100': 89.002, '11101': 131.302, '11110': 117.025, '11111': 149.957, '100000': 27.830000000000002, '100001': 88.604, '100010': 74.583, '100011': 124.455, '100100': 65.081, '100101': 114.944, '100110': 102.55, '100111': 141.048, '101000': 58.138000000000005, '101001': 110.92200000000001, '101010': 96.331, '101011': 138.276, '101100': 87.774, '101101': 130.929, '101110': 116.87100000000001, '101111': 150.26, '110000': 55.009, '110001': 109.482, '110010': 94.864, '110011': 138.19600000000003, '110100': 84.507, '110101': 128.934, '110110': 115.828, '110111': 150.238, '111000': 77.891, '111001': 125.146, '111010': 110.46400000000001, '111011': 148.081, '111100': 100.562, '111101': 140.06199999999998, '111110': 125.87, '111111': 156.86700000000002, '1000000': 25.262, '1000001': 86.858, '1000010': 72.895, '1000011': 123.41499999999999, '1000100': 63.345, '1000101': 113.805, '1000110': 101.887, '1000111': 140.845, '1001000': 56.74, '1001001': 109.957, '1001010': 95.53200000000001, '1001011': 138.286, '1001100': 87.399, '1001101': 130.669, '1001110': 117.04100000000001, '1001111': 150.817, '1010000': 51.725, '1010001': 106.70100000000001, '1010010': 92.565, '1010011': 136.958, '1010100': 82.598, '1010101': 128.00900000000001, '1010110': 114.99, '1010111': 150.04799999999997, '1011000': 76.892, '1011001': 125.09899999999999, '1011010': 110.041, '1011011': 147.96200000000002, '1011100': 100.39399999999999, '1011101': 140.212, '1011110': 125.987, '1011111': 157.288, '1100000': 49.399, '1100001': 106.02399999999999, '1100010': 91.734, '1100011': 136.82, '1100100': 81.984, '1100101': 127.726, '1100110': 115.288, '1100111': 150.57999999999998, '1101000': 74.536, '1101001': 123.574, '1101010': 108.985, '1101011': 147.891, '1101100': 99.941, '1101101': 140.247, '1101110': 126.415, '1101111': 157.85299999999998, '1110000': 69.52, '1110001': 120.818, '1110010': 106.41000000000001, '1110011': 146.724, '1110100': 95.99499999999999, '1110101': 137.857, '1110110': 124.822, '1110111': 157.526, '1111000': 88.741, '1111001': 133.88400000000001, '1111010': 119.22000000000001, '1111011': 154.911, '1111100': 109.21300000000001, '1111101': 147.063, '1111110': 132.928, '1111111': 162.72500000000002}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 60000/60000 [02:09<00:00, 462.98it/s]\n",
            "100%|██████████| 10000/10000 [00:22<00:00, 449.82it/s]\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "<ipython-input-76-dc9983b947f2>:44: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  analysis_df = analysis_df.append({\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    config  val_accuracy  val_loss  \\\n",
            "0  4bit30p        0.9659  0.171998   \n",
            "1  4bit40p        0.9629  0.169417   \n",
            "2  4bit50p        0.9618  0.180078   \n",
            "3  4bit60p        0.9604  0.207152   \n",
            "4  4bit70p        0.9573  0.214989   \n",
            "\n",
            "                                     history_val_acc  \\\n",
            "0  [0.9089999794960022, 0.9362000226974487, 0.937...   \n",
            "1  [0.9169999957084656, 0.9271000027656555, 0.942...   \n",
            "2  [0.9168999791145325, 0.9251000285148621, 0.927...   \n",
            "3  [0.9065999984741211, 0.9140999913215637, 0.925...   \n",
            "4  [0.9067000150680542, 0.9178000092506409, 0.923...   \n",
            "\n",
            "                                    history_val_loss  \\\n",
            "0  [0.5961990356445312, 0.2810992896556854, 0.243...   \n",
            "1  [0.7165398597717285, 0.40322554111480713, 0.24...   \n",
            "2  [1.0729739665985107, 0.5806041359901428, 0.340...   \n",
            "3  [0.7896328568458557, 0.39091727137565613, 0.29...   \n",
            "4  [0.8529000282287598, 0.3971153795719147, 0.286...   \n",
            "\n",
            "                                   history_train_acc  \\\n",
            "0  [0.8606666922569275, 0.9236666560173035, 0.940...   \n",
            "1  [0.8648666739463806, 0.9231166839599609, 0.935...   \n",
            "2  [0.8630499839782715, 0.9223499894142151, 0.934...   \n",
            "3  [0.861466646194458, 0.9171666502952576, 0.9309...   \n",
            "4  [0.8608499765396118, 0.9120166897773743, 0.928...   \n",
            "\n",
            "                                  history_train_loss  \n",
            "0  [1.7612853050231934, 0.3980737030506134, 0.232...  \n",
            "1  [2.221606969833374, 0.5513030886650085, 0.2889...  \n",
            "2  [3.1047916412353516, 0.7570062279701233, 0.389...  \n",
            "3  [2.903733968734741, 0.5294719934463501, 0.2888...  \n",
            "4  [3.1085143089294434, 0.5468863248825073, 0.286...  \n",
            "Processing 7bit60p\n",
            "{'0000': 0.0, '0001': 78.864, '0010': 62.479, '0011': 122.703, '0100': 51.547000000000004, '0101': 114.444, '0110': 97.87400000000001, '0111': 140.663, '1000': 44.011, '1001': 111.10000000000001, '1010': 93.152, '1011': 140.494, '1100': 82.423, '1101': 134.115, '1110': 115.551, '1111': 151.963, '10000': 38.641, '10001': 108.648, '10010': 90.944, '10011': 140.193, '10100': 78.929, '10101': 132.87699999999998, '10110': 115.301, '10111': 152.642, '11000': 71.176, '11001': 129.31300000000002, '11010': 110.99499999999999, '11011': 151.831, '11100': 98.17099999999999, '11101': 144.797, '11110': 126.26, '11111': 159.76999999999998, '100000': 34.632999999999996, '100001': 106.484, '100010': 89.03899999999999, '100011': 139.65, '100100': 77.292, '100101': 132.344, '100110': 115.213, '100111': 153.29000000000002, '101000': 68.71900000000001, '101001': 128.072, '101010': 110.45, '101011': 152.107, '101100': 98.535, '101101': 145.57, '101110': 127.27, '101111': 160.75, '110000': 63.175999999999995, '110001': 125.787, '110010': 108.11800000000001, '110011': 151.565, '110100': 95.664, '110101': 144.57, '110110': 126.61500000000001, '110111': 161.319, '111000': 86.071, '111001': 139.956, '111010': 121.745, '111011': 159.663, '111100': 108.778, '111101': 152.59, '111110': 134.32, '111111': 166.159, '1000000': 31.406000000000002, '1000001': 104.901, '1000010': 87.077, '1000011': 138.439, '1000100': 75.679, '1000101': 132.3, '1000110': 115.351, '1000111': 153.714, '1001000': 67.88900000000001, '1001001': 128.31, '1001010': 110.36500000000001, '1001011': 152.67700000000002, '1001100': 98.777, '1001101': 145.947, '1001110': 127.93499999999999, '1001111': 161.703, '1010000': 61.446, '1010001': 125.173, '1010010': 107.444, '1010011': 151.764, '1010100': 95.23700000000001, '1010101': 144.72199999999998, '1010110': 127.25900000000001, '1010111': 162.06300000000002, '1011000': 86.506, '1011001': 140.351, '1011010': 122.507, '1011011': 160.46699999999998, '1011100': 109.859, '1011101': 153.70000000000002, '1011110': 135.543, '1011111': 167.268, '1100000': 56.846000000000004, '1100001': 122.72800000000001, '1100010': 105.389, '1100011': 151.088, '1100100': 93.34299999999999, '1100101': 143.984, '1100110': 126.70500000000001, '1100111': 161.936, '1101000': 84.133, '1101001': 139.428, '1101010': 121.62, '1101011': 160.379, '1101100': 109.52199999999999, '1101101': 153.56900000000002, '1101110': 136.025, '1101111': 167.887, '1110000': 76.772, '1110001': 135.294, '1110010': 117.96600000000001, '1110011': 158.694, '1110100': 105.521, '1110101': 151.00900000000001, '1110110': 134.52100000000002, '1110111': 167.263, '1111000': 95.89, '1111001': 146.803, '1111010': 129.179, '1111011': 165.30700000000002, '1111100': 116.565, '1111101': 158.487, '1111110': 140.80599999999998, '1111111': 171.462}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 60000/60000 [02:10<00:00, 460.69it/s]\n",
            "100%|██████████| 10000/10000 [00:22<00:00, 452.85it/s]\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "<ipython-input-76-dc9983b947f2>:44: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  analysis_df = analysis_df.append({\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    config  val_accuracy  val_loss  \\\n",
            "0  4bit30p        0.9659  0.171998   \n",
            "1  4bit40p        0.9629  0.169417   \n",
            "2  4bit50p        0.9618  0.180078   \n",
            "3  4bit60p        0.9604  0.207152   \n",
            "4  4bit70p        0.9573  0.214989   \n",
            "\n",
            "                                     history_val_acc  \\\n",
            "0  [0.9089999794960022, 0.9362000226974487, 0.937...   \n",
            "1  [0.9169999957084656, 0.9271000027656555, 0.942...   \n",
            "2  [0.9168999791145325, 0.9251000285148621, 0.927...   \n",
            "3  [0.9065999984741211, 0.9140999913215637, 0.925...   \n",
            "4  [0.9067000150680542, 0.9178000092506409, 0.923...   \n",
            "\n",
            "                                    history_val_loss  \\\n",
            "0  [0.5961990356445312, 0.2810992896556854, 0.243...   \n",
            "1  [0.7165398597717285, 0.40322554111480713, 0.24...   \n",
            "2  [1.0729739665985107, 0.5806041359901428, 0.340...   \n",
            "3  [0.7896328568458557, 0.39091727137565613, 0.29...   \n",
            "4  [0.8529000282287598, 0.3971153795719147, 0.286...   \n",
            "\n",
            "                                   history_train_acc  \\\n",
            "0  [0.8606666922569275, 0.9236666560173035, 0.940...   \n",
            "1  [0.8648666739463806, 0.9231166839599609, 0.935...   \n",
            "2  [0.8630499839782715, 0.9223499894142151, 0.934...   \n",
            "3  [0.861466646194458, 0.9171666502952576, 0.9309...   \n",
            "4  [0.8608499765396118, 0.9120166897773743, 0.928...   \n",
            "\n",
            "                                  history_train_loss  \n",
            "0  [1.7612853050231934, 0.3980737030506134, 0.232...  \n",
            "1  [2.221606969833374, 0.5513030886650085, 0.2889...  \n",
            "2  [3.1047916412353516, 0.7570062279701233, 0.389...  \n",
            "3  [2.903733968734741, 0.5294719934463501, 0.2888...  \n",
            "4  [3.1085143089294434, 0.5468863248825073, 0.286...  \n",
            "Processing 7bit70p\n",
            "{'0000': 0.0, '0001': 91.24, '0010': 71.783, '0011': 132.36100000000002, '0100': 59.312, '0101': 126.88199999999999, '0110': 106.38, '0111': 148.548, '1000': 50.751999999999995, '1001': 123.697, '1010': 102.935, '1011': 149.04899999999998, '1100': 89.082, '1101': 143.38, '1110': 121.655, '1111': 158.194, '10000': 44.638999999999996, '10001': 121.56400000000001, '10010': 101.265, '10011': 149.284, '10100': 87.28099999999999, '10101': 143.881, '10110': 123.034, '10111': 159.732, '11000': 77.379, '11001': 140.029, '11010': 119.31899999999999, '11011': 159.443, '11100': 104.052, '11101': 153.359, '11110': 131.815, '11111': 165.585, '100000': 39.9, '100001': 119.546, '100010': 99.662, '100011': 149.557, '100100': 86.29599999999999, '100101': 144.211, '100110': 123.622, '100111': 160.83800000000002, '101000': 76.514, '101001': 140.534, '101010': 119.967, '101011': 160.693, '101100': 105.363, '101101': 154.718, '101110': 133.784, '101111': 167.31099999999998, '110000': 68.93199999999999, '110001': 137.261, '110010': 117.215, '110011': 160.022, '110100': 102.81899999999999, '110101': 154.419, '110110': 133.894, '110111': 168.183, '111000': 91.627, '111001': 149.459, '111010': 129.395, '111011': 166.794, '111100': 114.276, '111101': 160.689, '111110': 139.924, '111111': 171.902, '1000000': 36.382, '1000001': 118.202, '1000010': 98.365, '1000011': 149.37, '1000100': 85.38600000000001, '1000101': 144.466, '1000110': 123.91000000000001, '1000111': 161.577, '1001000': 76.126, '1001001': 141.13899999999998, '1001010': 120.654, '1001011': 161.546, '1001100': 106.374, '1001101': 155.905, '1001110': 135.12099999999998, '1001111': 168.631, '1010000': 68.536, '1010001': 138.01, '1010010': 117.639, '1010011': 161.15099999999998, '1010100': 103.923, '1010101': 155.693, '1010110': 135.183, '1010111': 169.56099999999998, '1011000': 93.06200000000001, '1011001': 151.34300000000002, '1011010': 131.22, '1011011': 168.721, '1011100': 116.08699999999999, '1011101': 162.654, '1011110': 141.853, '1011111': 173.709, '1100000': 62.308, '1100001': 135.148, '1100010': 115.384, '1100011': 160.335, '1100100': 101.894, '1100101': 155.101, '1100110': 134.84199999999998, '1100111': 169.504, '1101000': 91.322, '1101001': 150.732, '1101010': 130.782, '1101011': 168.846, '1101100': 116.146, '1101101': 163.223, '1101110': 142.539, '1101111': 174.458, '1110000': 82.033, '1110001': 146.68800000000002, '1110010': 126.86, '1110011': 167.246, '1110100': 112.791, '1110101': 161.739, '1110110': 141.45, '1110111': 174.309, '1111000': 101.23899999999999, '1111001': 156.675, '1111010': 136.798, '1111011': 172.85600000000002, '1111100': 122.02499999999999, '1111101': 166.785, '1111110': 146.455, '1111111': 177.43300000000002}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 60000/60000 [02:09<00:00, 462.75it/s]\n",
            "100%|██████████| 10000/10000 [00:22<00:00, 449.25it/s]\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "<ipython-input-76-dc9983b947f2>:44: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  analysis_df = analysis_df.append({\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    config  val_accuracy  val_loss  \\\n",
            "0  4bit30p        0.9659  0.171998   \n",
            "1  4bit40p        0.9629  0.169417   \n",
            "2  4bit50p        0.9618  0.180078   \n",
            "3  4bit60p        0.9604  0.207152   \n",
            "4  4bit70p        0.9573  0.214989   \n",
            "\n",
            "                                     history_val_acc  \\\n",
            "0  [0.9089999794960022, 0.9362000226974487, 0.937...   \n",
            "1  [0.9169999957084656, 0.9271000027656555, 0.942...   \n",
            "2  [0.9168999791145325, 0.9251000285148621, 0.927...   \n",
            "3  [0.9065999984741211, 0.9140999913215637, 0.925...   \n",
            "4  [0.9067000150680542, 0.9178000092506409, 0.923...   \n",
            "\n",
            "                                    history_val_loss  \\\n",
            "0  [0.5961990356445312, 0.2810992896556854, 0.243...   \n",
            "1  [0.7165398597717285, 0.40322554111480713, 0.24...   \n",
            "2  [1.0729739665985107, 0.5806041359901428, 0.340...   \n",
            "3  [0.7896328568458557, 0.39091727137565613, 0.29...   \n",
            "4  [0.8529000282287598, 0.3971153795719147, 0.286...   \n",
            "\n",
            "                                   history_train_acc  \\\n",
            "0  [0.8606666922569275, 0.9236666560173035, 0.940...   \n",
            "1  [0.8648666739463806, 0.9231166839599609, 0.935...   \n",
            "2  [0.8630499839782715, 0.9223499894142151, 0.934...   \n",
            "3  [0.861466646194458, 0.9171666502952576, 0.9309...   \n",
            "4  [0.8608499765396118, 0.9120166897773743, 0.928...   \n",
            "\n",
            "                                  history_train_loss  \n",
            "0  [1.7612853050231934, 0.3980737030506134, 0.232...  \n",
            "1  [2.221606969833374, 0.5513030886650085, 0.2889...  \n",
            "2  [3.1047916412353516, 0.7570062279701233, 0.389...  \n",
            "3  [2.903733968734741, 0.5294719934463501, 0.2888...  \n",
            "4  [3.1085143089294434, 0.5468863248825073, 0.286...  \n",
            "Processing 8bit30p\n",
            "{'0000': 0.0, '0001': 24.135, '0010': 19.869999999999997, '0011': 54.163000000000004, '0100': 16.369999999999997, '0101': 42.324, '0110': 43.971999999999994, '0111': 74.917, '1000': 13.898000000000001, '1001': 40.234, '1010': 35.129, '1011': 67.427, '1100': 36.498999999999995, '1101': 60.787, '1110': 61.293, '1111': 89.449, '10000': 12.269, '10001': 38.485, '10010': 33.547, '10011': 66.107, '10100': 29.676000000000002, '10101': 54.797, '10110': 55.567, '10111': 84.87400000000001, '11000': 31.487000000000002, '11001': 56.431000000000004, '11010': 51.355, '11011': 81.494, '11100': 51.553000000000004, '11101': 74.734, '11110': 74.1, '11111': 100.40599999999999, '100000': 10.915, '100001': 37.348, '100010': 32.444, '100011': 65.27, '100100': 28.455000000000002, '100101': 53.46, '100110': 54.655, '100111': 84.241, '101000': 25.916999999999998, '101001': 51.348, '101010': 46.246, '101011': 77.49000000000001, '101100': 47.033, '101101': 70.74900000000001, '101110': 70.35, '101111': 97.43400000000001, '110000': 27.838, '110001': 53.153999999999996, '110010': 48.139, '110011': 79.208, '110100': 44.112, '110101': 68.095, '110110': 68.555, '110111': 96.113, '111000': 44.949000000000005, '111001': 69.18299999999999, '111010': 63.983, '111011': 92.97999999999999, '111100': 63.56399999999999, '111101': 85.99600000000001, '111110': 84.6, '111111': 109.77199999999999, '1000000': 9.988, '1000001': 36.742999999999995, '1000010': 31.726999999999997, '1000011': 65.118, '1000100': 27.813000000000002, '1000101': 53.497, '1000110': 54.348, '1000111': 84.07199999999999, '1001000': 25.044, '1001001': 50.786, '1001010': 45.758, '1001011': 77.238, '1001100': 46.656000000000006, '1001101': 70.56800000000001, '1001110': 70.319, '1001111': 97.574, '1010000': 23.181, '1010001': 49.099999999999994, '1010010': 44.083999999999996, '1010011': 75.877, '1010100': 39.995000000000005, '1010101': 64.895, '1010110': 65.15799999999999, '1010111': 93.60300000000001, '1011000': 41.354, '1011001': 65.954, '1011010': 60.671, '1011011': 90.26, '1011100': 60.477999999999994, '1011101': 83.461, '1011110': 82.29599999999999, '1011111': 108.10300000000001, '1100000': 25.22, '1100001': 51.261, '1100010': 46.141, '1100011': 78.05499999999999, '1100100': 42.065, '1100101': 66.69600000000001, '1100110': 66.98700000000001, '1100111': 95.304, '1101000': 39.167, '1101001': 64.227, '1101010': 58.905, '1101011': 88.836, '1101100': 59.189, '1101101': 82.281, '1101110': 81.006, '1101111': 107.21799999999999, '1110000': 40.341, '1110001': 65.576, '1110010': 60.023, '1110011': 90.26, '1110100': 56.034, '1110101': 79.393, '1110110': 79.07000000000001, '1110111': 105.50099999999999, '1111000': 56.038, '1111001': 79.82300000000001, '1111010': 74.203, '1111011': 102.235, '1111100': 73.034, '1111101': 95.152, '1111110': 93.13000000000001, '1111111': 117.393, '10000000': 9.206000000000001, '10000001': 36.204, '10000010': 31.038, '10000011': 64.704, '10000100': 27.072, '10000101': 52.87, '10000110': 53.634, '10000111': 83.98899999999999, '10001000': 24.42, '10001001': 50.339, '10001010': 45.289, '10001011': 76.86800000000001, '10001100': 46.146, '10001101': 70.362, '10001110': 70.044, '10001111': 97.696, '10010000': 22.414, '10010001': 48.705999999999996, '10010010': 43.471000000000004, '10010011': 75.502, '10010100': 39.433, '10010101': 64.336, '10010110': 64.749, '10010111': 93.209, '10011000': 40.899, '10011001': 65.753, '10011010': 60.276999999999994, '10011011': 89.964, '10011100': 60.307, '10011101': 83.19600000000001, '10011110': 81.868, '10011111': 107.781, '10100000': 21.046, '10100001': 47.384, '10100010': 42.295, '10100011': 74.57600000000001, '10100100': 38.106, '10100101': 63.359, '10100110': 63.69800000000001, '10100111': 92.467, '10101000': 35.304, '10101001': 60.713, '10101010': 55.771, '10101011': 85.941, '10101100': 55.833, '10101101': 79.25, '10101110': 78.644, '10101111': 105.089, '10110000': 36.871, '10110001': 62.406000000000006, '10110010': 56.908, '10110011': 87.56, '10110100': 52.739000000000004, '10110101': 76.569, '10110110': 76.35799999999999, '10110111': 103.64, '10111000': 53.381, '10111001': 77.246, '10111010': 71.6, '10111011': 99.899, '10111100': 70.926, '10111101': 93.068, '10111110': 91.152, '10111111': 115.93100000000001, '11000000': 23.133999999999997, '11000001': 49.443, '11000010': 44.367, '11000011': 76.335, '11000100': 39.655, '11000101': 64.19999999999999, '11000110': 64.536, '11000111': 92.631, '11001000': 36.815, '11001001': 61.317, '11001010': 56.298, '11001011': 86.146, '11001100': 56.935, '11001101': 79.827, '11001110': 78.8, '11001111': 105.027, '11010000': 34.637, '11010001': 60.117, '11010010': 54.57, '11010011': 85.21199999999999, '11010100': 50.83, '11010101': 74.369, '11010110': 74.23599999999999, '11010111': 101.425, '11011000': 51.647, '11011001': 75.455, '11011010': 70.075, '11011011': 97.93, '11011100': 69.403, '11011101': 91.102, '11011110': 90.01, '11011111': 114.135, '11100000': 36.094, '11100001': 61.324999999999996, '11100010': 56.099000000000004, '11100011': 86.72, '11100100': 52.073, '11100101': 75.806, '11100110': 75.74799999999999, '11100111': 102.792, '11101000': 49.132000000000005, '11101001': 73.228, '11101010': 67.981, '11101011': 96.69500000000001, '11101100': 67.858, '11101101': 89.753, '11101110': 88.514, '11101111': 113.113, '11110000': 49.686, '11110001': 73.85, '11110010': 68.423, '11110011': 97.438, '11110100': 64.264, '11110101': 86.872, '11110110': 86.06400000000001, '11110111': 111.473, '11111000': 64.116, '11111001': 86.70899999999999, '11111010': 81.246, '11111011': 107.767, '11111100': 80.07400000000001, '11111101': 101.259, '11111110': 99.13900000000001, '11111111': 122.223}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 60000/60000 [02:09<00:00, 463.99it/s]\n",
            "100%|██████████| 10000/10000 [00:21<00:00, 469.30it/s]\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "<ipython-input-76-dc9983b947f2>:44: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  analysis_df = analysis_df.append({\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    config  val_accuracy  val_loss  \\\n",
            "0  4bit30p        0.9659  0.171998   \n",
            "1  4bit40p        0.9629  0.169417   \n",
            "2  4bit50p        0.9618  0.180078   \n",
            "3  4bit60p        0.9604  0.207152   \n",
            "4  4bit70p        0.9573  0.214989   \n",
            "\n",
            "                                     history_val_acc  \\\n",
            "0  [0.9089999794960022, 0.9362000226974487, 0.937...   \n",
            "1  [0.9169999957084656, 0.9271000027656555, 0.942...   \n",
            "2  [0.9168999791145325, 0.9251000285148621, 0.927...   \n",
            "3  [0.9065999984741211, 0.9140999913215637, 0.925...   \n",
            "4  [0.9067000150680542, 0.9178000092506409, 0.923...   \n",
            "\n",
            "                                    history_val_loss  \\\n",
            "0  [0.5961990356445312, 0.2810992896556854, 0.243...   \n",
            "1  [0.7165398597717285, 0.40322554111480713, 0.24...   \n",
            "2  [1.0729739665985107, 0.5806041359901428, 0.340...   \n",
            "3  [0.7896328568458557, 0.39091727137565613, 0.29...   \n",
            "4  [0.8529000282287598, 0.3971153795719147, 0.286...   \n",
            "\n",
            "                                   history_train_acc  \\\n",
            "0  [0.8606666922569275, 0.9236666560173035, 0.940...   \n",
            "1  [0.8648666739463806, 0.9231166839599609, 0.935...   \n",
            "2  [0.8630499839782715, 0.9223499894142151, 0.934...   \n",
            "3  [0.861466646194458, 0.9171666502952576, 0.9309...   \n",
            "4  [0.8608499765396118, 0.9120166897773743, 0.928...   \n",
            "\n",
            "                                  history_train_loss  \n",
            "0  [1.7612853050231934, 0.3980737030506134, 0.232...  \n",
            "1  [2.221606969833374, 0.5513030886650085, 0.2889...  \n",
            "2  [3.1047916412353516, 0.7570062279701233, 0.389...  \n",
            "3  [2.903733968734741, 0.5294719934463501, 0.2888...  \n",
            "4  [3.1085143089294434, 0.5468863248825073, 0.286...  \n",
            "Processing 8bit40p\n",
            "{'0000': 0.0, '0001': 44.646, '0010': 36.05, '0011': 84.763, '0100': 29.732000000000003, '0101': 72.825, '0110': 68.319, '0111': 108.276, '1000': 25.508, '1001': 69.63, '1010': 59.838, '1011': 102.81, '1100': 56.823, '1101': 95.175, '1110': 88.005, '1111': 122.406, '10000': 22.325999999999997, '10001': 67.26899999999999, '10010': 57.45, '10011': 101.328, '10100': 50.476, '10101': 90.48599999999999, '10110': 84.077, '10111': 120.397, '11000': 49.327999999999996, '11001': 89.78800000000001, '11010': 79.211, '11011': 117.538, '11100': 74.35300000000001, '11101': 109.559, '11110': 101.29599999999999, '11111': 132.963, '100000': 19.980999999999998, '100001': 65.405, '100010': 55.682, '100011': 100.36, '100100': 48.754, '100101': 89.127, '100110': 83.183, '100111': 119.65299999999999, '101000': 43.842, '101001': 85.08699999999999, '101010': 75.21700000000001, '101011': 114.858, '101100': 71.30799999999999, '101101': 107.214, '101110': 99.258, '101111': 131.683, '110000': 43.507999999999996, '110001': 85.634, '110010': 75.21600000000001, '110011': 115.236, '110100': 68.013, '110101': 104.725, '110110': 97.666, '110111': 130.832, '111000': 64.886, '111001': 103.089, '111010': 92.481, '111011': 128.084, '111100': 86.889, '111101': 119.82900000000001, '111110': 111.166, '111111': 140.657, '1000000': 18.022, '1000001': 63.71300000000001, '1000010': 54.371, '1000011': 99.136, '1000100': 47.36, '1000101': 88.00099999999999, '1000110': 82.163, '1000111': 119.449, '1001000': 42.494, '1001001': 84.551, '1001010': 74.43900000000001, '1001011': 114.512, '1001100': 70.74600000000001, '1001101': 107.277, '1001110': 99.18, '1001111': 131.96, '1010000': 39.029, '1010001': 81.834, '1010010': 71.801, '1010011': 112.86699999999999, '1010100': 64.631, '1010101': 102.037, '1010110': 95.546, '1010111': 129.446, '1011000': 62.239999999999995, '1011001': 101.069, '1011010': 90.746, '1011011': 126.75500000000001, '1011100': 85.288, '1011101': 118.681, '1011110': 110.131, '1011111': 140.072, '1100000': 39.041, '1100001': 82.539, '1100010': 72.625, '1100011': 113.86, '1100100': 65.205, '1100101': 103.208, '1100110': 96.734, '1100111': 130.78500000000003, '1101000': 60.172999999999995, '1101001': 99.75, '1101010': 88.938, '1101011': 126.107, '1101100': 84.163, '1101101': 118.294, '1101110': 109.936, '1101111': 140.36100000000002, '1110000': 57.812000000000005, '1110001': 98.287, '1110010': 88.115, '1110011': 125.801, '1110100': 80.30199999999999, '1110101': 115.463, '1110110': 107.759, '1110111': 139.22799999999998, '1111000': 76.612, '1111001': 113.131, '1111010': 102.523, '1111011': 136.274, '1111100': 96.271, '1111101': 127.81, '1111110': 118.869, '1111111': 147.074, '10000000': 16.639999999999997, '10000001': 62.65800000000001, '10000010': 53.034, '10000011': 98.509, '10000100': 46.184999999999995, '10000101': 86.842, '10000110': 81.563, '10000111': 119.101, '10001000': 41.488, '10001001': 83.13900000000001, '10001010': 73.599, '10001011': 114.39, '10001100': 70.279, '10001101': 106.761, '10001110': 99.231, '10001111': 131.768, '10010000': 38.190000000000005, '10010001': 81.408, '10010010': 71.6, '10010011': 113.125, '10010100': 64.328, '10010101': 102.718, '10010110': 95.671, '10010111': 129.715, '10011000': 61.941, '10011001': 100.732, '10011010': 90.277, '10011011': 126.81500000000001, '10011100': 85.107, '10011101': 118.468, '10011110': 110.344, '10011111': 140.45499999999998, '10100000': 35.577999999999996, '10100001': 79.60000000000001, '10100010': 69.324, '10100011': 111.645, '10100100': 62.237, '10100101': 100.952, '10100110': 94.67299999999999, '10100111': 129.32, '10101000': 57.287, '10101001': 97.384, '10101010': 86.926, '10101011': 124.82799999999999, '10101100': 82.47699999999999, '10101101': 116.857, '10101110': 108.599, '10101111': 139.503, '10110000': 55.931000000000004, '10110001': 96.69500000000001, '10110010': 86.372, '10110011': 124.384, '10110100': 78.673, '10110101': 114.052, '10110110': 106.74300000000001, '10110111': 138.687, '10111000': 75.423, '10111001': 112.004, '10111010': 101.44300000000001, '10111011': 135.647, '10111100': 95.503, '10111101': 127.551, '10111110': 118.72399999999999, '10111111': 146.95600000000002, '11000000': 35.816, '11000001': 79.99499999999999, '11000010': 70.101, '11000011': 112.666, '11000100': 63.013, '11000101': 101.669, '11000110': 94.873, '11000111': 129.84, '11001000': 57.84, '11001001': 97.747, '11001010': 87.72099999999999, '11001011': 125.647, '11001100': 83.53099999999999, '11001101': 117.836, '11001110': 109.05199999999999, '11001111': 140.151, '11010000': 54.071, '11010001': 95.271, '11010010': 85.118, '11010011': 123.882, '11010100': 77.732, '11010101': 113.631, '11010110': 106.497, '11010111': 138.44500000000002, '11011000': 74.549, '11011001': 111.43, '11011010': 101.122, '11011011': 135.698, '11011100': 95.709, '11011101': 127.72800000000001, '11011110': 119.01, '11011111': 147.696, '11100000': 52.674, '11100001': 94.498, '11100010': 84.333, '11100011': 123.907, '11100100': 77.019, '11100101': 113.405, '11100110': 105.617, '11100111': 138.762, '11101000': 71.596, '11101001': 109.391, '11101010': 99.162, '11101011': 134.403, '11101100': 93.93799999999999, '11101101': 126.56899999999999, '11101110': 118.088, '11101111': 147.22299999999998, '11110000': 68.757, '11110001': 107.296, '11110010': 97.30999999999999, '11110011': 133.36700000000002, '11110100': 89.734, '11110101': 123.655, '11110110': 115.773, '11110111': 145.662, '11111000': 85.363, '11111001': 120.529, '11111010': 110.057, '11111011': 142.542, '11111100': 103.743, '11111101': 134.299, '11111110': 125.17, '11111111': 152.612}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 60000/60000 [02:12<00:00, 454.11it/s]\n",
            "100%|██████████| 10000/10000 [00:20<00:00, 479.27it/s]\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "<ipython-input-76-dc9983b947f2>:44: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  analysis_df = analysis_df.append({\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    config  val_accuracy  val_loss  \\\n",
            "0  4bit30p        0.9659  0.171998   \n",
            "1  4bit40p        0.9629  0.169417   \n",
            "2  4bit50p        0.9618  0.180078   \n",
            "3  4bit60p        0.9604  0.207152   \n",
            "4  4bit70p        0.9573  0.214989   \n",
            "\n",
            "                                     history_val_acc  \\\n",
            "0  [0.9089999794960022, 0.9362000226974487, 0.937...   \n",
            "1  [0.9169999957084656, 0.9271000027656555, 0.942...   \n",
            "2  [0.9168999791145325, 0.9251000285148621, 0.927...   \n",
            "3  [0.9065999984741211, 0.9140999913215637, 0.925...   \n",
            "4  [0.9067000150680542, 0.9178000092506409, 0.923...   \n",
            "\n",
            "                                    history_val_loss  \\\n",
            "0  [0.5961990356445312, 0.2810992896556854, 0.243...   \n",
            "1  [0.7165398597717285, 0.40322554111480713, 0.24...   \n",
            "2  [1.0729739665985107, 0.5806041359901428, 0.340...   \n",
            "3  [0.7896328568458557, 0.39091727137565613, 0.29...   \n",
            "4  [0.8529000282287598, 0.3971153795719147, 0.286...   \n",
            "\n",
            "                                   history_train_acc  \\\n",
            "0  [0.8606666922569275, 0.9236666560173035, 0.940...   \n",
            "1  [0.8648666739463806, 0.9231166839599609, 0.935...   \n",
            "2  [0.8630499839782715, 0.9223499894142151, 0.934...   \n",
            "3  [0.861466646194458, 0.9171666502952576, 0.9309...   \n",
            "4  [0.8608499765396118, 0.9120166897773743, 0.928...   \n",
            "\n",
            "                                  history_train_loss  \n",
            "0  [1.7612853050231934, 0.3980737030506134, 0.232...  \n",
            "1  [2.221606969833374, 0.5513030886650085, 0.2889...  \n",
            "2  [3.1047916412353516, 0.7570062279701233, 0.389...  \n",
            "3  [2.903733968734741, 0.5294719934463501, 0.2888...  \n",
            "4  [3.1085143089294434, 0.5468863248825073, 0.286...  \n",
            "Processing 8bit50p\n",
            "{'0000': 0.0, '0001': 63.512, '0010': 50.683, '0011': 107.619, '0100': 41.744, '0101': 96.608, '0110': 85.7, '0111': 128.64999999999998, '1000': 35.471999999999994, '1001': 93.071, '1010': 78.548, '1011': 125.727, '1100': 71.62, '1101': 118.629, '1110': 105.02499999999999, '1111': 141.30499999999998, '10000': 31.186, '10001': 90.31, '10010': 76.241, '10011': 125.029, '10100': 66.689, '10101': 115.64399999999999, '10110': 103.09400000000001, '10111': 140.506, '11000': 61.969, '11001': 113.244, '11010': 98.59, '11011': 139.10500000000002, '11100': 89.015, '11101': 131.15099999999998, '11110': 117.185, '11111': 149.705, '100000': 27.697, '100001': 88.182, '100010': 74.43299999999999, '100011': 124.186, '100100': 65.003, '100101': 114.589, '100110': 102.62400000000001, '100111': 140.785, '101000': 57.986999999999995, '101001': 110.125, '101010': 95.589, '101011': 137.69600000000003, '101100': 87.089, '101101': 129.266, '101110': 115.876, '101111': 149.41199999999998, '110000': 54.692, '110001': 108.882, '110010': 94.586, '110011': 137.923, '110100': 84.25, '110101': 128.94, '110110': 115.741, '110111': 150.01999999999998, '111000': 77.66199999999999, '111001': 125.14500000000001, '111010': 110.348, '111011': 148.057, '111100': 100.446, '111101': 140.005, '111110': 125.82799999999999, '111111': 156.986, '1000000': 25.395, '1000001': 86.55799999999999, '1000010': 72.414, '1000011': 123.38300000000001, '1000100': 63.284000000000006, '1000101': 113.666, '1000110': 101.70700000000001, '1000111': 140.624, '1001000': 56.63, '1001001': 109.83800000000001, '1001010': 95.513, '1001011': 137.703, '1001100': 87.28, '1001101': 130.719, '1001110': 116.842, '1001111': 150.249, '1010000': 51.637, '1010001': 106.565, '1010010': 92.449, '1010011': 136.825, '1010100': 82.553, '1010101': 127.934, '1010110': 115.04, '1010111': 149.92, '1011000': 76.727, '1011001': 124.702, '1011010': 109.931, '1011011': 147.961, '1011100': 100.39399999999999, '1011101': 140.15800000000002, '1011110': 125.998, '1011111': 157.183, '1100000': 49.465, '1100001': 105.714, '1100010': 91.611, '1100011': 136.67399999999998, '1100100': 81.718, '1100101': 127.81300000000002, '1100110': 115.01899999999999, '1100111': 150.26999999999998, '1101000': 74.43299999999999, '1101001': 123.158, '1101010': 108.727, '1101011': 147.65800000000002, '1101100': 99.498, '1101101': 139.937, '1101110': 126.12, '1101111': 157.667, '1110000': 69.497, '1110001': 119.994, '1110010': 105.987, '1110011': 146.248, '1110100': 95.72, '1110101': 137.536, '1110110': 124.516, '1110111': 157.138, '1111000': 88.52, '1111001': 133.376, '1111010': 119.108, '1111011': 154.50300000000001, '1111100': 108.93700000000001, '1111101': 146.657, '1111110': 132.769, '1111111': 162.561, '10000000': 23.220000000000002, '10000001': 85.08699999999999, '10000010': 70.904, '10000011': 121.887, '10000100': 61.35, '10000101': 112.608, '10000110': 100.988, '10000111': 139.95, '10001000': 55.196000000000005, '10001001': 108.222, '10001010': 94.602, '10001011': 137.382, '10001100': 86.652, '10001101': 130.041, '10001110': 116.509, '10001111': 150.493, '10010000': 50.152, '10010001': 105.67999999999999, '10010010': 91.49, '10010011': 136.067, '10010100': 81.716, '10010101': 126.726, '10010110': 114.475, '10010111': 149.667, '10011000': 76.357, '10011001': 124.261, '10011010': 109.846, '10011011': 147.763, '10011100': 100.26100000000001, '10011101': 140.13, '10011110': 125.856, '10011111': 157.21699999999998, '10100000': 46.323, '10100001': 102.855, '10100010': 88.98100000000001, '10100011': 134.896, '10100100': 79.486, '10100101': 125.50500000000001, '10100110': 113.416, '10100111': 149.482, '10101000': 72.47099999999999, '10101001': 121.798, '10101010': 107.393, '10101011': 147.142, '10101100': 99.161, '10101101': 139.71800000000002, '10101110': 125.944, '10101111': 157.74699999999999, '10110000': 68.52900000000001, '10110001': 119.947, '10110010': 105.511, '10110011': 146.339, '10110100': 95.436, '10110101': 137.72699999999998, '10110110': 124.53200000000001, '10110111': 157.581, '10111000': 88.574, '10111001': 133.427, '10111010': 118.854, '10111011': 154.75900000000001, '10111100': 109.03999999999999, '10111101': 146.813, '10111110': 133.177, '10111111': 162.994, '11000000': 44.991, '11000001': 102.346, '11000010': 88.66499999999999, '11000011': 134.88400000000001, '11000100': 79.156, '11000101': 126.547, '11000110': 114.122, '11000111': 149.998, '11001000': 72.188, '11001001': 121.52799999999999, '11001010': 107.44, '11001011': 147.28900000000002, '11001100': 99.33500000000001, '11001101': 140.055, '11001110': 126.30199999999999, '11001111': 158.378, '11010000': 66.756, '11010001': 118.412, '11010010': 104.631, '11010011': 146.148, '11010100': 94.433, '11010101': 136.972, '11010110': 124.298, '11010111': 157.462, '11011000': 88.207, '11011001': 133.40099999999998, '11011010': 118.92999999999999, '11011011': 155.04399999999998, '11011100': 109.346, '11011101': 147.29500000000002, '11011110': 133.601, '11011111': 163.61999999999998, '11100000': 62.815999999999995, '11100001': 116.233, '11100010': 102.015, '11100011': 144.475, '11100100': 92.277, '11100101': 136.06799999999998, '11100110': 123.641, '11100111': 157.118, '11101000': 84.94200000000001, '11101001': 131.493, '11101010': 117.093, '11101011': 154.388, '11101100': 108.337, '11101101': 146.847, '11101110': 133.271, '11101111': 163.477, '11110000': 79.528, '11110001': 128.196, '11110010': 114.077, '11110011': 152.828, '11110100': 103.95500000000001, '11110101': 144.174, '11110110': 131.341, '11110111': 162.59799999999998, '11111000': 96.665, '11111001': 140.261, '11111010': 125.93299999999999, '11111011': 160.309, '11111100': 116.08300000000001, '11111101': 152.756, '11111110': 138.933, '11111111': 167.863}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 60000/60000 [02:10<00:00, 460.47it/s]\n",
            "100%|██████████| 10000/10000 [00:22<00:00, 449.59it/s]\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "<ipython-input-76-dc9983b947f2>:44: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  analysis_df = analysis_df.append({\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    config  val_accuracy  val_loss  \\\n",
            "0  4bit30p        0.9659  0.171998   \n",
            "1  4bit40p        0.9629  0.169417   \n",
            "2  4bit50p        0.9618  0.180078   \n",
            "3  4bit60p        0.9604  0.207152   \n",
            "4  4bit70p        0.9573  0.214989   \n",
            "\n",
            "                                     history_val_acc  \\\n",
            "0  [0.9089999794960022, 0.9362000226974487, 0.937...   \n",
            "1  [0.9169999957084656, 0.9271000027656555, 0.942...   \n",
            "2  [0.9168999791145325, 0.9251000285148621, 0.927...   \n",
            "3  [0.9065999984741211, 0.9140999913215637, 0.925...   \n",
            "4  [0.9067000150680542, 0.9178000092506409, 0.923...   \n",
            "\n",
            "                                    history_val_loss  \\\n",
            "0  [0.5961990356445312, 0.2810992896556854, 0.243...   \n",
            "1  [0.7165398597717285, 0.40322554111480713, 0.24...   \n",
            "2  [1.0729739665985107, 0.5806041359901428, 0.340...   \n",
            "3  [0.7896328568458557, 0.39091727137565613, 0.29...   \n",
            "4  [0.8529000282287598, 0.3971153795719147, 0.286...   \n",
            "\n",
            "                                   history_train_acc  \\\n",
            "0  [0.8606666922569275, 0.9236666560173035, 0.940...   \n",
            "1  [0.8648666739463806, 0.9231166839599609, 0.935...   \n",
            "2  [0.8630499839782715, 0.9223499894142151, 0.934...   \n",
            "3  [0.861466646194458, 0.9171666502952576, 0.9309...   \n",
            "4  [0.8608499765396118, 0.9120166897773743, 0.928...   \n",
            "\n",
            "                                  history_train_loss  \n",
            "0  [1.7612853050231934, 0.3980737030506134, 0.232...  \n",
            "1  [2.221606969833374, 0.5513030886650085, 0.2889...  \n",
            "2  [3.1047916412353516, 0.7570062279701233, 0.389...  \n",
            "3  [2.903733968734741, 0.5294719934463501, 0.2888...  \n",
            "4  [3.1085143089294434, 0.5468863248825073, 0.286...  \n",
            "Processing 8bit60p\n",
            "{'0000': 0.0, '0001': 78.902, '0010': 62.305, '0011': 122.501, '0100': 51.285, '0101': 114.197, '0110': 97.76, '0111': 140.817, '1000': 43.721999999999994, '1001': 110.511, '1010': 92.73299999999999, '1011': 139.933, '1100': 81.955, '1101': 133.52100000000002, '1110': 115.188, '1111': 151.583, '10000': 38.362, '10001': 107.044, '10010': 90.093, '10011': 139.475, '10100': 78.334, '10101': 131.599, '10110': 114.285, '10111': 152.221, '11000': 71.048, '11001': 129.103, '11010': 110.931, '11011': 151.75900000000001, '11100': 98.105, '11101': 144.413, '11110': 125.95799999999998, '11111': 159.458, '100000': 34.42400000000001, '100001': 106.16000000000001, '100010': 88.593, '100011': 139.24, '100100': 76.906, '100101': 131.88400000000001, '100110': 114.94, '100111': 152.976, '101000': 68.373, '101001': 128.103, '101010': 109.913, '101011': 152.031, '101100': 98.521, '101101': 145.263, '101110': 127.05900000000001, '101111': 160.736, '110000': 63.099000000000004, '110001': 125.694, '110010': 107.879, '110011': 151.51500000000001, '110100': 95.389, '110101': 144.474, '110110': 126.894, '110111': 161.508, '111000': 86.139, '111001': 139.958, '111010': 121.984, '111011': 159.686, '111100': 108.97900000000001, '111101': 152.68200000000002, '111110': 134.625, '111111': 166.33800000000002, '1000000': 31.573999999999998, '1000001': 105.13, '1000010': 87.733, '1000011': 139.453, '1000100': 75.71700000000001, '1000101': 131.515, '1000110': 115.293, '1000111': 153.808, '1001000': 67.93, '1001001': 128.152, '1001010': 110.389, '1001011': 152.669, '1001100': 98.702, '1001101': 146.218, '1001110': 128.02700000000002, '1001111': 161.776, '1010000': 61.379000000000005, '1010001': 125.22800000000001, '1010010': 107.67500000000001, '1010011': 152.101, '1010100': 95.576, '1010101': 144.741, '1010110': 127.45600000000002, '1010111': 162.14700000000002, '1011000': 86.701, '1011001': 140.857, '1011010': 123.016, '1011011': 160.875, '1011100': 110.148, '1011101': 153.90200000000002, '1011110': 135.89499999999998, '1011111': 167.555, '1100000': 57.214, '1100001': 123.443, '1100010': 105.703, '1100011': 151.45, '1100100': 93.947, '1100101': 144.664, '1100110': 127.476, '1100111': 162.496, '1101000': 84.56700000000001, '1101001': 140.06099999999998, '1101010': 122.203, '1101011': 161.23299999999998, '1101100': 110.196, '1101101': 154.32100000000003, '1101110': 136.512, '1101111': 168.433, '1110000': 77.258, '1110001': 136.197, '1110010': 118.762, '1110011': 159.025, '1110100': 106.071, '1110101': 152.425, '1110110': 135.126, '1110111': 167.95, '1111000': 96.489, '1111001': 147.74300000000002, '1111010': 129.953, '1111011': 166.17499999999998, '1111100': 117.18299999999999, '1111101': 159.216, '1111110': 141.357, '1111111': 172.197, '10000000': 28.978, '10000001': 103.655, '10000010': 86.277, '10000011': 139.27800000000002, '10000100': 75.17, '10000101': 132.11999999999998, '10000110': 115.17099999999999, '10000111': 153.838, '10001000': 66.947, '10001001': 128.025, '10001010': 110.25500000000001, '10001011': 152.885, '10001100': 98.84400000000001, '10001101': 146.573, '10001110': 128.244, '10001111': 162.295, '10010000': 60.867999999999995, '10010001': 125.21799999999999, '10010010': 107.736, '10010011': 152.251, '10010100': 95.42299999999999, '10010101': 145.283, '10010110': 127.82, '10010111': 162.805, '10011000': 87.254, '10011001': 141.464, '10011010': 123.711, '10011011': 161.73000000000002, '10011100': 110.904, '10011101': 154.73000000000002, '10011110': 136.69899999999998, '10011111': 168.516, '10100000': 55.512, '10100001': 121.857, '10100010': 105.212, '10100011': 151.7, '10100100': 93.589, '10100101': 144.733, '10100110': 128.124, '10100111': 163.398, '10101000': 84.919, '10101001': 141.067, '10101010': 123.214, '10101011': 162.046, '10101100': 110.971, '10101101': 155.595, '10101110': 137.72799999999998, '10101111': 169.763, '10110000': 78.152, '10110001': 137.77, '10110010': 120.112, '10110011': 161.116, '10110100': 107.631, '10110101': 154.105, '10110110': 136.72400000000002, '10110111': 169.515, '10111000': 97.933, '10111001': 149.57999999999998, '10111010': 131.698, '10111011': 167.93, '10111100': 119.00099999999999, '10111101': 161.132, '10111110': 143.279, '10111111': 173.757, '11000000': 52.553999999999995, '11000001': 121.63499999999999, '11000010': 104.209, '11000011': 151.713, '11000100': 92.636, '11000101': 144.786, '11000110': 127.584, '11000111': 163.692, '11001000': 83.915, '11001001': 140.76, '11001010': 122.825, '11001011': 162.44400000000002, '11001100': 111.161, '11001101': 156.12300000000002, '11001110': 138.036, '11001111': 170.097, '11010000': 76.614, '11010001': 137.19600000000003, '11010010': 119.6, '11010011': 161.237, '11010100': 107.458, '11010101': 154.32000000000002, '11010110': 136.786, '11010111': 170.02200000000002, '11011000': 98.17099999999999, '11011001': 149.71699999999998, '11011010': 132.157, '11011011': 168.586, '11011100': 119.399, '11011101': 161.87, '11011110': 143.96900000000002, '11011111': 174.44799999999998, '11100000': 70.55699999999999, '11100001': 133.768, '11100010': 116.241, '11100011': 159.61800000000002, '11100100': 104.535, '11100101': 152.731, '11100110': 135.669, '11100111': 169.441, '11101000': 95.18799999999999, '11101001': 148.476, '11101010': 130.791, '11101011': 168.136, '11101100': 118.69, '11101101': 161.599, '11101110': 143.844, '11101111': 174.685, '11110000': 87.34, '11110001': 144.364, '11110010': 126.92999999999999, '11110011': 166.27, '11110100': 114.51899999999999, '11110101': 159.34599999999998, '11110110': 142.29500000000002, '11110111': 174.108, '11111000': 104.812, '11111001': 154.538, '11111010': 137.083, '11111011': 172.049, '11111100': 124.333, '11111101': 165.30800000000002, '11111110': 147.846, '11111111': 177.823}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 60000/60000 [02:10<00:00, 459.80it/s]\n",
            "100%|██████████| 10000/10000 [00:22<00:00, 450.74it/s]\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n",
            "<ipython-input-76-dc9983b947f2>:44: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  analysis_df = analysis_df.append({\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    config  val_accuracy  val_loss  \\\n",
            "0  4bit30p        0.9659  0.171998   \n",
            "1  4bit40p        0.9629  0.169417   \n",
            "2  4bit50p        0.9618  0.180078   \n",
            "3  4bit60p        0.9604  0.207152   \n",
            "4  4bit70p        0.9573  0.214989   \n",
            "\n",
            "                                     history_val_acc  \\\n",
            "0  [0.9089999794960022, 0.9362000226974487, 0.937...   \n",
            "1  [0.9169999957084656, 0.9271000027656555, 0.942...   \n",
            "2  [0.9168999791145325, 0.9251000285148621, 0.927...   \n",
            "3  [0.9065999984741211, 0.9140999913215637, 0.925...   \n",
            "4  [0.9067000150680542, 0.9178000092506409, 0.923...   \n",
            "\n",
            "                                    history_val_loss  \\\n",
            "0  [0.5961990356445312, 0.2810992896556854, 0.243...   \n",
            "1  [0.7165398597717285, 0.40322554111480713, 0.24...   \n",
            "2  [1.0729739665985107, 0.5806041359901428, 0.340...   \n",
            "3  [0.7896328568458557, 0.39091727137565613, 0.29...   \n",
            "4  [0.8529000282287598, 0.3971153795719147, 0.286...   \n",
            "\n",
            "                                   history_train_acc  \\\n",
            "0  [0.8606666922569275, 0.9236666560173035, 0.940...   \n",
            "1  [0.8648666739463806, 0.9231166839599609, 0.935...   \n",
            "2  [0.8630499839782715, 0.9223499894142151, 0.934...   \n",
            "3  [0.861466646194458, 0.9171666502952576, 0.9309...   \n",
            "4  [0.8608499765396118, 0.9120166897773743, 0.928...   \n",
            "\n",
            "                                  history_train_loss  \n",
            "0  [1.7612853050231934, 0.3980737030506134, 0.232...  \n",
            "1  [2.221606969833374, 0.5513030886650085, 0.2889...  \n",
            "2  [3.1047916412353516, 0.7570062279701233, 0.389...  \n",
            "3  [2.903733968734741, 0.5294719934463501, 0.2888...  \n",
            "4  [3.1085143089294434, 0.5468863248825073, 0.286...  \n",
            "Processing 8bit70p\n",
            "{'0000': 0.0, '0001': 93.03999999999999, '0010': 73.318, '0011': 133.917, '0100': 60.407000000000004, '0101': 128.402, '0110': 107.747, '0111': 149.39600000000002, '1000': 51.309, '1001': 124.872, '1010': 104.05, '1011': 150.31, '1100': 90.393, '1101': 145.01500000000001, '1110': 122.999, '1111': 159.246, '10000': 45.525000000000006, '10001': 123.465, '10010': 102.97099999999999, '10011': 150.901, '10100': 88.83000000000001, '10101': 145.552, '10110': 124.252, '10111': 161.005, '11000': 78.533, '11001': 141.77200000000002, '11010': 120.671, '11011': 160.704, '11100': 105.02, '11101': 154.598, '11110': 132.96099999999998, '11111': 166.506, '100000': 40.823, '100001': 121.612, '100010': 101.355, '100011': 151.209, '100100': 87.84400000000001, '100101': 145.82999999999998, '100110': 124.85300000000001, '100111': 162.0, '101000': 77.575, '101001': 142.239, '101010': 121.49799999999999, '101011': 162.024, '101100': 106.565, '101101': 156.244, '101110': 134.882, '101111': 168.368, '110000': 69.79299999999999, '110001': 138.94500000000002, '110010': 118.478, '110011': 161.184, '110100': 104.173, '110101': 155.766, '110110': 134.888, '110111': 168.917, '111000': 92.193, '111001': 150.98, '111010': 130.53, '111011': 167.916, '111100': 114.803, '111101': 161.727, '111110': 140.77, '111111': 172.702, '1000000': 37.186, '1000001': 120.107, '1000010': 100.096, '1000011': 150.885, '1000100': 86.726, '1000101': 145.578, '1000110': 125.061, '1000111': 162.688, '1001000': 77.069, '1001001': 142.49200000000002, '1001010': 121.852, '1001011': 162.732, '1001100': 107.199, '1001101': 156.987, '1001110': 135.88400000000001, '1001111': 169.284, '1010000': 69.203, '1010001': 139.167, '1010010': 119.11, '1010011': 162.125, '1010100': 104.87, '1010101': 156.695, '1010110': 136.108, '1010111': 170.265, '1011000': 93.86, '1011001': 152.586, '1011010': 132.216, '1011011': 169.51, '1011100': 116.869, '1011101': 163.448, '1011110': 142.6, '1011111': 174.452, '1100000': 63.17100000000001, '1100001': 136.45499999999998, '1100010': 116.562, '1100011': 161.438, '1100100': 102.79, '1100101': 155.924, '1100110': 135.50699999999998, '1100111': 170.33599999999998, '1101000': 91.95100000000001, '1101001': 151.68300000000002, '1101010': 131.52700000000002, '1101011': 169.655, '1101100': 117.131, '1101101': 163.94, '1101110': 143.227, '1101111': 175.22099999999998, '1110000': 82.724, '1110001': 147.74200000000002, '1110010': 127.771, '1110011': 168.152, '1110100': 113.64, '1110101': 162.594, '1110110': 142.33, '1110111': 175.007, '1111000': 101.866, '1111001': 157.78300000000002, '1111010': 137.784, '1111011': 173.75, '1111100': 122.715, '1111101': 167.7, '1111110': 147.127, '1111111': 178.224, '10000000': 34.131, '10000001': 118.495, '10000010': 98.611, '10000011': 150.46300000000002, '10000100': 85.553, '10000101': 145.476, '10000110': 124.85000000000001, '10000111': 162.822, '10001000': 76.262, '10001001': 142.108, '10001010': 121.72800000000001, '10001011': 163.191, '10001100': 107.545, '10001101': 157.257, '10001110': 136.128, '10001111': 170.037, '10010000': 68.9, '10010001': 139.316, '10010010': 119.259, '10010011': 162.826, '10010100': 105.318, '10010101': 157.614, '10010110': 136.942, '10010111': 171.264, '10011000': 94.764, '10011001': 153.484, '10011010': 133.02700000000002, '10011011': 170.507, '10011100': 118.034, '10011101': 164.561, '10011110': 143.704, '10011111': 175.573, '10100000': 62.767, '10100001': 136.67000000000002, '10100010': 116.79299999999999, '10100011': 161.979, '10100100': 103.24, '10100101': 156.857, '10100110': 136.441, '10100111': 171.23499999999999, '10101000': 92.973, '10101001': 152.81300000000002, '10101010': 132.812, '10101011': 170.75, '10101100': 118.27600000000001, '10101101': 165.115, '10101110': 144.40900000000002, '10101111': 176.412, '10110000': 84.18299999999999, '10110001': 148.895, '10110010': 129.179, '10110011': 169.44500000000002, '10110100': 115.161, '10110101': 163.99099999999999, '10110110': 143.83599999999998, '10110111': 176.4, '10111000': 103.55399999999999, '10111001': 159.008, '10111010': 139.201, '10111011': 174.974, '10111100': 124.497, '10111101': 169.27900000000002, '10111110': 148.783, '10111111': 179.694, '11000000': 57.516, '11000001': 133.646, '11000010': 114.07000000000001, '11000011': 160.61700000000002, '11000100': 101.015, '11000101': 155.551, '11000110': 135.343, '11000111': 170.744, '11001000': 91.046, '11001001': 151.856, '11001010': 132.14000000000001, '11001011': 170.601, '11001100': 117.72, '11001101': 164.809, '11001110': 144.35999999999999, '11001111': 176.435, '11010000': 82.62700000000001, '11010001': 148.231, '11010010': 128.528, '11010011': 169.31, '11010100': 114.93299999999999, '11010101': 163.919, '11010110': 144.034, '11010111': 176.648, '11011000': 103.87299999999999, '11011001': 159.418, '11011010': 139.821, '11011011': 175.65200000000002, '11011100': 125.14500000000001, '11011101': 169.875, '11011110': 149.718, '11011111': 180.46200000000002, '11100000': 75.07600000000001, '11100001': 144.334, '11100010': 125.02199999999999, '11100011': 167.604, '11100100': 111.41900000000001, '11100101': 162.281, '11100110': 142.44, '11100111': 175.886, '11101000': 100.907, '11101001': 158.21699999999998, '11101010': 138.55100000000002, '11101011': 175.287, '11101100': 124.35799999999999, '11101101': 169.686, '11101110': 149.502, '11101111': 180.504, '11110000': 91.78999999999999, '11110001': 154.079, '11110010': 134.526, '11110011': 173.626, '11110100': 120.725, '11110101': 168.17399999999998, '11110110': 148.26600000000002, '11110111': 180.072, '11111000': 109.42200000000001, '11111001': 163.242, '11111010': 143.744, '11111011': 178.763, '11111100': 129.37, '11111101': 173.046, '11111110': 152.90699999999998, '11111111': 183.072}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 60000/60000 [02:09<00:00, 461.86it/s]\n",
            "100%|██████████| 10000/10000 [00:21<00:00, 471.34it/s]\n",
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    config  val_accuracy  val_loss  \\\n",
            "0  4bit30p        0.9659  0.171998   \n",
            "1  4bit40p        0.9629  0.169417   \n",
            "2  4bit50p        0.9618  0.180078   \n",
            "3  4bit60p        0.9604  0.207152   \n",
            "4  4bit70p        0.9573  0.214989   \n",
            "\n",
            "                                     history_val_acc  \\\n",
            "0  [0.9089999794960022, 0.9362000226974487, 0.937...   \n",
            "1  [0.9169999957084656, 0.9271000027656555, 0.942...   \n",
            "2  [0.9168999791145325, 0.9251000285148621, 0.927...   \n",
            "3  [0.9065999984741211, 0.9140999913215637, 0.925...   \n",
            "4  [0.9067000150680542, 0.9178000092506409, 0.923...   \n",
            "\n",
            "                                    history_val_loss  \\\n",
            "0  [0.5961990356445312, 0.2810992896556854, 0.243...   \n",
            "1  [0.7165398597717285, 0.40322554111480713, 0.24...   \n",
            "2  [1.0729739665985107, 0.5806041359901428, 0.340...   \n",
            "3  [0.7896328568458557, 0.39091727137565613, 0.29...   \n",
            "4  [0.8529000282287598, 0.3971153795719147, 0.286...   \n",
            "\n",
            "                                   history_train_acc  \\\n",
            "0  [0.8606666922569275, 0.9236666560173035, 0.940...   \n",
            "1  [0.8648666739463806, 0.9231166839599609, 0.935...   \n",
            "2  [0.8630499839782715, 0.9223499894142151, 0.934...   \n",
            "3  [0.861466646194458, 0.9171666502952576, 0.9309...   \n",
            "4  [0.8608499765396118, 0.9120166897773743, 0.928...   \n",
            "\n",
            "                                  history_train_loss  \n",
            "0  [1.7612853050231934, 0.3980737030506134, 0.232...  \n",
            "1  [2.221606969833374, 0.5513030886650085, 0.2889...  \n",
            "2  [3.1047916412353516, 0.7570062279701233, 0.389...  \n",
            "3  [2.903733968734741, 0.5294719934463501, 0.2888...  \n",
            "4  [3.1085143089294434, 0.5468863248825073, 0.286...  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-76-dc9983b947f2>:44: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  analysis_df = analysis_df.append({\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# x = np.array([30]*len(analysis_df['val_accuracy']))\n",
        "# y = analysis_df['val_accuracy']\n",
        "\n",
        "# plt.scatter(x, y)\n",
        "# plt.show()\n",
        "\n",
        "analysis_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "C7knT8pLEVfW",
        "outputId": "32fc87ec-58bf-401c-e917-cde0915b6c13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    config  val_accuracy  val_loss  \\\n",
              "0  4bit30p        0.9659  0.171998   \n",
              "1  4bit40p        0.9629  0.169417   \n",
              "2  4bit50p        0.9618  0.180078   \n",
              "3  4bit60p        0.9604  0.207152   \n",
              "4  4bit70p        0.9573  0.214989   \n",
              "\n",
              "                                     history_val_acc  \\\n",
              "0  [0.9089999794960022, 0.9362000226974487, 0.937...   \n",
              "1  [0.9169999957084656, 0.9271000027656555, 0.942...   \n",
              "2  [0.9168999791145325, 0.9251000285148621, 0.927...   \n",
              "3  [0.9065999984741211, 0.9140999913215637, 0.925...   \n",
              "4  [0.9067000150680542, 0.9178000092506409, 0.923...   \n",
              "\n",
              "                                    history_val_loss  \\\n",
              "0  [0.5961990356445312, 0.2810992896556854, 0.243...   \n",
              "1  [0.7165398597717285, 0.40322554111480713, 0.24...   \n",
              "2  [1.0729739665985107, 0.5806041359901428, 0.340...   \n",
              "3  [0.7896328568458557, 0.39091727137565613, 0.29...   \n",
              "4  [0.8529000282287598, 0.3971153795719147, 0.286...   \n",
              "\n",
              "                                   history_train_acc  \\\n",
              "0  [0.8606666922569275, 0.9236666560173035, 0.940...   \n",
              "1  [0.8648666739463806, 0.9231166839599609, 0.935...   \n",
              "2  [0.8630499839782715, 0.9223499894142151, 0.934...   \n",
              "3  [0.861466646194458, 0.9171666502952576, 0.9309...   \n",
              "4  [0.8608499765396118, 0.9120166897773743, 0.928...   \n",
              "\n",
              "                                  history_train_loss  \n",
              "0  [1.7612853050231934, 0.3980737030506134, 0.232...  \n",
              "1  [2.221606969833374, 0.5513030886650085, 0.2889...  \n",
              "2  [3.1047916412353516, 0.7570062279701233, 0.389...  \n",
              "3  [2.903733968734741, 0.5294719934463501, 0.2888...  \n",
              "4  [3.1085143089294434, 0.5468863248825073, 0.286...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-07a79699-42f8-4187-936a-80519c75abd4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>config</th>\n",
              "      <th>val_accuracy</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>history_val_acc</th>\n",
              "      <th>history_val_loss</th>\n",
              "      <th>history_train_acc</th>\n",
              "      <th>history_train_loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4bit30p</td>\n",
              "      <td>0.9659</td>\n",
              "      <td>0.171998</td>\n",
              "      <td>[0.9089999794960022, 0.9362000226974487, 0.937...</td>\n",
              "      <td>[0.5961990356445312, 0.2810992896556854, 0.243...</td>\n",
              "      <td>[0.8606666922569275, 0.9236666560173035, 0.940...</td>\n",
              "      <td>[1.7612853050231934, 0.3980737030506134, 0.232...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4bit40p</td>\n",
              "      <td>0.9629</td>\n",
              "      <td>0.169417</td>\n",
              "      <td>[0.9169999957084656, 0.9271000027656555, 0.942...</td>\n",
              "      <td>[0.7165398597717285, 0.40322554111480713, 0.24...</td>\n",
              "      <td>[0.8648666739463806, 0.9231166839599609, 0.935...</td>\n",
              "      <td>[2.221606969833374, 0.5513030886650085, 0.2889...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4bit50p</td>\n",
              "      <td>0.9618</td>\n",
              "      <td>0.180078</td>\n",
              "      <td>[0.9168999791145325, 0.9251000285148621, 0.927...</td>\n",
              "      <td>[1.0729739665985107, 0.5806041359901428, 0.340...</td>\n",
              "      <td>[0.8630499839782715, 0.9223499894142151, 0.934...</td>\n",
              "      <td>[3.1047916412353516, 0.7570062279701233, 0.389...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4bit60p</td>\n",
              "      <td>0.9604</td>\n",
              "      <td>0.207152</td>\n",
              "      <td>[0.9065999984741211, 0.9140999913215637, 0.925...</td>\n",
              "      <td>[0.7896328568458557, 0.39091727137565613, 0.29...</td>\n",
              "      <td>[0.861466646194458, 0.9171666502952576, 0.9309...</td>\n",
              "      <td>[2.903733968734741, 0.5294719934463501, 0.2888...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4bit70p</td>\n",
              "      <td>0.9573</td>\n",
              "      <td>0.214989</td>\n",
              "      <td>[0.9067000150680542, 0.9178000092506409, 0.923...</td>\n",
              "      <td>[0.8529000282287598, 0.3971153795719147, 0.286...</td>\n",
              "      <td>[0.8608499765396118, 0.9120166897773743, 0.928...</td>\n",
              "      <td>[3.1085143089294434, 0.5468863248825073, 0.286...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-07a79699-42f8-4187-936a-80519c75abd4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-07a79699-42f8-4187-936a-80519c75abd4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-07a79699-42f8-4187-936a-80519c75abd4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-24cc6afa-baa7-4111-8a83-e780de676be7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-24cc6afa-baa7-4111-8a83-e780de676be7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-24cc6afa-baa7-4111-8a83-e780de676be7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "analysis_df",
              "summary": "{\n  \"name\": \"analysis_df\",\n  \"rows\": 25,\n  \"fields\": [\n    {\n      \"column\": \"config\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 25,\n        \"samples\": [\n          \"5bit60p\",\n          \"7bit40p\",\n          \"4bit30p\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"val_accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0027032496098697164,\n        \"min\": 0.9573000073432922,\n        \"max\": 0.9661999940872192,\n        \"num_unique_values\": 21,\n        \"samples\": [\n          0.9659000039100647,\n          0.9624999761581421,\n          0.9607999920845032\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"val_loss\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.018678120368333457,\n        \"min\": 0.14896921813488007,\n        \"max\": 0.21498934924602509,\n        \"num_unique_values\": 25,\n        \"samples\": [\n          0.19284455478191376,\n          0.18096870183944702,\n          0.17199766635894775\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"history_val_acc\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"history_val_loss\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"history_train_acc\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"history_train_loss\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMuOd1VqK2pi"
      },
      "source": [
        "### What is the value reservoir adds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUUS7VFZSEqb",
        "outputId": "5faf0473-6bc4-40e1-b6ac-fd58bddd117b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(60000, 10)\n",
            "(10000, 196)\n"
          ]
        }
      ],
      "source": [
        "# trainX[1]\n",
        "print(trainY.shape)\n",
        "\n",
        "# pX[1]\n",
        "print(pY.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DkXM-kX4VR_K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc4d238c-307c-46b3-c1d7-63c12988460d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60%_525nm_filter1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x790c84a0fe20> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unknown node type <gast.gast.Expr object at 0x790c303632b0>\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x790c84a0fe20> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unknown node type <gast.gast.Expr object at 0x790c303632b0>\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x790c849b8700> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unknown node type <gast.gast.Expr object at 0x790c6fff6ce0>\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x790c849b8700> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unknown node type <gast.gast.Expr object at 0x790c6fff6ce0>\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x790ce8cbf250> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unknown node type <gast.gast.Expr object at 0x790c84633a00>\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x790ce8cbf250> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unknown node type <gast.gast.Expr object at 0x790c84633a00>\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.total\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.count\n",
            "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.total\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.count\n",
            "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.total\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.count\n",
            "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.total\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.count\n",
            "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.total\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.count\n",
            "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.total\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.count\n",
            "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.total\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.count\n",
            "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.total\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.count\n",
            "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.total\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.count\n",
            "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.total\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.count\n",
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x790dc5672d40> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unknown node type <gast.gast.Expr object at 0x790c6ff4faf0>\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x790dc5672d40> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unknown node type <gast.gast.Expr object at 0x790c6ff4faf0>\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x790ce8129750> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unknown node type <gast.gast.Expr object at 0x790c84986bc0>\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x790ce8129750> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unknown node type <gast.gast.Expr object at 0x790c84986bc0>\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x790c3026de10> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unknown node type <gast.gast.Expr object at 0x790ce8f5d990>\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x790c3026de10> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unknown node type <gast.gast.Expr object at 0x790ce8f5d990>\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x790c849b8a60> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unknown node type <gast.gast.Expr object at 0x790ce90980a0>\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x790c849b8a60> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unknown node type <gast.gast.Expr object at 0x790ce90980a0>\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x790c849b9d80> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unknown node type <gast.gast.Expr object at 0x790cbf932ec0>\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x790c849b9d80> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unknown node type <gast.gast.Expr object at 0x790cbf932ec0>\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x790c6ffd04c0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unknown node type <gast.gast.Expr object at 0x790c84af4610>\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x790c6ffd04c0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unknown node type <gast.gast.Expr object at 0x790c84af4610>\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n",
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x790ce8c9b130> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unknown node type <gast.gast.Expr object at 0x790c847c18a0>\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x790ce8c9b130> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unknown node type <gast.gast.Expr object at 0x790c847c18a0>\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x790ce8c98940> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unknown node type <gast.gast.Expr object at 0x790c84783ac0>\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results: -0.06 (0.00) MSE\n",
            "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x790ce8c98940> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unknown node type <gast.gast.Expr object at 0x790c84783ac0>\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Test NMSE: 97.586741988617\n"
          ]
        }
      ],
      "source": [
        "# import random\n",
        "# import matplotlib\n",
        "# import matplotlib.pyplot as plt\n",
        "# import numpy as np\n",
        "# from math import sqrt\n",
        "# from sklearn.metrics import mean_squared_error\n",
        "# import csv\n",
        "\n",
        "# from sklearn.model_selection import cross_val_score\n",
        "# from sklearn.model_selection import KFold\n",
        "# from scikeras.wrappers import KerasRegressor\n",
        "\n",
        "# with open('NARMA2_train.csv', newline='') as csvfile:\n",
        "#     time_dat = list(csv.reader(csvfile))\n",
        "# train_dat = time_dat[0]\n",
        "# print(train_dat)\n",
        "\n",
        "# with open('NARMA2_test.csv', newline='') as csvfile:\n",
        "#     time_dat = list(csv.reader(csvfile))\n",
        "# test_dat = time_dat[0][:50]\n",
        "# print(test_dat)\n",
        "\n",
        "# def deg2function(ind, uk):\n",
        "#     if ind==0:\n",
        "#         return float((0.6*pow(uk,3)) + 0.1)\n",
        "#     elif ind==1:\n",
        "#         k=target_output[ind-1]\n",
        "#         return float((0.4*k) + (0.6*pow(uk,3)) + 0.1)\n",
        "#     else:\n",
        "#         k=target_output[ind-1]\n",
        "#         k_1=target_output[ind-2]\n",
        "#         return float((0.4*k) + (0.4*k*k_1) + (0.6*pow(uk,3)) + 0.1)\n",
        "\n",
        "# target_output = []\n",
        "\n",
        "# for ind, val in enumerate(train_dat):\n",
        "#     ytk = deg2function(ind, float(val))\n",
        "#     target_output.append(ytk)\n",
        "# # print(target_output)\n",
        "# for ind, val in enumerate(test_dat):\n",
        "#     ytk = deg2function(450+ind, float(val))\n",
        "#     target_output.append(ytk)\n",
        "# # print(target_output)\n",
        "\n",
        "filename = \"60%_525nm_filter1.xlsx\"\n",
        "print(filename.split('.')[0])\n",
        "res_inp = pd.read_excel(filename, index_col=None, header=None)\n",
        "# Row-wise Normalized between 0 and 1\n",
        "res_inp_normalized = res_inp.copy()\n",
        "for i, row in res_inp_normalized.iterrows():\n",
        "    minval = row.min()\n",
        "    maxval = row.max()\n",
        "    res_inp_normalized.loc[i] = (row - minval) / (maxval - minval)\n",
        "\n",
        "#         linearModel = RidgeCV(alphas=(1, 0.001, 0.00001), cv=100)\n",
        "#         linearModel.fit(res_inp_normalized[:450], target_output[:450])\n",
        "#         print(linearModel.score(res_inp_normalized[450:], target_output[450:]))\n",
        "linearModel = Sequential()\n",
        "linearModel.add(Dense(1, input_shape=(30,), kernel_initializer='he_normal', activation='relu'))\n",
        "# linearModel.add(Dense(1, kernel_initializer='normal'))\n",
        "opt = tf.keras.optimizers.Adam()\n",
        "linearModel.compile(loss='mean_squared_error', optimizer=opt)\n",
        "\n",
        "estimator = KerasRegressor(model=linearModel, epochs=100, batch_size=50, verbose=0)\n",
        "kfold = KFold(n_splits=10)\n",
        "results = cross_val_score(estimator, res_inp_normalized[:450], target_output[:450],\n",
        "                          cv=kfold, scoring='neg_mean_squared_error')\n",
        "print(\"Results: %.2f (%.2f) MSE\" % (results.mean(), results.std()))\n",
        "\n",
        "y_pred = linearModel.predict(res_inp_normalized[450:])\n",
        "mse = mean_squared_error(target_output[450:], y_pred)\n",
        "var = np.var(target_output[450:], dtype=np.float64).astype('float').item()\n",
        "\n",
        "print('Test NMSE:', mse/var)\n",
        "#         all_nmse[filename.name.split('.')[0]] = mse/var\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.11.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "StTyQou-FW4v",
        "outputId": "2a9f60d6-2199-419e-9e02-de36f8e5abf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow==2.11.0\n",
            "  Downloading tensorflow-2.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m588.3/588.3 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (1.56.2)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (3.8.0)\n",
            "Collecting keras<2.12,>=2.11.0 (from tensorflow==2.11.0)\n",
            "  Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m88.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (16.0.6)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (1.22.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (23.1)\n",
            "Collecting protobuf<3.20,>=3.9.2 (from tensorflow==2.11.0)\n",
            "  Downloading protobuf-3.19.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m59.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (1.16.0)\n",
            "Collecting tensorboard<2.12,>=2.11 (from tensorflow==2.11.0)\n",
            "  Downloading tensorboard-2.11.2-py3-none-any.whl (6.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m74.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-estimator<2.12,>=2.11.0 (from tensorflow==2.11.0)\n",
            "  Downloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.2/439.2 kB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (4.7.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.11.0) (0.32.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.11.0) (0.41.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0) (2.17.3)\n",
            "Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.12,>=2.11->tensorflow==2.11.0)\n",
            "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0) (3.4.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0) (2.27.1)\n",
            "Collecting tensorboard-data-server<0.7.0,>=0.6.0 (from tensorboard<2.12,>=2.11->tensorflow==2.11.0)\n",
            "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m80.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0 (from tensorboard<2.12,>=2.11->tensorflow==2.11.0)\n",
            "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0) (2.3.6)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (3.2.2)\n",
            "Installing collected packages: tensorboard-plugin-wit, tensorflow-estimator, tensorboard-data-server, protobuf, keras, google-auth-oauthlib, tensorboard, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.12.0\n",
            "    Uninstalling tensorflow-estimator-2.12.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.12.0\n",
            "  Attempting uninstall: tensorboard-data-server\n",
            "    Found existing installation: tensorboard-data-server 0.7.1\n",
            "    Uninstalling tensorboard-data-server-0.7.1:\n",
            "      Successfully uninstalled tensorboard-data-server-0.7.1\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.12.0\n",
            "    Uninstalling keras-2.12.0:\n",
            "      Successfully uninstalled keras-2.12.0\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.0.0\n",
            "    Uninstalling google-auth-oauthlib-1.0.0:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.0.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.12.3\n",
            "    Uninstalling tensorboard-2.12.3:\n",
            "      Successfully uninstalled tensorboard-2.12.3\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.12.0\n",
            "    Uninstalling tensorflow-2.12.0:\n",
            "      Successfully uninstalled tensorflow-2.12.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-datasets 4.9.2 requires protobuf>=3.20, but you have protobuf 3.19.6 which is incompatible.\n",
            "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 3.19.6 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed google-auth-oauthlib-0.4.6 keras-2.11.0 protobuf-3.19.6 tensorboard-2.11.2 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.11.0 tensorflow-estimator-2.11.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google",
                  "keras",
                  "tensorboard",
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "rM5t3KghFbEG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9Utw6NLZFzLj"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "D8L5_XrHID7Z",
        "-atf-YTzSRI3",
        "hI4_4y_PtR08",
        "1kK_PCHbI3Mb",
        "5zJ3-ObmJ1Zg",
        "RMuOd1VqK2pi"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0d5205160bc14986afe86a1f10f0bfa6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1da91789a55243a49349b420bc758852": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4490d439b342455bb334041c10b41ae7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ae2c1f6ad6ff47a889ccc550f36230a5",
              "IPY_MODEL_9de148b9ed774c6db8e60f3314c63be5"
            ],
            "layout": "IPY_MODEL_1da91789a55243a49349b420bc758852"
          }
        },
        "92fc58f5cddf435e99532d4155fd5715": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "98a03a4ba6354bd3be0e9c3639b6f929": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9de148b9ed774c6db8e60f3314c63be5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d5205160bc14986afe86a1f10f0bfa6",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_92fc58f5cddf435e99532d4155fd5715",
            "value": 0.11364663352914596
          }
        },
        "a96000645a9d4dcba56aa9b4605a04d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ae2c1f6ad6ff47a889ccc550f36230a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98a03a4ba6354bd3be0e9c3639b6f929",
            "placeholder": "​",
            "style": "IPY_MODEL_a96000645a9d4dcba56aa9b4605a04d2",
            "value": "0.001 MB of 0.008 MB uploaded (0.000 MB deduped)\r"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}